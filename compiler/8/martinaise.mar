| The Martinaise Compiler  
| This is the compiler for Martinaise, written in Martinaise.
|
| This file is pretty long, but I tried to write the code in an order so that it
| can be read from top to bottom. Comment sections introduce new concepts as you
| read along.
|
| I really recommend reading this with syntax highlighting enabled.
| If you use VS Code: There's a vscode_extension folder in this project. You can
|   open only that folder (File > Open Folder) and then in the debug panel
|   (ctrl + shift + D), you can run the extension. This will open a new VS Code
|   window. If you manage to create a .vsix extension, feel welcome to add it to
|   the repo – my local npm setup seems to not like the commands given in the
|   official guide.
| If you don't use VS Code: There's a text mate grammar in the vscode_extension
|   folder. Good luck!
|
| To understand this file, you don't need to know how compilers are built. You
| should have some experience with programming and a basic understanding of how
| computers work.
|
| Rough overview  
| Like many compilers, the Martinaise compiler works in stages:
|
| ┌──────┐  parsing  ┌─────┐  monomorphization  ┌──────┐  lowering  ┌───────┐
| │ .mar │ ────────> │ Ast │ ─────────────────> │ Mono | ─────────> │ .soil │
| └──────┘           └─────┘                    └──────┘            └───────┘
|
| - .mar: source code, read as a string
| - Ast:  abstract syntax tree, roughly corresponding to the code
| - Mono: monomorphized tree, containing only functions compiled for a
|         concrete combination of type arguments
| - .soil: Soil binary, which you can run in the Soil VM
|
| Glossary  
| I'm not generally a fan of abbreviations, but for concepts that pop up all
| over the place, reading long names gets tedious. Here's a list of
| abbreviations that are used throughout the code:
|
| arg  = argument
| def  = definition
| env  = environment
| expr = expression
| fun  = function
| src  = source
| str  = string
| var  = variable
|
| Plural forms have an "s" at the end (as in "args" or "defs").

import stdlib.mar

| Compatibility With Editor Tooling  
| To enable further tooling such as editor extensions to be built, the compiler
| supports a -json flag, which causes all output to be displayed in a structured
| JSON format.
| TODO: Describe why Martinaise doesn't natively support the LSP.

var tooling_mode = false

var code_cache = map[Str, Str]() | maps file path to content

fun read_cached_code(path: Str): Maybe[Str] { code_cache.get_maybe(path) }
fun read_code(path: Str): Result[Str, Str] {
  if read_cached_code(path) is some(content) then return ok[Str, Str](content)
  var content =
    if tooling_mode then {
      var obj = Json.map(map[Str, Json](
        "type" -> Json.string("read_file"),
        "path" -> Json.string(path),
      ))
      println(obj)
      var response = stdin.read_line()
        or return error[Str, Str]("Couldn't read from stdin.")
      var response = response
        or return error[Str, Str]("Stdin ended without response.")
      var response = response.parse_json()
        or return error[Str, Str]("Response was not JSON.")
      var response = response.map
        or return error[Str, Str]("Response was not a JSON map.")
      var type = response.get_maybe("type")
        or return error[Str, Str]("Response doesn't have a type.")
      var type = type.string
        or return error[Str, Str]("Response type is not a string.")
      type == "read_file"
        or return error[Str, Str]("Response wasn't of type read_file.")
      var success = response.get_maybe("success")
        or return error[Str, Str]("Response didn't have success field.")
      var success = success.bool
        or return error[Str, Str]("Response success isn't a bool.")
      success or return error[Str, Str]("Couldn't read file.")
      response.get_maybe("content")
        or return error[Str, Str]("Response doesn't contain content.")
    } else {
      var content = read_file(path)
        or return error[Str, Str]("Couldn't read file.")
      content.to_str()
    }
  code_cache.&.put(path, content)
  ok[Str, Str](content)
}

| Terminal utilities  

fun write_ansi_escape_sequence[W](writer: W, sequence: Str) {
  writer.write(27.lower_byte().to_char())
  writer.write(sequence)
}
fun print_status(message: Str) {
  if tooling_mode then return {}
  stderr.write_ansi_escape_sequence("[1A") | move cursor up one line
  stderr.write_ansi_escape_sequence("[K")  | erase the current line
  eprintln(message)
}

| Source Locations  
| When compiling and running code, we want errors to point to the right place in
| the source code. To do that, locations are carried throughout the pipeline.

struct Src { file: Str, span: Range[Int] }

fun src(file: Str, span: Range[Int]): Src { Src { file, span } }

fun write[W](writer: W, src: Src) {
  writer."{src.file} {src.span.start} – {src.span.end}"
}

| Maps each file path to a slice that contains for every line at which byte it
| starts.
var line_cache = map[Str, Slice[Int]]()

struct CodePosition { line: Int, column: Int }

fun get_lines_of_file(file: Str): Maybe[Slice[Int]] {
  if line_cache.get_maybe(file) is some(lines) then return some(lines)
  var content = read_cached_code(file) or return none[Slice[Int]]()
  var lines = vec(0)
  for it in content.iter().enumerate() do
    if it.item == newline then lines.&.push(it.index + 1)
  var lines = lines.to_slice()
  line_cache.&.put(file, lines)
  some(lines)
}

fun byte_offset_to_code_position(file: Str, offset: Int): Maybe[CodePosition] {
  var lines = get_lines_of_file(file) or return none[CodePosition]()
  var line = lines.binary_search_leftmost_greater_equal(offset + 1) - 1
  var column = offset - lines.get(line)
  some(CodePosition { line, column })
}
fun to_code_range(src: Src): Maybe[Range[CodePosition]] {
  var start = src.file.byte_offset_to_code_position(src.span.start)
    or return none[Range[CodePosition]]()
  var end   = src.file.byte_offset_to_code_position(src.span.end)
    or return none[Range[CodePosition]]()
  some(start..end)
}

fun to_offset(position: CodePosition, file: Str): Maybe[Int] {
  var lines = get_lines_of_file(file) or return none[Int]()
  var offset = lines.get_maybe(position.line) or return none[Int]()
  some(offset + position.column)
}

fun <=>(a: CodePosition, b: CodePosition): Ordering {
  var line_cmp = a.line <=> b.line
  line_cmp is equal or return line_cmp
  a.column <=> b.column
}

fun write[W](writer: W, position: CodePosition) {
  writer."{position.line}:{position.column}"
}

| Errors  
| When an error occurs, we need to highlight the faulty piece of code. Depending
| on the medium, this might either result in a message in the terminal showing
| a piece of the code, or a squiggly line in the IDE directly at the error
| location.

struct Error { src: Src, title: Str, description: Str, context: Vec[Str] }

fun make_error(
  src: Src, title: Str, description: Str, context: Vec[Str]
): Error { Error { src, title, description, context } }
fun make_error(src: Src, title: Str, description: Str): Error {
  make_error(src, title, description, vec[Str]())
}
fun make_error(src: Src, title: Str): Error { make_error(src, title, "") }

fun write[W](writer: W, error: Error) {
  if error.context.is_not_empty() then {
    writer."Error when compiling\n"
    for entry in error.context do writer." - {entry}\n"
    writer."\n"
  }

  var code = read_code(error.src.file) or {
    writer."{error.src.file} 
      '{error.src.span.start} – {error.src.span.end}: 
      '{error.title}\n
      '{error.description}"
    return {}
  }

  var lines = vec[Str]()
  var current_line = string_builder().&
  var offset_in_line = 0
  for i in 0..code.len do {
    if i == error.src.span.start then offset_in_line = current_line.len()
    if code.get(i) == newline then {
      lines.&.push(current_line.to_str())
      current_line = string_builder().&
      if i >= error.src.span.start then break
    } else current_line.write(code.get(i))
  }
  | Now, lines contains all lines up to the line that contains the error.
  | offset_in_line is the offset into the last complete line.
  var num_lines_to_display = min(lines.len, 4)
  writer."{error.src.file}\n"
  for line_number in {lines.len - num_lines_to_display}..lines.len do {
    writer.write_line_number(line_number)
    writer." | {lines.get(line_number)}\n"
  }
  for i in 0..{7 + offset_in_line} do writer." "
  for i in error.src.span do writer."^"
  writer."\n"
  for i in 0..{7 + offset_in_line} do writer." "
  writer.write(error.title)
  if error.description.is_not_empty() then {
    writer.write(newline)
    writer.write(newline)
    writer.write(error.description)
  }
}
fun write_line_number[W](writer: W, n: Int) {
  if n >= 1000 then writer.write(n)
  else if n >= 100 then writer.write(" {n}")
  else if n >= 10 then writer.write("  {n}")
  else writer.write("   {n}")
}

fun to_json(error: Error): Json {
  var src_obj =
    switch error.src.to_code_range()
      case some(range) map(
        "file" -> Json.string(error.src.file),
        "start" -> Json.map(map(
          "line"   -> Json.int(range.start.line),
          "column" -> Json.int(range.start.column),
        )),
        "end" -> Json.map(map(
          "line"   -> Json.int(range.start.line),
          "column" -> Json.int(range.start.column),
        ))
      )
      case none map(
        "file"  -> Json.string(error.src.file),
        "start" -> Json.map(map("line" -> Json.int(0), "column" -> Json.int(0))),
        "end"   -> Json.map(map("line" -> Json.int(0), "column" -> Json.int(0))),
      )

  var context_array = vec[Json]()
  for entry in error.context do context_array.&.push(Json.string(entry))

  Json.map(map(
    "type" -> Json.string("error"),
    "src" -> Json.map(src_obj),
    "title" -> Json.string(error.title),
    "description" -> Json.string(error.description),
    "context" -> Json.array(context_array),
  ))
}

| The Abstract Syntax Tree  
| An input file is parsed into an abstract syntax tree. This tree is a
| representation of the program that roughly corresponds to the structure of the
| source code.

| A string that appears in the input and knows where it comes from.
struct AstStr { str: Str, src: Src }

struct FileAst { imports: Vec[AstStr], defs: Vec[AstDef] }
enum AstDef {
  opaque_: AstOpaqueType,
  struct_: AstStruct,
  enum_: AstEnum,
  var_: AstVar, | same AstVar as in funs
  fun_: AstFun,
}

struct AstOpaqueType { name: AstStr, size: Int, alignment: Int }

struct AstStruct {
  name: AstStr,
  type_args: Vec[AstStr],
  fields: Vec[AstStructField],
}
struct AstStructField { name: AstStr, type: Type }

struct AstEnum {
  name: AstStr,
  type_args: Vec[AstStr],
  variants: Vec[AstEnumVariant],
}
struct AstEnumVariant { name: AstStr, type: Type }

struct AstFun {
  name: AstStr,
  is_fallback: Bool,
  type_args: Vec[AstStr],
  args: Vec[AstFunArg],
  returns: Type,
  kind: AstFunKind,
}
struct AstFunArg { name: AstStr, type: Type }
enum AstFunKind {
  builtin: AstBuiltinDots, body: Vec[AstExpr], asm_: Vec[AstInstr]
}
struct AstBuiltinDots { dots: AstStr }
enum AstExpr {
  int: Int,                   | 42
  float: Float,               | 1.2
  str: Str,                   | "foo"
  name: AstStr,               | foo
  call: AstCall,              | ...(arg)
  make_struct: AstMakeStruct, | Foo { a = ... }
  make_enum: AstMakeEnum,     | Maybe.some(5)
  member: AstMember,          | foo.bar
  var_: AstVar,               | var foo = ...
  assign: AstAssign,          | foo = ...
  switch_: AstSwitch,         | switch foo case a ... case b(bar) ...
  loop_: AstLoop ,            | loop ...
  break_: AstBreak,           | break(2)
  continue_: AstContinue,     | continue
  return_: AstReturn,         | return ...
  try: AstTry,                | ...?
  try_scope: AstTryScope,     | try ...
  block: Vec[AstExpr],        | { ... }
}
struct AstCall {
  callee: &AstExpr,
  type_args: Maybe[Vec[Type]],
  opening_parenthesis: AstStr,
  args: Vec[AstExpr],
}
struct AstMakeStruct {
  type: Type, type_src: Src, fields: Vec[AstMakeStructField]
}
struct AstMakeStructField { name: AstStr, value: AstExpr }
struct AstMakeEnum { type: Type, variant: AstStr, arg: &AstExpr }
struct AstMember { of: &AstExpr, name: AstStr }
struct AstVar { name: AstStr, value: &AstExpr }
struct AstAssign { to: &AstExpr, value: &AstExpr, equal_sign: AstStr }
struct AstSwitch {
  keyword: AstStr, value: &AstExpr,
  cases: Vec[AstCase], default_: Maybe[&AstDefaultCase],
}
struct AstCase { variant: AstStr, binding: Maybe[AstStr], body: AstExpr }
struct AstDefaultCase { keyword: AstStr, body: AstExpr }
struct AstLoop { keyword: AstStr, body: &AstExpr }
struct AstBreak { keyword: AstStr, value: &AstExpr }
struct AstContinue { keyword: AstStr }
struct AstReturn { keyword: AstStr, value: &AstExpr }
struct AstTry { value: &AstExpr, question_mark: AstStr }
struct AstTryScope { keyword: AstStr, body: &AstExpr }

struct AstInstr { kind: AstInstrKind, mnemonic: AstStr }
enum AstInstrKind {
  label: AstStr, | Not really an instruction, but meh.
  nop,
  panic,
  move: RegAndReg,
  movei: RegAndWord,
  moveib: RegAndByte,
  load: RegAndReg,
  loadb: RegAndReg,
  store: RegAndReg,
  storeb: RegAndReg,
  push: Reg,
  pop: Reg,
  jump: AstStr,
  cjump: AstStr,
  call: AstStr,
  ret,
  syscall: Byte,
  cmp: RegAndReg,
  isequal,
  isless,
  isgreater,
  islessequal,
  isgreaterequal,
  isnotequal,
  fcmp: RegAndReg,
  fisequal,
  fisless,
  fisgreater,
  fislessequal,
  fisgreaterequal,
  fisnotequal,
  inttofloat: Reg,
  floattoint: Reg,
  add: RegAndReg,
  sub: RegAndReg,
  mul: RegAndReg,
  div: RegAndReg,
  rem: RegAndReg,
  fadd: RegAndReg,
  fsub: RegAndReg,
  fmul: RegAndReg,
  fdiv: RegAndReg,
  and: RegAndReg,
  or: RegAndReg,
  xor: RegAndReg,
  negate: Reg,
}

enum Reg { sp, st, a, b, c, d, e, f }

enum Word { literal: Int, label: AstStr, str: Str }

struct RegAndReg { first: Reg, second: Reg }
struct RegAndWord { reg: Reg, word: Word }
struct RegAndByte { reg: Reg, byte: Byte }

fun &(first: Reg, second: Reg): RegAndReg { RegAndReg { first, second } }
fun &(reg: Reg, word: Word): RegAndWord { RegAndWord { reg, word } }
fun &(reg: Reg, byte: Byte): RegAndByte { RegAndByte { reg, byte } }

fun @(str: Str, src: Src): AstStr { AstStr { str, src } }

fun call(
  callee: AstExpr, type_args: Maybe[Vec[Type]], args: Vec[AstExpr],
  opening_parenthesis: AstStr
): AstExpr {
  AstExpr.call(AstCall {
    callee = callee.put_on_heap(), type_args, opening_parenthesis, args
  })
}
fun call(
  callee: AstExpr, args: Vec[AstExpr], opening_parenthesis: AstStr
): AstExpr { callee.call(none[Vec[Type]](), args, opening_parenthesis) }
fun call(callee: AstExpr, opening_parenthesis: AstStr): AstExpr {
  callee.call(vec[AstExpr](), opening_parenthesis)
}
fun member(of: AstExpr, name: AstStr): AstExpr {
  AstExpr.member(AstMember { of = of.put_on_heap(), name })
}
fun var_(name: AstStr, value: AstExpr): AstExpr {
  AstExpr.var_(AstVar { name, value = value.put_on_heap() })
}

fun write[W](writer: W, ast: FileAst) {
  for import_ in ast.imports do writer."import {import_}\n"
  for def in ast.defs do writer."{def}\n"
}
fun write[W](writer: W, def: AstDef) {
  switch def
  case opaque_(o) writer.write(o)
  case struct_(s) writer.write(s)
  case enum_(e) writer.write(e)
  case var_(v) writer.write(v)
  case fun_(f) writer.write(f)
}
fun write[W](writer: W, name: AstStr) { writer."{name.str}" }
fun write[W](writer: W, opaque_: AstOpaqueType) {
  writer."opaque {opaque_.name} = {opaque_.size} {
    if opaque_.size == 1 then "byte" else "bytes"
  } big, {opaque_.alignment} {
    if opaque_.alignment == 1 then "byte" else "bytes"
  } aligned"
}
fun write[W](writer: W, struct_: AstStruct) {
  writer."struct {struct_.name}{type_args(struct_.type_args)} "
  if struct_.fields.is_empty() then writer."\{\}" else {
    writer."\{\n"
    for field in struct_.fields do
      writer."  {field.name}: {field.type},\n"
    writer."\}"
  }
}
fun write[W](writer: W, enum_: AstEnum) {
  writer."enum {enum_.name}{type_args(enum_.type_args)} "
  if enum_.variants.is_empty() then writer."\{}" else {
    writer."\{\n\}"
    for variant in enum_.variants do
      writer."  {variant.name}: {variant.type},\n"
    writer."}"
  }
}

struct Indent { amount: Int }
fun inc(indent: Indent): Indent { Indent { amount = indent.amount + 1 } }
fun write[W](writer: W, indent: Indent) {
  for i in 0..{2 * indent.amount} do writer." "
}
struct Indented[T] { indent: Indent, what: T }
fun write[W, T](writer: W, indented: Indented[T]) {
  writer.write(indented.indent, indented.what)
}
fun indent(amount: Int): Indent { Indent { amount } }
fun indented[T](what: T, indent: Indent): Indented[T] {
  Indented { indent, what }
}

fun write[W](writer: W, var_: AstVar) {
  writer.write(Indent { amount = 0 }, var_)
}
fun write[W](writer: W, indent: Indent, var_: AstVar) {
  writer."var {var_.name} = {var_.value.*.indented(indent)}"
}
fun write[W](writer: W, fun_: AstFun) {
  writer."{if fun_.is_fallback then "fallback " else ""}
    'fun {fun_.name}{type_args(fun_.type_args)}
    '({comma_separated(fun_.args)}): {fun_.returns} "
  switch fun_.kind
  case builtin writer."\{ ... \}"
  case body(body) writer.write_block(Indent { amount = 0 }, body)
  case asm_(instructions) {
    writer."asm \{\n"
    for instruction in instructions do writer."  {instruction}\n"
    writer."}"
  }
}
fun write_block[W](writer: W, indent: Indent, body: Vec[AstExpr]) {
  if body.is_empty() then { writer."\{}" return {} }
  writer."\{\n"
  for expr in body do
    writer."{indent.inc()}{expr.indented(indent.inc())}\n"
  writer."{indent}\}"
}
fun write[W](writer: W, indent: Indent, expr: AstExpr) {
  switch expr
  case int(int) writer.write(int)
  case float(float) writer.write(float)
  case str(str) writer."\"{str}\"" | TODO: escape special characters
  case name(name) writer.write(name)
  case call(call) {
    writer.write(indent, call.callee.*)
    if call.type_args is some(type_args) then writer."{type_args(type_args)}"
    writer."("
    var first = true
    for arg in call.args do {
      if first then first = false else writer.", "
      writer.write(indent, arg)
    }
    writer.")"
  }
  case make_struct(struct_) {
    writer."{struct_.type} "
    if struct_.fields.is_empty() then writer."\{}" else {
      writer."\{\n"
      for field in struct_.fields do
        writer."{indent.inc()}{field.name} = 
          '{field.value.indented(indent.inc())},\n"
      writer."{indent}}"
    }
  }
  case make_enum(enum_)
    writer."{enum_.type}.{enum_.variant}({enum_.arg.*.indented(indent)})"
  case member(member) writer."{member.of.*.indented(indent)}.{member.name}"
  case var_(var_) writer.write(var_)
  case assign(assign)
    writer."{assign.to.*.indented(indent)} = {assign.value.*.indented(indent)}"
  case switch_(switch_) {
    writer."switch { {switch_.value.*.indented(indent)} }"
    for case_ in switch_.cases do {
      writer."\n{indent}case {case_.variant}"
      if case_.binding is some(binding) then writer."({binding})"
      writer." \{\n
        '{indent.inc()}{case_.body.indented(indent.inc())}\n
        '{indent}\}"
    }
    if switch_.default_ is some(default_) then
      writer."\n{indent}default \{\n
        '{indent.inc()}{default_.*.body.indented(indent.inc())}\n
        '{indent}}"
  }
  case loop_(loop_) writer."loop {loop_.body.*.indented(indent)}"
  case break_(break_) writer."break({break_.value.*.indented(indent)})"
  case continue_ writer."continue"
  case return_(return_) writer."return {return_.value.*.indented(indent)}"
  case try(try_) writer."{try_.value.*.indented(indent)}?"
  case try_scope(scope) writer."try {scope.body.*.indented(indent)}"
  case block(block) writer.write_block(indent, block)
}
fun write[W](writer: W, arg: AstFunArg) { writer."{arg.name}: {arg.type}" }

fun write[W](writer: W, instruction: AstInstr) {
  switch instruction.kind
  case label(label) writer."{label}:"
  case nop writer."nop"
  case panic writer."panic"
  case move(regs) writer."move {regs.first} {regs.second}"
  case movei(args) writer."movei {args.reg} {args.word}"
  case moveib(args) writer."moveib {args.reg} {args.byte}"
  case load(regs) writer."load {regs.first} {regs.second}"
  case loadb(regs) writer."loadb {regs.first} {regs.second}"
  case store(regs) writer."store {regs.first} {regs.second}"
  case storeb(regs) writer."storeb {regs.first} {regs.second}"
  case push(reg) writer."push {reg}"
  case pop(reg) writer."pop {reg}"
  case jump(word) writer."jump {word}"
  case cjump(word) writer."cjump {word}"
  case call(word) writer."call {word}"
  case ret writer."ret"
  case syscall(byte) writer."syscall {byte}"
  case cmp(regs) writer."cmp {regs.first} {regs.second}"
  case isequal writer."isequal"
  case isless writer."isless"
  case isgreater writer."isgreater"
  case islessequal writer."islessequal"
  case isgreaterequal writer."isgreaterequal"
  case isnotequal writer."isnotequal"
  case fcmp(regs) writer."fcmp {regs.first} {regs.second}"
  case fisequal writer."fisequal"
  case fisless writer."fisless"
  case fisgreater writer."fisgreater"
  case fislessequal writer."fislessequal"
  case fisgreaterequal writer."fisgreaterequal"
  case fisnotequal writer."fisnotequal"
  case inttofloat(reg) writer."inttofloat {reg}"
  case floattoint(reg) writer."floattoint {reg}"
  case add(regs) writer."add {regs.first} {regs.second}"
  case sub(regs) writer."sub {regs.first} {regs.second}"
  case mul(regs) writer."mul {regs.first} {regs.second}"
  case div(regs) writer."div {regs.first} {regs.second}"
  case rem(regs) writer."rem {regs.first} {regs.second}"
  case fadd(regs) writer."fadd {regs.first} {regs.second}"
  case fsub(regs) writer."fsub {regs.first} {regs.second}"
  case fmul(regs) writer."fmul {regs.first} {regs.second}"
  case fdiv(regs) writer."fdiv {regs.first} {regs.second}"
  case and(regs) writer."and {regs.first} {regs.second}"
  case or(regs) writer."or {regs.first} {regs.second}"
  case xor(regs) writer."xor {regs.first} {regs.second}"
  case negate(reg) writer."negate {reg}"
}

fun write[W](writer: W, reg: Reg) {
  switch reg
  case sp writer."sp"
  case st writer."st"
  case a writer."a"
  case b writer."b"
  case c writer."c"
  case d writer."d"
  case e writer."e"
  case f writer."f"
}

fun write[W](writer: W, word: Word) {
  switch word
  case literal(num) writer."{num}"
  case label(str) writer."{str}"
  case str(str) writer."{str}"
}

fun signature(def: AstDef): AstSignature { AstSignature { def } }
fun signature(fun_: AstFun): AstSignature {
  AstSignature { def = AstDef.fun_(fun_) }
}
struct AstSignature { def: AstDef }
fun write[W](writer: W, signature: AstSignature) {
  switch signature.def
  case opaque_(opaque_)
    writer."opaque {opaque_.name}"
  case struct_(struct_)
    writer."struct {struct_.name}{type_args(struct_.type_args)}"
  case enum_(enum_) writer."enum {enum_.name}{type_args(enum_.type_args)}"
  case var_(var_) writer."var {var_.name}"
  case fun_(fun_) writer
    ."fun {fun_.name}{type_args(fun_.type_args)}({comma_separated(fun_.args)})"
}

| A signature that doesn't print argument names, only types.
fun stripped_signature(fun_: AstFun): StrippedFunSignature {
  var type_args = vec[Type]()
  for arg in fun_.type_args do type_args.&.push(type(arg.str))
  var arg_types = vec[Type]()
  for arg in fun_.args do arg_types.&.push(arg.type)
  signature(fun_.name.str, some(type_args), arg_types)
}
fun signature(
  name: Str, type_args: Maybe[Vec[Type]], arg_types: Vec[Type]
): StrippedFunSignature { StrippedFunSignature { name, type_args, arg_types } }
struct StrippedFunSignature {
  name: Str, type_args: Maybe[Vec[Type]], arg_types: Vec[Type]
}
fun write[W](writer: W, signature: StrippedFunSignature) {
  writer."{signature.name}"
  if signature.type_args is some(type_args_)
  then writer.write(type_args(type_args_))
  writer."({comma_separated(signature.arg_types)})"
}

| Parsing  
| Unlike the parser in Candy (github.com/candy-lang/candy), the Martinaise
| parser favors simplicity over robustness. The first time it encounters an
| error, it simply gives up. This also means that for invalid code, you'll only
| get the first syntax error reported.
| 
| The parser is structured as a recursive descent parser: Lots of little
| functions call each other, each parsing a specific syntax, and all operate
| with a common cursor. Most higher-level parser functions return a
| Result[Maybe[...], Str], where the return value has this meaning:
|
| - ok(none): The parser function doesn't match what comes next in the input.
|   The cursor remains unchanged.
| - ok(some(...)): The parsing was successful. The result is in the return
|   value.
| - error(...): The input is invalid. The entire parser should give up. The
|   cursor is at the position where the error in the input is.
|
| For example, here are possible results of the parse_number function:
|
| input         | "abc"    | "42 foo"     | "42foo"
| cursor before |  ^       |  ^           |  ^
| cursor after  |  ^       |    ^         |    ^
| result        | ok(none) | ok(some(42)) | error("Expected another digit.")
|
| - In the first case, the parser didn't match because the input doesn't start
|   with a digit.
| - In the second case, the parser does match, and it successfully parses the
|   number, moving the cursor after the number.
| - In the third case, the input starts with a digit – unmistakably a number!
|   However, because it has a lowercase letter in it, it's invalid and results
|   in an error. This is an invalid program.
|
| Whitespace is automatically consumed by the fundamental parsers. This is done
| because Martinaise generally doesn't care about whitespace and it makes the
| code of the higher-level parsers (structs, enums, etc.) much more concise.

| The code is guaranteed to have a null char at the end.
struct Parser { file: Str, code: Str, cursor: Int }

fun parser(file: Str, code: Str): Parser {
  Parser { file, code = "{code}{null_char}", cursor = 0 }
}

var null_char = 0.lower_byte().to_char()
fun current(parser: Parser): Char { parser.code.get_unchecked(parser.cursor) }
fun rest(parser: Parser): Str { parser.code.without_first(parser.cursor) }
fun advance(parser: &Parser) { parser.advance_by(1) }
fun advance_by(parser: &Parser, n: Int) { parser.cursor = parser.cursor + n }

fun consume_whitespace(parser: &Parser) {
  loop {
    if parser.cursor >= parser.code.len then break
    var char = parser.current()
    if char.is_whitespace() then {
      parser.cursor = parser.cursor + 1
      continue
    }
    if char == #| then {
      loop {
        if parser.cursor >= parser.code.len then break
        if parser.current() == newline then break
        parser.cursor = parser.cursor + 1
      }
      continue
    }
    break | not a whitespace nor comment
  }
}
fun consume_prefix(parser: &Parser, prefix: Str): Maybe[AstStr] {
  parser.consume_whitespace()
  var start = parser.cursor
  parser.rest().starts_with(prefix) or return none[AstStr]()
  parser.advance_by(prefix.len)
  var end = parser.cursor
  some(prefix @ src(parser.file, start..end))
}
| Also makes sure there's a non-letter following, so consume_keyword("fun")
| doesn't match the code "funny".
fun consume_keyword(parser: &Parser, keyword: Str): Maybe[AstStr] {
  parser.consume_whitespace()
  var start = parser.cursor
  parser.rest().starts_with(keyword) or return none[AstStr]()
  if parser.rest().len > keyword.len then {
    var char_after = parser.rest().get(keyword.len)
    if char_after.is_letter() or char_after.is_digit() or char_after == #_
    then return none[AstStr]()
  }
  parser.advance_by(keyword.len)
  var end = parser.cursor
  some(keyword @ src(parser.file, start..end))
}

fun parse_name(parser: &Parser): Maybe[AstStr] {
  var start = parser.cursor
  loop {
    var char = parser.current()
    if char.is_letter() or {char == #_} then
      parser.advance()
    else if char.is_digit() then {
      if parser.cursor == start then break else parser.advance()
    }
    else break
  }
  var end = parser.cursor
  if start == end then return none[AstStr]()
  some(parser.code.substr(start..end) @ src(parser.file, start..end))
}

fun parse_lower_name(parser: &Parser): Maybe[AstStr] {
  parser.consume_whitespace()
  if not({#a..=#z}.contains(parser.current())) then return none[AstStr]()
  parser.parse_name()
}

fun parse_upper_name(parser: &Parser): Maybe[AstStr] {
  parser.consume_whitespace()
  if not({#A..=#Z}.contains(parser.current())) then return none[AstStr]()
  parser.parse_name()
}

fun parse_operator_name(parser: &Parser): Maybe[AstStr] {
  parser.consume_whitespace()
  var allowed = "%!~@^\\`/&*+$-<>=."
  var start = parser.cursor
  loop {
    var char = parser.current()
    var is_operator = false
    for c in allowed.chars() do
      if char == c then is_operator = true
    if is_operator then parser.advance() else break
  }
  var end = parser.cursor
  if start == end then return none[AstStr]()
  var name = parser.code.substr(start..end)
  | disallow some patterns
  if name == "=" then { parser.cursor = start return none[AstStr]() }
  if name == "." then { parser.cursor = start return none[AstStr]() }
  if name.starts_with(".*") / name.starts_with(".&")
  then { parser.cursor = start return none[AstStr]() }
  some(name @ src(parser.file, start..end))
}

| Convenience methods for the three possible results of parsers returning a
| Result[Maybe[T], Str].
fun bad_input[T](error: Str): Result[Maybe[T], Str] {
  error[Maybe[T], Str](error)
}
fun no_match[T](): Result[Maybe[T], Str] {
  ok[Maybe[T], Str](none[T]())
}
fun parsed[T](val: T): Result[Maybe[T], Str] {
  ok[Maybe[T], Str](some(val))
}

fun parse_type(parser: &Parser): Result[Maybe[Type], Str] {
  if parser.consume_prefix("&") is some then {
    var arg = parser.parse_type()?
      or return bad_input[Type]("After &, there must come a type.")
    return parsed(type("&", vec(arg)))
  }
  if parser.consume_keyword("_") is some then return parsed(type("_"))

  var name = parser.parse_upper_name() or return no_match[Type]()
  var args = parser.parse_type_args()? or vec[Type]()
  parsed(Type { name = name.str, args })
}

fun parse_type_args(parser: &Parser): Result[Maybe[Vec[Type]], Str] {
  var args = vec[Type]()
  parser.consume_prefix("[") or return no_match[Vec[Type]]()
  loop {
    args.&.push(parser.parse_type()? or break)
    parser.consume_prefix(",") or break
  }
  parser.consume_prefix("]") or return bad_input[Vec[Type]](
    "Expected a closing bracket to end the type arguments.")
  parsed(args)
}

| Like parse_type_args, but the args can only be strings, not types with
| generics.
fun parse_type_params(parser: &Parser): Result[Maybe[Vec[AstStr]], Str] {
  var args = vec[AstStr]()
  parser.consume_prefix("[") or return no_match[Vec[AstStr]]()
  loop {
    args.&.push(parser.parse_upper_name() or break)
    parser.consume_prefix(",") or break
  }
  parser.consume_prefix("]") or return bad_input[Vec[AstStr]](
    "Expected a closing bracket to end the type arguments.")
  parsed(args)
}

| Expressions are parsed in two parts: parse_expr_without_suffix can parse
| atomic expressions such as 4 or "hey". parse_expr_suffix can parse expressions
| that are written behind other expressions and wrap them, for example
| `foo or bar` being parsed into an or of foo and bar.
fun parse_expr(parser: &Parser): Result[Maybe[AstExpr], Str] {
  parser.parse_expr(Precedence.assign)
}

enum Precedence { immediate, operator, and, or, is, assign }
fun to_int(precedence: Precedence): Int {
  switch precedence
  case immediate 5
  case operator 4
  case and 3
  case or 2
  case is 1
  case assign 0
}
fun <=>(a: Precedence, b: Precedence): Ordering { a.to_int() <=> b.to_int() }

fun parse_expr(
  parser: &Parser, precedence: Precedence,
): Result[Maybe[AstExpr], Str] {
  var expr = parser.parse_expr_without_suffix()?
    or return no_match[AstExpr]()
  loop expr = parser.parse_expr_suffix(expr, precedence)? or break
  parsed(expr)
}
fun parse_expr_without_suffix(parser: &Parser): Result[Maybe[AstExpr], Str] {
  if parser.parse_number()? is some(int) then return parsed(int)
  if parser.parse_char()? is some(char) then return parsed(char)
  if parser.parse_str()? is some(str) then return parsed(str)
  if parser.parse_make()? is some(make) then return parsed(make)
  if parser.parse_block()? is some(blck) then return parsed(AstExpr.block(blck))
  if parser.parse_var()? is some(var_) then return parsed(AstExpr.var_(var_))
  if parser.parse_if()? is some(if_) then return parsed(if_)
  if parser.parse_switch()? is some(switch_) then return parsed(switch_)
  if parser.parse_loop()? is some(loop_) then return parsed(loop_)
  if parser.parse_for()? is some(for_) then return parsed(for_)
  if parser.parse_break()? is some(break_) then return parsed(break_)
  if parser.parse_continue()? is some(continue_) then return parsed(continue_)
  if parser.parse_return()? is some(return_) then return parsed(return_)
  if parser.parse_try_scope()? is some(try_) then return parsed(try_)
  if parser.parse_lower_name() is some(n) then return parsed(AstExpr.name(n))
  if parser.current() == #; then return bad_input[AstExpr]("Nice try, Mik!")
  no_match[AstExpr]()
}
fun parse_expr_suffix(
  parser: &Parser, expr: AstExpr, precedence: Precedence,
): Result[Maybe[AstExpr], Str] {
  if precedence <= Precedence.is then
    if parser.parse_expr_suffix_is(expr)? is some(is_) then return parsed(is_)
  if precedence <= Precedence.or then
    if parser.parse_expr_suffix_or(expr)? is some(or_) then return parsed(or_)
  if precedence <= Precedence.and then
    if parser.parse_expr_suffix_and(expr)? is some(and_) then
      return parsed(and_)
  if precedence <= Precedence.operator then
    if parser.parse_expr_suffix_operator(expr)? is some(o) then return parsed(o)
  if precedence <= Precedence.assign then
    if parser.parse_expr_suffix_assign(expr)? is some(a) then return parsed(a)
  if parser.parse_expr_suffix_member(expr)? is some(mem) then return parsed(mem)
  if parser.parse_expr_suffix_call(expr)? is some(call) then return parsed(call)
  if parser.parse_expr_suffix_try(expr)? is some(try_) then return parsed(try_)
  no_match[AstExpr]()
}

fun parse_digits(parser: &Parser, radix: Int): Result[Maybe[Int], Str] {
  var start = parser.cursor
  var num = 0
  if radix > {10 + 26} then return bad_input[Int]("The radix is too big.")
  loop {
    var char = parser.current()
    if {#0 ..+ min(radix, 10).lower_byte()}.contains(char) then {
      num = num * radix + {char - #0}.to_int()
      parser.advance()
      continue
    }
    if radix >= 10 then if {#a ..+ min(radix - 10, 26).lower_byte()}.contains(char)
    then {
      num = num * radix + {char - #a + 10.lower_byte()}.to_int()
      parser.advance()
      continue
    }
    if char == #_ then parser.advance() else break
  }
  if parser.cursor == start then return no_match[Int]()
  parsed(num)
}

fun parse_number(parser: &Parser): Result[Maybe[AstExpr], Str] {
  parser.consume_whitespace()
  var radix = 10
  var sign = if parser.consume_prefix("-") is some then {0-1} else 1
  var value = parser.parse_digits(radix)? or
    return
      if sign == 1
      then no_match[AstExpr]()
      else bad_input[AstExpr]("Expected number after the minus sign.")
  if parser.consume_prefix("#") is some then {
    radix = value
    value = parser.parse_digits(radix)? or return bad_input[AstExpr](
      "Expected the value of the number after the radix pound.")
  }
  var expr = AstExpr.int(sign * value)
  var cursor_before_dot = parser.cursor
  if parser.consume_prefix(".") is some then {
    var start_of_decimals = parser.cursor
    var decimals = parser.parse_digits(radix)? or {
      parser.cursor = cursor_before_dot
      return parsed(expr)
    }
    var num_decimals = parser.cursor - start_of_decimals
    if num_decimals > 18 then return bad_input[AstExpr]("Too many decimals.")

    var integer_part = value.to_float()
    var decimal_part = decimals.to_float() / {10 ** num_decimals}.to_float()
    expr = AstExpr.float(sign.to_float() * {integer_part + decimal_part})
  }
  var end = parser.cursor
  parsed(expr)
}

| #a becomes Char { byte = 97.lower_byte() }
fun parse_char(parser: &Parser): Result[Maybe[AstExpr], Str] {
  parser.consume_prefix("#") or return no_match[AstExpr]()
  var char = parser.current()
  parser.advance()
  var src = src(parser.file, {parser.cursor - 2}..parser.cursor)
  parsed(AstExpr.make_struct(AstMakeStruct {
    type = type("Char"),
    type_src = src,
    fields = vec(AstMakeStructField {
      name = "byte" @ src,
      value = AstExpr.int(char.byte.to_int())
        .member("lower_byte" @ src).call("(" @ src),
    }),
  }))
}

| TODO: document strings somewhere
fun parse_str(parser: &Parser): Result[Maybe[AstExpr], Str] {
  parser.consume_whitespace()
  var start = parser.cursor
  var parts = parser.parse_str_parts()? or return no_match[AstExpr]()
  var end = parser.cursor
  var src = src(parser.file, start..end)
  if parts.len == 1 then {
    var expr = parts.get(0)
    if expr is str then return parsed(expr)
  }
  var block = vec[AstExpr]()
  block.&.push(var_("$str" @ src,
    AstExpr.name("string_builder" @ src)
      .call(none[Vec[Type]](), vec[AstExpr](), "(" @ src)
      .member("&" @ src)))
  for part in parts do
    block.&.push(AstExpr.name("$str" @ src).member("write" @ src)
      .call(vec(part), "(" @ src))
  block.&.push(AstExpr.name("$str" @ src)
    .member("to_str" @ src).call("(" @ src))
  parsed(AstExpr.block(block))
}
| Parses a string literal, potentially with interpolation, into expressions.
| "Hello" -> ["Hello"]
| "Hello, {3}!" -> ["Hello", 3]
| "foo \" bar" -> ["foo \" bar "]
fun parse_str_parts(parser: &Parser): Result[Maybe[Vec[AstExpr]], Str] {
  parser.consume_prefix("\"") or return no_match[Vec[AstExpr]]()

  var parts = vec[AstExpr]()
  var part = vec[Char]()
  loop {
    var c = parser.current()
    | double quote -> string ends
    if c == #" then { parser.advance() break }
    | brace -> interpolation
    if c == #{ then {
      parser.advance()
      if part.is_not_empty() then {
        parts.&.push(AstExpr.str(part.to_str()))
        part = vec[Char]()
      }
      var expr = parser.parse_expr()? or return bad_input[Vec[AstExpr]](
        "Expected an expression as string interpolation.")
      parts.&.push(expr)
      parser.consume_prefix("}") or return bad_input[Vec[AstExpr]](
        "Expected a closing brace after string interpolation.")
      continue
    }
    | backslash -> escaped character
    if c == #\ then {
      parser.advance()
      if parser.current() == #\ then { part.&.push(#\) parser.advance() continue }
      if parser.current() == #" then { part.&.push(#") parser.advance() continue }
      if parser.current() == #{ then { part.&.push(#{) parser.advance() continue }
      if parser.current() == #} then { part.&.push(#}) parser.advance() continue }
      if parser.current() == #n then { part.&.push(newline) parser.advance() continue }
      return bad_input[Vec[AstExpr]]("Unknown string escape.")
    }
    | newline -> skip, consume whitespace in next line until single quote
    if c == newline then {
      parser.advance()
      loop if parser.current() == space then parser.advance() else break
      parser.current() == #' or return bad_input[Vec[AstExpr]](
        "After a newline, a string needs to have a single quote.")
      parser.advance()
      continue
    }
    | everything else -> literal character
    part.&.push(parser.current())
    parser.advance()
  }
  if part.is_not_empty() then parts.&.push(AstExpr.str(part.to_str()))
  parsed(parts)
}

| Parses either a struct creation such as Foo { foo, bar = 4 } or an enum
| creation such as Maybe[Int].some(4).
fun parse_make(parser: &Parser): Result[Maybe[AstExpr], Str] {
  parser.consume_whitespace()
  var start = parser.cursor
  var type = parser.parse_type()? or return no_match[AstExpr]()
  var end = parser.cursor
  var type_src = src(parser.file, start..end)
  if parser.consume_prefix("\{") is some then {
    var fields = vec[AstMakeStructField]()
    loop {
      var name = parser.parse_lower_name() or break
      var value =
        if parser.consume_prefix("=") is some then
          parser.parse_expr()?
            or return bad_input[AstExpr]("Expected the value of the field.")
        else AstExpr.name(name)
      fields.&.push(AstMakeStructField { name, value })
      parser.consume_prefix(",") or break
    }
    parser.consume_prefix("}")
      or return bad_input[AstExpr]("Expected a closing brace.")
    parsed(AstExpr.make_struct(AstMakeStruct { type, type_src, fields }))
  } else {
    parser.consume_prefix(".")
      or return bad_input[AstExpr]("Expected struct or enum creation.")
    var variant = parser.parse_lower_name()
      or return bad_input[AstExpr]("Expected the variant.")

    var arg = AstExpr.block(vec[AstExpr]())
    if parser.consume_prefix("(") is some then {
      arg = parser.parse_expr()? or return bad_input[AstExpr](
        "Expected an argument for the variant.")
      parser.consume_prefix(")")
        or return bad_input[AstExpr]("Expected a closing parenthesis.")
    }
    parsed(AstExpr.make_enum(
      AstMakeEnum { type, variant, arg = arg.put_on_heap() }
    ))
  }
}

fun parse_block(parser: &Parser): Result[Maybe[Vec[AstExpr]], Str] {
  parser.consume_prefix("\{") or return no_match[Vec[AstExpr]]()
  var statements = vec[AstExpr]()
  loop statements.&.push(parser.parse_expr()? or break)
  parser.consume_prefix("}") or return bad_input[Vec[AstExpr]](
    "Expected the closing brace of the block.")
  parsed(statements)
}

fun parse_var(parser: &Parser): Result[Maybe[AstVar], Str] {
  parser.consume_keyword("var") or return no_match[AstVar]()
  var name = parser.parse_lower_name()
    or return bad_input[AstVar]("Expected the name of the variable.")
  parser.consume_prefix("=")
    or return bad_input[AstVar]("Expected an equals sign.")
  var value = parser.parse_expr()?
    or return bad_input[AstVar]("Expected the value of the variable.")
  parsed(AstVar { name, value = value.put_on_heap() })
}

| An if can take multiple forms:
| - if condition then foo
| - if condition then foo else bar
| - if condition is variant then foo
| - if condition is variant then foo else bar
| - if condition is variant(binding) then foo
| - if condition is variant(binding) then foo else bar
| They all get desugared into a switch.
fun parse_if(parser: &Parser): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("if") or return no_match[AstExpr]()
  var condition = parser.parse_expr(Precedence.or)?
    or return bad_input[AstExpr]("Expected the condition.")
  var variant = "true" @ keyword.src
  var binding = none[AstStr]()
  if parser.consume_keyword("is") is some then {
    variant = parser.parse_lower_name()
      or return bad_input[AstExpr]("Expected a variant.")
    if parser.consume_prefix("(") is some then {
      binding = some(parser.parse_lower_name()
        or return bad_input[AstExpr]("Expected the name of the binding."))
      parser.consume_prefix(")")
        or return bad_input[AstExpr]("Expected a closing parenthesis.")
    }
  }
  parser.consume_keyword("then")
    or return bad_input[AstExpr]("Expected then keyword.")
  var then_ = parser.parse_expr()?
    or return bad_input[AstExpr]("Expected a then expression.")
  var else_ = AstExpr.block(vec[AstExpr]())
  var else_src = keyword.src
  if parser.consume_keyword("else") is some(keyword) then {
    else_ = parser.parse_expr()?
      or return bad_input[AstExpr]("Expected an else expression.")
    else_src = keyword.src
  }
  parsed(AstExpr.switch_(AstSwitch {
    keyword,
    value = condition.put_on_heap(),
    cases = vec(AstCase { variant, binding, body = then_ }),
    default_ = some(AstDefaultCase {
      keyword = "default" @ else_src,
      body = else_,
    }.put_on_heap()),
  }))
}

fun parse_switch(parser: &Parser): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("switch") or return no_match[AstExpr]()
  var value = parser.parse_expr()? or return bad_input[AstExpr](
    "Expected the value that is switched over.")
  var cases = vec[AstCase]()
  loop {
    parser.consume_keyword("case") or break
    var variant = parser.parse_lower_name()
      or return bad_input[AstExpr]("Expected a variant.")
    var binding = none[AstStr]()
    var opening_paren = parser.consume_prefix("(")
    if opening_paren is some then {
      binding = some(parser.parse_lower_name()
        or return bad_input[AstExpr]("Expected the name of the binding."))
      parser.consume_prefix(")")
        or return bad_input[AstExpr]("Expected a closing parenthesis.")
    }
    var body = parser.parse_expr()?
      or return bad_input[AstExpr]("Expected a case expression.")
    cases.&.push(AstCase { variant, binding, body })
  }
  var default_ = none[&AstDefaultCase]()
  if parser.consume_keyword("default") is some(keyword) then {
    var body = parser.parse_expr()?
      or return bad_input[AstExpr]("Expected a default expression.")
    default_ = some(AstDefaultCase { keyword, body }.put_on_heap())
  }
  parsed(AstExpr.switch_(AstSwitch {
    keyword, value = value.put_on_heap(), cases, default_,
  }))
}

fun parse_loop(parser: &Parser): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("loop") or return no_match[AstExpr]()
  var expr = parser.parse_expr()?
    or return bad_input[AstExpr]("Expected loop expression.")
  parsed(AstExpr.loop_(AstLoop { keyword, body = expr.put_on_heap() }))
}

| A for-loop such as `for foo in bar do baz` gets desugared into this:
| {
|   var $iter = bar.iter().&
|   loop {
|     var foo = switch $iter.next() case some(a) a case none break
|     baz
|   }
| }
fun parse_for(parser: &Parser): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("for") or return no_match[AstExpr]()
  var src = keyword.src
  var iter_var = parser.parse_lower_name()
    or return bad_input[AstExpr](
      "Expected the name of the iteration variable.")
  parser.consume_keyword("in")
    or return bad_input[AstExpr]("Expected in keyword.")
  var iter = parser.parse_expr()?
    or return bad_input[AstExpr]("Expected something to iterate over.")
  parser.consume_keyword("do")
    or return bad_input[AstExpr]("Expected do keyword.")
  var expr = parser.parse_expr()?
    or return bad_input[AstExpr]("Expected a loop expression.")
  parsed(AstExpr.block(vec(
    var_("$iter" @ src,
      iter.member("iter" @ src).call("(" @ src).member("&" @ src)),
    AstExpr.loop_(AstLoop {
      keyword,
      body = AstExpr.block(vec(
        var_(iter_var, AstExpr.switch_(AstSwitch {
          keyword,
          value = AstExpr.name("$iter" @ src)
            .member("next" @ src).call("(" @ src).put_on_heap(),
          cases = vec(
            AstCase {
              variant = "some" @ src,
              binding = some("a" @ src),
              body = AstExpr.name("a" @ src),
            },
            AstCase {
              variant = "none" @ src,
              binding = none[AstStr](),
              body = AstExpr.break_(AstBreak {
                keyword = "break" @ src,
                value = AstExpr.make_struct(AstMakeStruct {
                  type = type("Nothing"),
                  type_src = src,
                  fields = vec[AstMakeStructField](),
                }).put_on_heap()
              }),
            },
          ),
          default_ = none[&AstDefaultCase](),
        })),
        expr,
      )).put_on_heap()
    })
  )))
}

fun parse_break(parser: &Parser): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("break")
    or return no_match[AstExpr]()
  var expr = if parser.consume_prefix("(") is some
    then {
      var expr = parser.parse_expr()?
        or return bad_input[AstExpr]("Expected break expression.")
      parser.consume_prefix(")")
        or return bad_input[AstExpr]("Expected closing parenthesis.")
      expr
    }
    else AstExpr.make_struct(AstMakeStruct {
      type = type("Nothing"),
      type_src = keyword.src,
      fields = vec[AstMakeStructField](),
    })
  parsed(AstExpr.break_(AstBreak { keyword, value = expr.put_on_heap() }))
}

fun parse_continue(parser: &Parser): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("continue")
    or return no_match[AstExpr]()
  parsed(AstExpr.continue_(AstContinue { keyword }))
}

fun parse_return(parser: &Parser): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("return")
    or return no_match[AstExpr]()
  var expr = parser.parse_expr()?
    or return bad_input[AstExpr]("Expected returned expression.")
  parsed(AstExpr.return_(AstReturn { keyword, value = expr.put_on_heap() }))
}

fun parse_try_scope(parser: &Parser): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("try") or return no_match[AstExpr]()
  var body = parser.parse_expr()?
    or return bad_input[AstExpr]("Expected an expression to try")
  parsed(AstExpr.try_scope(AstTryScope { keyword, body = body.put_on_heap() }))
}

fun parse_expr_suffix_member(
  parser: &Parser, current: AstExpr,
): Result[Maybe[AstExpr], Str] {
  var dot = parser.consume_prefix(".") or return no_match[AstExpr]()
  if parser.consume_prefix("*") is some(star) then
    return parsed(current.member(star))
  if parser.consume_prefix("&") is some(ampersand) then
    return parsed(current.member(ampersand))
  if parser.parse_lower_name() is some(name) then
    return parsed(current.member(name))
  if parser.parse_str_parts()? is some(parts) then return {
    var block = vec[AstExpr]()
    block.&.push(var_("$str" @ dot.src, current))
    for part in parts do
      block.&.push(AstExpr.name("$str" @ dot.src)
        .member("write" @ dot.src)
        .call(vec(part), "(" @ dot.src))
    parsed(AstExpr.block(block))
  }
  return bad_input[AstExpr]("Expected the name of a member.")
}

fun parse_expr_suffix_call(
  parser: &Parser, current: AstExpr,
): Result[Maybe[AstExpr], Str] {
  var type_args = parser.parse_type_args()?
  var opening_parenthesis = parser.consume_prefix("(")
    or return switch type_args
      case some bad_input[AstExpr]("Expected an opening parenthesis.")
      case none no_match[AstExpr]()
  var args = vec[AstExpr]()
  loop {
    args.&.push(parser.parse_expr()? or break)
    parser.consume_prefix(",") or break
  }
  parser.consume_prefix(")") or return bad_input[AstExpr](
    "Expected closing parenthesis of the call. Args: {args.len}")
  parsed(current.call(type_args, args, opening_parenthesis))
}

fun parse_expr_suffix_operator(
  parser: &Parser, current: AstExpr,
): Result[Maybe[AstExpr], Str] {
  var operator = parser.parse_operator_name() or return no_match[AstExpr]()
  var value = parser.parse_expr(Precedence.immediate)?
    or return bad_input[AstExpr](
      "Expected an expression on the right side of the operator.")
  parsed(AstExpr.name(operator)
    .call(none[Vec[Type]](), vec(current, value), operator))
}

fun parse_expr_suffix_assign(
  parser: &Parser, current: AstExpr,
): Result[Maybe[AstExpr], Str] {
  var equal_sign = parser.consume_prefix("=") or return no_match[AstExpr]()
  var value = parser.parse_expr()? or return bad_input[AstExpr](
    "Expected an expression on the right side of the assign.")
  parsed(AstExpr.assign(AstAssign {
    to = current.put_on_heap(),
    value = value.put_on_heap(),
    equal_sign,
  }))
}

fun parse_expr_suffix_is(
  parser: &Parser, current: AstExpr,
): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("is") or return no_match[AstExpr]()
  var variant = parser.parse_lower_name()
    or return bad_input[AstExpr]("Expected a variant.")
  parsed(AstExpr.switch_(AstSwitch {
    keyword,
    value = current.put_on_heap(),
    cases = vec(AstCase {
      variant, binding = none[AstStr](),
      body = AstExpr.name("true" @ keyword.src)
    }),
    default_ = some(AstDefaultCase {
      keyword = "default" @ keyword.src,
      body = AstExpr.name("false" @ keyword.src),
    }.put_on_heap()),
  }))
}

fun parse_expr_suffix_and(
  parser: &Parser, current: AstExpr,
): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("and") or return no_match[AstExpr]()
  var alternative = parser.parse_expr(Precedence.and)?
    or return bad_input[AstExpr]("Expected alternative after and.")
  parsed(AstExpr.switch_(AstSwitch {
    keyword,
    value = current.member(keyword).call("(" @ keyword.src).put_on_heap(),
    cases = vec(
      AstCase {
        variant = "short_circuit" @ keyword.src,
        binding = some("$primary" @ keyword.src),
        body = AstExpr.name("$primary" @ keyword.src),
      },
      AstCase {
        variant = "evaluate_alternative" @ keyword.src,
        binding = none[AstStr](),
        body = alternative,
      },
    ),
    default_ = none[&AstDefaultCase](),
  }))
}

fun parse_expr_suffix_or(
  parser: &Parser, current: AstExpr,
): Result[Maybe[AstExpr], Str] {
  var keyword = parser.consume_keyword("or") or return no_match[AstExpr]()
  var binding = if parser.consume_prefix("(") is some then {
    var name = parser.parse_lower_name()
    parser.consume_prefix(")") or return bad_input[AstExpr](
      "Expected closing parenthesis after or binding.")
    some(name)
  } else none[AstStr]()
  var alternative = parser.parse_expr(Precedence.or)?
    or return bad_input[AstExpr]("Expected alternative after or.")
  parsed(AstExpr.switch_(AstSwitch {
    keyword,
    value = current.member(keyword).call("(" @ keyword.src).put_on_heap(),
    cases = vec(
      AstCase {
        variant = "short_circuit" @ keyword.src,
        binding = some("$primary" @ keyword.src),
        body = AstExpr.name("$primary" @ keyword.src),
      },
      AstCase {
        variant = "evaluate_alternative" @ keyword.src,
        binding,
        body = alternative,
      },
    ),
    default_ = none[&AstDefaultCase](),
  }))
}

fun parse_expr_suffix_try(
  parser: &Parser, current: AstExpr,
): Result[Maybe[AstExpr], Str] {
  var question_mark = parser.consume_prefix("?")
    or return no_match[AstExpr]()
  parsed(AstExpr.try(AstTry { question_mark, value = current.put_on_heap() }))
}

fun parse_asm_name(parser: &Parser): Maybe[AstStr] {
  parser.consume_whitespace()
  var span =
  if parser.consume_prefix("\"") is some then {
    var start = parser.cursor
    loop if parser.current() == #" then break else parser.advance()
    var end = parser.cursor
    parser.advance()
    start..end
  } else {
    var start = parser.cursor
    loop {
      var c = parser.current()
      if c.is_whitespace() / {c == #:} / {c == #}}
      then break
      else parser.advance()
    }
    var end = parser.cursor
    start..end
  }
  if span.is_empty() then return none[AstStr]()
  some(parser.code.substr(span) @ src(parser.file, span))
}
fun parse_reg(parser: &Parser): Result[Reg, Str] {
  var name = {parser.parse_asm_name()
    or return error[Reg, Str]("Expected a register.")}.str
  if name == "sp" then return ok[Reg, Str](Reg.sp)
  if name == "st" then return ok[Reg, Str](Reg.st)
  if name == "a" then return ok[Reg, Str](Reg.a)
  if name == "b" then return ok[Reg, Str](Reg.b)
  if name == "c" then return ok[Reg, Str](Reg.c)
  if name == "d" then return ok[Reg, Str](Reg.d)
  if name == "e" then return ok[Reg, Str](Reg.e)
  if name == "f" then return ok[Reg, Str](Reg.f)
  error[Reg, Str]("Expected a register.")
}
fun parse_regs(parser: &Parser): Result[RegAndReg, Str] {
  var first  = parser.parse_reg()?
  var second = parser.parse_reg()?
  ok[RegAndReg, Str](first & second)
}

fun parse_asm_str(parser: &Parser): Result[Str, Str] {
  parser.consume_prefix("\"") or return error[Str, Str]("Expected string.")
  var start = parser.cursor
  loop if parser.current() == #" then break else parser.advance()
  parser.advance()
  ok[Str, Str](parser.code.substr(start..{parser.cursor - 1}))
}

fun parse_asm_num(parser: &Parser): Result[Int, Str] {
  if parser.consume_prefix("0b") is some then
    return ok[Int, Str](parser.parse_digits(2)?
      or return error[Int, Str]("Expected a binary number."))
  if parser.consume_prefix("0x") is some then
    return ok[Int, Str](parser.parse_digits(16)?
      or return error[Int, Str]("Expected a hexadecimal number."))
  ok[Int, Str](parser.parse_digits(10)?
    or return error[Int, Str]("Expected a number."))
}
fun parse_asm_word(parser: &Parser): Result[Word, Str] {
  parser.consume_whitespace()
  if {#0..=#9}.contains(parser.current()) then
    return ok[Word, Str](Word.literal(parser.parse_asm_num()?))
  if parser.current() == #" then
    return ok[Word, Str](Word.str(parser.parse_asm_str()?))
  ok[Word, Str](Word.label(parser.parse_asm_name()
    or return error[Word, Str]("Expected a number, string, or label.")))
}
fun parse_asm_byte(parser: &Parser): Result[Byte, Str] {
  var num = parser.parse_asm_num()?
  if num >= 256 then return error[Byte, Str]("Number doesn't fit in a byte.")
  ok[Byte, Str](num.lower_byte())
}

fun parse_instruction(parser: &Parser): Result[Maybe[AstInstr], Str] {
  var name = parser.parse_asm_name() or return no_match[AstInstr]()
  if parser.consume_prefix(":") is some then
    return parsed(AstInstr {
      kind = AstInstrKind.label(name), mnemonic = name
    })
  var kind = {
    var name = name.str
    if name == "nop" then AstInstrKind.nop
    else if name == "panic" then AstInstrKind.panic
    else if name == "move" then AstInstrKind.move(parser.parse_regs()?)
    else if name == "movei" then AstInstrKind.movei(
      parser.parse_reg()? & parser.parse_asm_word()?)
    else if name == "moveib" then AstInstrKind.moveib(
      parser.parse_reg()? & parser.parse_asm_byte()?)
    else if name == "load" then AstInstrKind.load(parser.parse_regs()?)
    else if name == "loadb" then AstInstrKind.loadb(parser.parse_regs()?)
    else if name == "store" then AstInstrKind.store(parser.parse_regs()?)
    else if name == "storeb" then AstInstrKind.storeb(parser.parse_regs()?)
    else if name == "push" then AstInstrKind.push(parser.parse_reg()?)
    else if name == "pop" then AstInstrKind.pop(parser.parse_reg()?)
    else if name == "jump" then AstInstrKind.jump(
      parser.parse_asm_name() or return bad_input[AstInstr](
        "Expected a label to jump to."))
    else if name == "cjump" then AstInstrKind.cjump(
      parser.parse_asm_name() or return bad_input[AstInstr](
        "Expected a label to cjump to."))
    else if name == "call" then AstInstrKind.call(
      parser.parse_asm_name() or return bad_input[AstInstr](
        "Expected a label to call."))
    else if name == "ret" then AstInstrKind.ret
    else if name == "syscall" then AstInstrKind.syscall(
      parser.parse_asm_byte()?)
    else if name == "cmp" then AstInstrKind.cmp(parser.parse_regs()?)
    else if name == "isequal" then AstInstrKind.isequal
    else if name == "isless" then AstInstrKind.isless
    else if name == "isgreater" then AstInstrKind.isgreater
    else if name == "islessequal" then AstInstrKind.islessequal
    else if name == "isgreaterequal" then AstInstrKind.isgreaterequal
    else if name == "isnotequal" then AstInstrKind.isnotequal
    else if name == "fcmp" then AstInstrKind.fcmp(parser.parse_regs()?)
    else if name == "fisequal" then AstInstrKind.fisequal
    else if name == "fisless" then AstInstrKind.fisless
    else if name == "fisgreater" then AstInstrKind.fisgreater
    else if name == "fislessequal" then AstInstrKind.fislessequal
    else if name == "fisgreaterequal" then AstInstrKind.fisgreaterequal
    else if name == "fisnotequal" then AstInstrKind.fisnotequal
    else if name == "inttofloat" then AstInstrKind.inttofloat(
        parser.parse_reg()?)
    else if name == "floattoint" then AstInstrKind.floattoint(
        parser.parse_reg()?)
    else if name == "add" then AstInstrKind.add(parser.parse_regs()?)
    else if name == "sub" then AstInstrKind.sub(parser.parse_regs()?)
    else if name == "mul" then AstInstrKind.mul(parser.parse_regs()?)
    else if name == "div" then AstInstrKind.div(parser.parse_regs()?)
    else if name == "rem" then AstInstrKind.rem(parser.parse_regs()?)
    else if name == "fadd" then AstInstrKind.fadd(parser.parse_regs()?)
    else if name == "fsub" then AstInstrKind.fsub(parser.parse_regs()?)
    else if name == "fmul" then AstInstrKind.fmul(parser.parse_regs()?)
    else if name == "fdiv" then AstInstrKind.fdiv(parser.parse_regs()?)
    else if name == "and" then AstInstrKind.and(parser.parse_regs()?)
    else if name == "or" then AstInstrKind.or(parser.parse_regs()?)
    else if name == "xor" then AstInstrKind.xor(parser.parse_regs()?)
    else if name == "negate" then AstInstrKind.negate(parser.parse_reg()?)
    else return bad_input[AstInstr]("Unknown instruction {name}.")
  }
  parsed(AstInstr { kind, mnemonic = name })
}

fun parse_fun(parser: &Parser): Result[Maybe[AstFun], Str] {
  var is_fallback = parser.consume_keyword("fallback") is some
  parser.consume_keyword("fun")
    or return if is_fallback
      then bad_input[AstFun]("Expected a fun keyword after fallback.")
      else no_match[AstFun]()
  var fun_name = parser.parse_lower_name()
    or parser.parse_operator_name()
    or return bad_input[AstFun]("
      'Expected a lowercase name or operator name of the function.")
  var type_args = parser.parse_type_params()? or vec[AstStr]()
  var args = vec[AstFunArg]()
  parser.consume_prefix("(")
    or return bad_input[AstFun]("Expected an opening parenthesis.")
  loop {
    var name = parser.parse_lower_name() or break
    parser.consume_prefix(":")
      or return bad_input[AstFun]("Expected a colon.")
    var type = parser.parse_type()?
      or return bad_input[AstFun]("Expected the type of the argument.")
    args.&.push(AstFunArg { name, type })
    parser.consume_prefix(",") or break
  }
  parser.consume_prefix(")")
    or return bad_input[AstFun](
      "Expected a parameter or closing parenthesis.")
  var returns = type("Nothing")
  if parser.consume_prefix(":") is some then
    returns = parser.parse_type()?
      or return bad_input[AstFun]("Expected the return type.")
  var kind =
    if parser.consume_prefix("\{ ... }") is some(dots) then
      AstFunKind.builtin(AstBuiltinDots { dots })
    else if parser.consume_prefix("asm \{") is some then {
      var instructions = vec[AstInstr]()
      loop instructions.&.push(parser.parse_instruction()? or break)
      parser.consume_prefix("}") or return bad_input[AstFun](
        "Expected an instruction or closing brace.")
      AstFunKind.asm_(instructions)
    }
    else if parser.parse_block()? is some(block) then AstFunKind.body(block)
    else return bad_input[AstFun]("Expected a function body.")
  parsed(AstFun {
    name = fun_name, is_fallback, type_args, args, returns, kind
  })
}

fun parse_opaque(parser: &Parser): Result[Maybe[AstOpaqueType], Str] {
  parser.consume_keyword("opaque") or return no_match[AstOpaqueType]()
  var name = parser.parse_upper_name()
    or return bad_input[AstOpaqueType]("Expected an uppercase name.")
  parser.consume_prefix("=")
    or return bad_input[AstOpaqueType]("Expected an equals sign.")
  var size = parser.parse_bytes_amount("size")? or unreachable()
  parser.consume_prefix("big")
    or return bad_input[AstOpaqueType]("Expected \"big\".")
  parser.consume_prefix(",")
    or return bad_input[AstOpaqueType]("Expected comma.")
  var alignment = parser.parse_bytes_amount("alignment")? or unreachable()
  parser.consume_prefix("aligned")
    or return bad_input[AstOpaqueType]("Expected \"aligned\".")
  parsed(AstOpaqueType { name, size, alignment })
}
fun parse_bytes_amount(parser: &Parser, name: Str): Result[Maybe[Int], Str] {
  parser.consume_whitespace()
  var amount = parser.parse_digits(10)?
    or return bad_input[Int]("Expected {name}.")
  if amount == 1
  then parser.consume_prefix("byte")
    or return bad_input[Int]("Expected \"byte\".")
  else parser.consume_prefix("bytes")
    or return bad_input[Int]("Expected \"bytes\".")
  parsed(amount)
}

fun parse_struct(parser: &Parser): Result[Maybe[AstStruct], Str] {
  parser.consume_keyword("struct") or return no_match[AstStruct]()
  var name = parser.parse_upper_name()
    or return bad_input[AstStruct]("Expected an uppercase name.")
  var type_args = parser.parse_type_params()? or vec[AstStr]()
  parser.consume_prefix("\{")
    or return bad_input[AstStruct]("Expected an opening brace.")
  var fields = vec[AstStructField]()
  loop {
    var field_name = parser.parse_lower_name() or break
    parser.consume_prefix(":")
      or return bad_input[AstStruct]("Expected a colon.")
    var field_type = parser.parse_type()?
      or return bad_input[AstStruct]("Expected the type of the field.")
    fields.&.push(AstStructField { name = field_name, type = field_type })
    parser.consume_prefix(",") or break
  }
  parser.consume_prefix("}") or return bad_input[AstStruct](
    "Expected a closing brace to end the struct.")
  parsed(AstStruct { name, type_args, fields })
}

fun parse_enum(parser: &Parser): Result[Maybe[AstEnum], Str] {
  parser.consume_keyword("enum") or return no_match[AstEnum]()
  var name = parser.parse_upper_name()
    or return bad_input[AstEnum]("Expected an uppercase name.")
  var type_args = parser.parse_type_params()? or vec[AstStr]()
  parser.consume_prefix("\{")
    or return bad_input[AstEnum]("Expected an opening brace.")
  var variants = vec[AstEnumVariant]()
  loop {
    var variant_name = parser.parse_lower_name() or break
    var variant_type = type("Nothing")
    if parser.consume_prefix(":") is some then
      variant_type = parser.parse_type()?
        or return bad_input[AstEnum]("Expected the type of the variant.")
    variants.&.push(AstEnumVariant { name = variant_name, type = variant_type })
    parser.consume_prefix(",") or break
  }
  parser.consume_prefix("}") or return bad_input[AstEnum](
    "Expected a closing brace to end the enum.")
  parsed(AstEnum { name, type_args, variants })
}

fun parse_def(parser: &Parser): Result[Maybe[AstDef], Str] {
  if parser.parse_opaque()? is some(opq) then return parsed(AstDef.opaque_(opq))
  if parser.parse_struct()? is some(st) then return parsed(AstDef.struct_(st))
  if parser.parse_enum()? is some(enum_) then return parsed(AstDef.enum_(enum_))
  if parser.parse_var()? is some(var_) then return parsed(AstDef.var_(var_))
  if parser.parse_fun()? is some(fun_) then return parsed(AstDef.fun_(fun_))
  no_match[AstDef]()
}
fun parse_defs(parser: &Parser): Result[Vec[AstDef], Str] {
  var defs = vec[AstDef]()
  loop defs.&.push(parser.parse_def()? or break)
  if parser.current() != null_char then
    return error[Vec[AstDef], Str]("Expected a definition.")
  ok[Vec[AstDef], Str](defs)
}

fun parse_import(parser: &Parser): Result[Maybe[AstStr], Str] {
  parser.consume_keyword("import") or return no_match[AstStr]()
  | The imported thing goes until the end of the line.
  var start = parser.cursor
  loop {
    if parser.cursor >= parser.code.len then break
    if parser.current() == newline then break
    parser.cursor = parser.cursor + 1
  }
  var end = parser.cursor
  | Trim it.
  loop if start < end and parser.code.get(start).is_whitespace()
    then start = start + 1
    else break
  loop if end > start and parser.code.get(end - 1).is_whitespace()
    then end = end - 1
    else break
  if start == end then
    return bad_input[AstStr]("Expected an import (a file path).")
  parsed(AstStr {
    src = src(parser.file, start..end),
    str = parser.code.substr(start..end),
  })
}
fun parse_imports(parser: &Parser): Result[Vec[AstStr], Str] {
  var imports = vec[AstStr]()
  loop imports.&.push(parser.parse_import()? or break)
  ok[Vec[AstStr], Str](imports)
}

fun parse_single_file(input: Str, file: Str): Result[FileAst, Error] {
  var parser = parser(file, input)
  var imports = parser.&.parse_imports()
    or(error) return error[FileAst, Error](make_error(
      src(file, parser.cursor..{parser.cursor + 1}), error))
  var defs = parser.&.parse_defs()
    or(error) return error[FileAst, Error](make_error(
      src(file, parser.cursor..{parser.cursor + 1}), error))
  ok[FileAst, Error](FileAst { imports, defs })
}

| Joining Asts From Multiple Files  
| Multiple FileAsts are joined into a single Ast. While we do that, we make the
| lookup of methods and variables simpler by putting everything into a map with
| the name as the key. Thus, the Ast no longer contains an ordering of
| defintions.
| This is also an opportunity to validate the general signatures of definitions
| – in the first revisions of Martinaise, you could define a function foo(Foo),
| even if no Foo type exists. The function would simply match no call, so
| everything's fine. This practice is almost always not the intended behavior,
| so there are some checks here.

struct Ast {
  types: Map[Str, AstType],
  globals: Map[Str, AstVar],
  funs: Map[Str, Vec[AstFun]],
}
enum AstType { opaque_: AstOpaqueType, struct_: AstStruct, enum_: AstEnum }

fun write[W](writer: W, ast: Ast) {
  for type in ast.types do writer."{type.value}\n"
  for global in ast.globals do writer."{global.value}\n"
  for funs in ast.funs do for f in funs.value do writer."{f}\n"
}
fun write[W](writer: W, type: AstType) {
  switch type
  case opaque_(o) writer."{o}"
  case struct_(s) writer."{s}"
  case enum_(e) writer."{e}"
}

fun src(type: AstType): Src {
  switch type
  case opaque_(type) type.name.src
  case struct_(type) type.name.src
  case enum_(type) type.name.src
}

fun parse_file_and_dependencies(
  out: &Map[Str, FileAst], file: Str, parent_import: Maybe[AstStr],
): Result[Nothing, Error] {
  if out.contains(file) then return ok[Nothing, Error]({})

  print_status("Reading {file}")
  var content = read_code(file)
    or(error) return error[Nothing, Error](make_error(
      switch parent_import
        case some(import_) import_.src
        case none src(file, 0..0),
      "Couldn't read {file}: {error}"
    ))

  print_status("Parsing {file}")
  var ast = content.parse_single_file(file)?
  out.put(file, ast)

  | eprintln("Imports:")
  | for import in ast.imports do eprintln("- {import.str}")

  for import_ in ast.imports do
    parse_file_and_dependencies(
      out,
      file.relative_import(import_.str),
      some(import_)
    )?

  ok[Nothing, Error]({})
}
| Resolves the path relative to the base.
| "/foo/tour.mar".relative_import("stdin.mar") -> "/foo/stdin.mar"
| "hey.mar".relative_import("../foo.mar") -> "../foo.mar"
fun relative_import(base: Str, path: Str): Str {
  if path.starts_with("/") then return path
  base = base.remove_last_component()
  | We could just return "{base}/{path}", but that results in un-canonical
  | paths such as "foo/bar/../baz.mar". So, each "../" at the beginning of the
  | path cancels out the last component of the base.
  loop {
    if base.is_empty() then return path
    if path.starts_with("../") then {
      base = base.remove_last_component()
      path = path.without_first(3)
      continue
    }
    break
  }
  "{base}/{path}"
}
fun remove_last_component(path: Str): Str {
  var end = path.len
  loop {
    if end == 0 then break
    if path.get(end - 1) == #/ then { end = end - 1 break }
    end = end - 1
  }
  path.substr(0..end)
}

fun parse_project(entry_file: Str): Result[Ast, Error] {
  var asts = map[Str, FileAst]()

  | Reference types such as &T are type-checked just like any other types. For
  | this to work, we create an implicitly imported file with this struct:
  | struct &[T] { *: T }
  var ref_file = "_ref"
  var invalid_location = src(ref_file, 0..0)
  asts.&.put("_ref", FileAst {
    imports = vec[AstStr](),
    defs = vec(AstDef.struct_(AstStruct {
      name = "&" @ invalid_location,
      type_args = vec("T" @ invalid_location),
      fields = vec(AstStructField {
        name = "*" @ invalid_location, type = type("T")
      }),
    }))
  })

  asts.&.parse_file_and_dependencies(entry_file, none[AstStr]())?

  var types = map[Str, AstType]()
  var globals = map[Str, AstVar]()
  var funs = map[Str, Vec[AstFun]]()

  for ast in asts do {
    for def in ast.value.defs do {
      switch def
      case opaque_(opaque_) {
        if types.contains(opaque_.name.str) then return error[Ast, Error](
          conflicting_names_error("types", opaque_.name))
        types.&.put(opaque_.name.str, AstType.opaque_(opaque_))
      }
      case struct_(struct_) {
        if types.contains(struct_.name.str) then return error[Ast, Error](
          conflicting_names_error("types", struct_.name))
        types.&.put(struct_.name.str, AstType.struct_(struct_))
      }
      case enum_(enum_) {
        if types.contains(enum_.name.str) then return error[Ast, Error](
          conflicting_names_error("types", enum_.name))
        types.&.put(enum_.name.str, AstType.enum_(enum_))
      }
      case var_(global) {
        if globals.contains(global.name.str) then return error[Ast, Error](
          conflicting_names_error("global variables", global.name))
        globals.&.put(global.name.str, global)
      }
      case fun_(fun_)
        if funs.contains(fun_.name.str)
        then {
          | TODO: update once there exists Map.get_ref
          var overloads = funs.get(fun_.name.str)
          overloads.&.push(fun_)
          funs.&.put(fun_.name.str, overloads)
        }
        else funs.&.put(fun_.name.str, vec(fun_))
    }
  }

  for type in types do
    switch type.value
    case opaque_ {
      | TODO: check that alignment is 1, 2, 4, or 8
    }
    case struct_(struct_) {
      for arg in struct_.type_args do
        if arg.str.exists(types, vec[AstStr]()) then return error[Ast, Error](
          concrete_type_used_as_arg_error(struct_.name, arg))
      for field in struct_.fields do
        if field.type.exists(types, struct_.type_args) is error(type) then
          return error[Ast, Error](type_doesnt_exist_error(struct_.name, type))
    }
    case enum_(enum_) {
      for arg in enum_.type_args do
        if arg.str.exists(types, vec[AstStr]()) then return error[Ast, Error](
          concrete_type_used_as_arg_error(enum_.name, arg))
      for variant in enum_.variants do
        if variant.type.exists(types, enum_.type_args) is error(type) then
          return error[Ast, Error](type_doesnt_exist_error(enum_.name, type))
    }

  for funs in funs do
    for fun_ in funs.value do {
      for arg in fun_.type_args do
        if arg.str.exists(types, vec[AstStr]()) then return error[Ast, Error](
          concrete_type_used_as_arg_error(fun_.name, arg))
      for arg in fun_.args do
        if arg.type.exists(types, fun_.type_args) is error(type) then
          return error[Ast, Error](type_doesnt_exist_error(fun_.name, type))
    }

  ok[Ast, Error](Ast { types, globals, funs })
}

| Checks if the type exists.
| TODO: This is a horrible name for a function that doesn't return a Bool.
fun exists(
  type: Type, types: Map[Str, AstType], extra: Vec[AstStr],
): Result[Nothing, Str] {
  if not(type.name.exists(types, extra))
  then return error[Nothing, Str](type.name)
  for arg in type.args do arg.exists(types, extra)?
  ok[Nothing, Str]({})
}
fun exists(type: Str, types: Map[Str, AstType], extra: Vec[AstStr]): Bool {
  if types.contains(type) then true else {
    for extra in extra do if extra.str == type then return true
    false
  }
}

fun conflicting_names_error(group: Str, name: AstStr): Error {
  make_error(
    name.src,
    "Multiple {group} are named \"{name}\".",
    "All {group} need to have different names.",
  )
}
fun concrete_type_used_as_arg_error(who: AstStr, arg: AstStr): Error {
  make_error(
    who.src,
    "{who} uses {arg} as a type argument, but it's also a concrete type.",
    "Type arguments can't be named like concrete types.",
  )
}
fun type_doesnt_exist_error(who: AstStr, type: Str): Error {
  make_error(
    who.src, "{who} refers to {type}, but that type doesn't exist."
  )
}

| Type Sinks  
| At some places in the code, types need to "line up". Because of the Never
| type, this is less strict that type equality. Take this code for example:
|
| var a = if condition then 3 else return 4
|
| Even though both branches of the if have different types (Int and Never), they
| still line up properly to a final Int type. Type sinks are a way to ensure
| multiple expressions evaluate to the same type.

struct TypeSink { current: Maybe[Type] }

fun type_sink(): TypeSink { TypeSink { current = none[Type]() } }
fun type_sink(type: Type): TypeSink { TypeSink { current = some(type) } }

fun add(sink: &TypeSink, type: Type): Result[Nothing, Str] {
  if type.is_never() then return ok[Nothing, Str]({})
  switch sink.current
  case none {
    sink.current = some(type)
    ok[Nothing, Str]({})
  }
  case some(current) {
    switch merge(current, type)
    case some(merged) {
      sink.current = some(merged)
      ok[Nothing, Str]({})
    }
    case none return error[Nothing, Str]("
      ' expected: {current}\n
      '   actual: {type}")
  }
}
| Merges potentially incomplete types. For example, Maybe[A, _] and Maybe[_, B]
| would get merged to Maybe[A, B].
fun merge(a: Type, b: Type): Maybe[Type] {
  if a.name == "_" then return some(b)
  if b.name == "_" then return some(a)
  if a.name != b.name then return none[Type]()
  if a.args.len != b.args.len then return none[Type]()
  var merged_args = vec[Type]()
  for i in 0..a.args.len do
    switch merge(a.args.get(i), b.args.get(i))
    case none return none[Type]()
    case some(type) merged_args.&.push(type)
  some(type(a.name, merged_args))
}
fun finish(sink: TypeSink): Type { sink.current.unwrap("type sink failed") }

| Type Solving  
| When compiling generic code, the free type variables need to be bound to
| concrete types. For example, to compile a function foo[A](), we need to know
| what A is. For each specific A that foo is used with, a new version gets
| compiled. Type parameters such as A can also be inferred:
|
| fun foo[A](a: Foo[A], b: A) { ... }
| fun foo[A](a: A, b: A) { ... }
|
| foo(Foo[Int], Int)
|
| When compiling the call, the Martinaise compiler figures out to use the first
| function with A = Int. It uses the TypeSolver for that. Here's how to use it:
|
| 1. Create a TypeSolver, passing all type variables that need to be bound.
|    In the example above, that would be A.
| 2. Repeatedly call unify with the generic type and the concrete types of the
|    usage site.
|    - For calls, unify all arguments.
|    - For struct creations, unify all fields.
|    - For enum creations, unify the argument.
|    In the example above, we call unify(Foo[A], Foo[Int]) and unify(A, Int).
| 3. Call finish. This ensures that no type variables are unbound and it returns
|    a type environment (a Map[Str, Type]) that maps the generic type parameters
|    to concrete types. It can be used to specialize the generic code to the
|    usage site.
|    In the example above, the resulting type environment would be {A: Int}.

struct TypeSolver { vars: Set[Str], env: Map[Str, Type] }

fun create_type_solver(vars_: Vec[AstStr]): TypeSolver {
  | TODO: make sure each type var only exists once
  var vars = set[Str]()
  for var_ in vars_ do vars.&.put(var_.str)
  TypeSolver { vars, env = map[Str, Type]() }
}
| Calling this function adds the constraint that `concrete` needs to be
| assignable to `generic`. Returns whether that works.
fun unify(
  solver: &TypeSolver, generic: Type, concrete: Type,
): Result[Bool, Str] {
  | Under type env {A: Int}, is Str assignable to A? Depends on whether Str is
  | assignable to Int.
  if solver.env.get_maybe(generic.name) is some(mapped) then {
    if generic.args.is_not_empty() then
      return error[Bool, Str]("Generics can't have type arguments.")
    if solver.vars.contains(mapped.name) then
      panic("mapped generic can't be in solver vars")
    return solver.unify(mapped, concrete)
  }

  if solver.vars.contains(generic.name) then {
    solver.env.&.put(generic.name, concrete)
    return ok[Bool, Str](true)
  }

  generic.name == concrete.name or return ok[Bool, Str](false)
  generic.args.len == concrete.args.len or return ok[Bool, Str](false)
  for zip in zip(generic.args.iter(), concrete.args.iter()) do
    solver.unify(zip.a, zip.b)? or return ok[Bool, Str](false)

  ok[Bool, Str](true)
}
fun finish(solver: TypeSolver): Result[Map[Str, Type], Str] {
  for var_ in solver.vars do
    if not(solver.env.contains(var_)) then return error[Map[Str, Type], Str]({
      var out = string_builder().&
      if solver.env.size > 0 then {
        out."These type variables are bound:\n"
        for entry in solver.env do out." - {entry.key} = {entry.value}\n"
      }
      out."The type variable {var_} is unbound."
      out.to_str()
    })

  ok[Map[Str, Type], Str](solver.env)
}

| Tracking Variables That Are In Scope  
| In Martinaise, variable shadowing is allowed – you can create a new variable
| with the same name as an existing one, whether in the same scope or an inner
| scope.
| Initially, information about which variables are in scope were stored in a
| hash map. Unfortunately, managing nested scopes gets difficult or inefficient
| pretty quickly.
| In Candy, we just dealt with this problem using some fancy new thing (tm). In
| our case, this is an immutable hash map from the "im" Rust crate – a hash map
| where inserting values returns a new hash map instead. The resulting hash maps
| share a lot of the data internally, so memory usage is not too bad. Still,
| we're creating heap-allocated pointer-linked nodes all over the place.
| Martinaise uses a much simpler approach: When new variables are defined, they
| are just appended to a vector. When entering scopes, we remember the length of
| the vector and we truncate it to that length when we exit the scope. For
| variable lookups, we walk the vec in reverse. Here's an example:
|
| var foo = 2
| var bar = 3
| var baz = {
|   var foo = foo + 1
|   bar = bar - 1
|   foo * 2
| }
|
| ┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐
| │ foo = 2 │ (1) │ foo = 2 │ (2) │ foo = 2 │ (3) │ foo = 2 │ (4) │ foo = 2 │
| ├─────────┤     ├─────────┤     ├─────────┤     ├─────────┤     ├─────────┤
| │ bar = 3 │     │ bar = 3 │     │ bar = 2 │     │ bar = 3 │     │ bar = 3 │
| └─────────┘     ├─────────┤     ├─────────┤     └─────────┘     ├─────────┤
|                 │ foo = 3 │     │ foo = 3 │                     │ baz = 6 │
|                 └─────────┘     └─────────┘                     └─────────┘
|
| 1. When entering the baz scope, foo and bar are already defined. Because we
|    enter a scope, we remember the length of the variable vector (length 2).
|    The definition of foo inside the baz scope gets appended to the vector.
| 2. When accessing variables, we walk the vector from the end to the beginning.
|    "foo" accesses the foo from the inner scope, "bar" accesses the bar from
|    the outer scope. Here, bar is changed to a new value.
| 3. When exiting a scope, we truncate the vector to the length we remembered
|    (length 2). The newly defined foo goes out of scope.
| 4. New definitions are again just appended to the vector.
|
| You might think that doing a linear search on a vector is horribly
| inefficient. Thankfully, some aspects of this problem make this not-so-bad in
| practice:
|
| - Variable scopes tend to be small. Variables are local to a function, so they
|   are limited by the function length.
| - Martinaise makes it easy to start new scopes to avoid cluttering the
|   surrounding namespace. This makes the number of variables in a scope even
|   smaller.
| - You tend to use recently defined variables more often. As a result, walking
|   the vector is often pretty slow.
| - Computers are super fast. Linearly scanning through memory is one of the
|   fastest memory access patterns you can have, unlike traversing down nodes of
|   a hash map.

struct Vars[T] { visible: Vec[VarInScope[T]] }
struct VarInScope[T] { name: Str, data: T }
struct VarScope { num_visible: Int }

fun vars[T](): Vars[T] { Vars { visible = vec[VarInScope[T]]() } }

fun define[T](vars: &Vars[T], name: Str, data: T) {
  vars.visible.&.push(VarInScope { name, data })
}
fun lookup[T](vars: Vars[T], name: Str): Maybe[T] {
  for var_ in vars.visible.to_slice().rev_iter() do
    if var_.name == name then return some(var_.data)
  none[T]()
}

fun snapshot[T](vars: Vars[T]): VarScope {
  VarScope { num_visible = vars.visible.len }
}
fun restore[T](vars: &Vars[T], scope: VarScope) {
  vars.visible.len = scope.num_visible
}

| Context  
| When monoing fails, we want to have backtraces – a path from the main function
| over all monoed function to the failing src. The Context tracks what the
| compiler is currently doing – it's basically a stack of function signatures.
| Each time a signature is pushed or popped, it also prints a one-line message
| to the console, something like this:
|
| Monoing main > println > print > write > write_with_radix > digit_to_char >...
|
| TODO: don't print every line, only visible changes
| TODO: debounce printing

struct Context { signatures: Vec[Str] }

fun context(): Context { Context { signatures = vec[Str]() } }

fun push(context: &Context, signature: Str) {
  context.signatures.&.push(signature)
  if not(tooling_mode) then context.print_status()
  if context.signatures.len >= 100 then {
    for signature in context.signatures do eprintln(signature)
    panic("overflow")
  }
}
fun pop(context: &Context) {
  context.signatures.&.pop()
  context.print_status()
}

fun print_status(context: Context) {
  var out = string_builder().&
  out.write("Monoing ")
  var first = true
  for signature in context.signatures do {
    if first then first = false else out.write(" > ")
    | Because we want many signatures to fit on one line, only write the
    | function name up to the first opening parenthesis or bracket.
    var i = 0
    for char in signature.iter().enumerate() do
      if {char.item == #(} / {char.item == #[} then { i = char.index break }
    out.write(signature.substr(0..i))
    if out.len() > 80 then break
  }
  if out.len() > 80 then {
    out.truncate_to_len(77)
    out.write("...")
  }
  print_status(out.to_str())
}

| Ast Lookup  

| Looks up the type with the given name. Type names have to be unique.
fun lookup_type(ast: Ast, name: Str): Result[AstType, Error] {
  switch ast.types.get_maybe(name)
  case some(match) ok[AstType, Error](match)
  case none return error[AstType, Error](
    make_error(src("todo", 0..0), {
      var sb = string_builder().&
      sb."There is no type named \"{name}\".\n"
      sb."Types:"
      for type in ast.types do
        sb."\n- {type.key}"
      sb.to_str()
    }))
}

| Looks up the global variable with the given name. Names of global variables
| have to be unique.
fun lookup_global(ast: Ast, name: Str): Maybe[AstVar] {
  ast.globals.get_maybe(name)
}

| Looks up the function with the given name, the given number of type args
| (none means they are inferred) and the args of the given types.
struct LookupFunSolution { fun_: AstFun, type_env: Map[Str, Type] }
fun lookup_fun(
  ast: Ast, name: AstStr, type_args: Maybe[Vec[Type]], arg_types: Vec[Type]
): Result[LookupFunSolution, Error] {
  var name_matches = ast.funs.get_maybe(name.str)
    or return error[LookupFunSolution, Error](
      make_error(name.src, "There are no defintions named \"{name}\"."))

  var full_matches = vec[LookupFunSolution]()
  for fun_ in name_matches do {
    var solver = create_type_solver(fun_.type_args)
    if type_args is some(type_args_) then {
      if type_args_.len != fun_.type_args.len then continue
      for i in 0..type_args_.len do
        switch solver.&
          .unify(type(fun_.type_args.get(i).str), type_args_.get(i))
        case ok(worked) worked.assert()
        case error(message) return error[LookupFunSolution, Error](
          make_error(name.src, message))
    }
    if arg_types.len != fun_.args.len then continue
    var matches = true
    for i in 0..arg_types.len do
      switch solver.&.unify(fun_.args.get(i).type, arg_types.get(i))
      case ok(works) works or { matches = false break }
      case error(message) return error[LookupFunSolution, Error](
        make_error(name.src, message))
    if not(matches) then continue
    var type_env = solver.finish()
      or(error) return error[LookupFunSolution, Error](make_error(
        name.src,
        "Found a function matching a call:\n
        '  call: {signature(name.str, type_args, arg_types)}\n
        ' match: {fun_.stripped_signature()}\n
        'However, resolving the call doesn't work:\n
        '{error}"
      ))
    full_matches.&.push(LookupFunSolution { fun_, type_env })
  }

  if full_matches.is_empty() then
    return error[LookupFunSolution, Error](make_error(
      name.src,
      "This call doesn't work.",
      {
        var out = string_builder().&
        out."
          'This is the signature:\n
          ' > {signature(name.str, type_args, arg_types)}\n"
        if name_matches.is_empty()
        then out."There are no defintions named \"{name}\"."
        else {
          out."These definitions have the same name, but arguments don't match:"
          for match in name_matches do out."\n - {match.stripped_signature()}"
        }
        out.to_str()
      }
    ))

  var non_fallback_matches = vec[LookupFunSolution]()
  var fallback_matches = vec[LookupFunSolution]()
  for match in full_matches do
    {if match.fun_.is_fallback
     then fallback_matches.&
     else non_fallback_matches.&}.push(match)

  if non_fallback_matches.len > 1 then
    return error[LookupFunSolution, Error](make_error(
      name.src,
      "This call matches multiple functions.",
      {
        var out = string_builder().&
        out."  call: {signature(name.str, type_args, arg_types)}\n"
        for match in non_fallback_matches do {
          var padded_signature = match.fun_.stripped_signature().format()
            .pad_right(30, # )
          out."\n match: {padded_signature}"
          if match.type_env.is_not_empty() then {
            out." with "
            var first = true
            for entry in match.type_env do {
              if first then first = false else out.", "
              out."{entry.key} = {entry.value}"
            }
          }
        }
        out.to_str()
      }
    ))
  if non_fallback_matches.len == 1 then
    return ok[LookupFunSolution, Error](non_fallback_matches.get(0))
  
  | There are zero non-fallback matches. Check the fallback matches.
  if fallback_matches.len > 1 then
    return error[LookupFunSolution, Error](make_error(
      name.src,
      "This call matches multiple fallback functions.",
      {
        var out = string_builder().&
        out."  call: {signature(name.str, type_args, arg_types)}\n"
        for match in fallback_matches do {
          var padded_signature = match.fun_.stripped_signature().format()
            .pad_right(30, # )
          out."\n match: {padded_signature}"
          if match.type_env.is_not_empty() then {
            out." with "
            var first = true
            for entry in match.type_env do {
              if first then first = false else out.", "
              out."{entry.key} = {entry.value}"
            }
          }
        }
        out.to_str()
      }
    ))

  | We checked above for zero matches in total. As we know that we have zero
  | non-fallback matches and <= 1 fallback matches, we know there is exactly one
  | fallback match.
  ok[LookupFunSolution, Error](fallback_matches.get(0))
}

| Mono  
| Generic code such as a function foo[T]() doesn't have any generic form in the
| final output. Instead, for each place where foo is called (each "callsite"), a
| new version of foo gets compiled. This process (called "monomorphization")
| enables useful programming patterns. For example, just by writing a compare_to
| function for a type, you can automatically use all other comparison functions.
| Generally speaking, monoed code also tends to be faster than general code.
|
| The Mono is the next stage in the compiler. Here, functions and types are
| monoed (aka they are made to be not generic anymore). Only the functions and
| types that are reachable from the main function appear here – everything else
| is ignored. While the Ast may contain invalid code (like 3 = 1), the Mono is
| guaranteed to be correct – during monoing, variable scoping, name lookups, and
| type checking take place.
|
| Functions in the Mono are way simpler than Ast functions in another way: They
| are linear, only containing slots for local variables and instructions that
| may jump to each other.
|
| Take this AST function:
|
| fun foo(a: Bool) {
|   var foo =
|     if condition
|     then 2
|     else 3
|   foo + 1
| }
|
| In the Mono, it looks something like this:
|
| fun foo(a: Bool) {
|   slot_0: Bool = arg 0
|   slot_1: Int = uninitialized
|   slot_2: Int = 2
|   slot_3: Int = 3
|   slot_4: Int = uninitialized
|   slot_5: Int = 1
|
|   label_0:
|     jump_if_variant a true label_1
|     jump label_2
|   label_1:
|     assign slot_1 = slot_2
|     jump label_3
|   label_2:
|     assign slot_1 = slot_3
|     jump label_3
|   label_3:
|     perform_call slot_4 = +(slot_1, slot_5)
|     return slot_4
| }
|
| Globals are lowered into functions that take no arguments and return the
| value of the global.

struct Mono {
  | Monomorphized type definitions.
  type_defs: Map[Type, MonoTypeDef],
  layouts: Map[Type, MemLayout],

  | Global variables. They map to a function that computes the value.
  globals: Map[Str, MonoFun],
  globals_init_order: Vec[Str],

  | Monomorphized functions. Keys are signatures such as "foo[Byte](Byte)".
  funs: Map[Str, MonoFun],
  entry_point: Str,
}

enum MonoTypeDef {
  opaque_: MonoOpaqueType,
  struct_: MonoStruct,
  enum_: MonoEnum,
}
struct MonoOpaqueType { size: Int, alignment: Int }
struct MonoStruct { fields: Vec[MonoStructField] }
struct MonoStructField { name: Str, type: Type }
struct MonoEnum { variants: Vec[MonoEnumVariant] }
struct MonoEnumVariant { name: Str, type: Type }

struct MonoFun {
  name: AstStr,
  type_args: Vec[Type],
  arg_types: Vec[Type],
  return_type: Type,
  kind: MonoFunKind,
}

enum MonoFunKind {
  body: MonoFunBody,
  asm_: Vec[AstInstr],
}
struct MonoFunBody {
  slots: Vec[MonoSlot],
  statements: Vec[MonoStatementAndSrc],
}

struct MonoSlot { type: Type, initial_value: MonoSlotValue }
enum MonoSlotValue { uninitialized, arg: Int, int: Int, float: Float, str: Str }
struct MonoSlotRef { index: Int }

struct MonoStatementAndSrc { statement: MonoStatement, src: Src }
enum MonoStatement {
  nop,
  label: MonoLabel,
  assign: MonoAssign,
  set_enum: MonoSetEnum,
  call: MonoCall,
  try_start: MonoLabel,
  try_end,
  jump: MonoJump,
  jump_if_variant: MonoJumpIfVariant,
  get_enum_value: MonoGetEnumValue,
  return_: MonoExpr,
  ref: MonoRef,
}
struct MonoLabel { id: Int }
struct MonoAssign { to: MonoExpr, value: MonoExpr }
struct MonoSetEnum { to: MonoExpr, variant: Str, payload: MonoExpr }
struct MonoCall { to: MonoExpr, fun_: Str, args: Vec[MonoExpr] }
struct MonoJump { target: MonoLabel }
struct MonoJumpIfVariant {
  condition: MonoExpr,
  variant: Str,
  target: MonoLabel,
}
struct MonoGetEnumValue { to: MonoExpr, of: MonoExpr, variant: Str }
struct MonoRef { to: MonoExpr, of: MonoExpr }

struct MonoExpr { type: Type, kind: MonoExprKind }
enum MonoExprKind {
  nothing,
  never,
  global: Str,
  slot: MonoSlotRef,
  member: MonoMember,
}
struct MonoMember { of: &MonoExpr, name: Str }

fun hash(hasher: &Hasher, slot: MonoSlotRef) { hasher.hash(slot.index) }
fun ==(a: MonoSlotRef, b: MonoSlotRef): Bool { a.index == b.index }

fun @(statement: MonoStatement, src: Src): MonoStatementAndSrc {
  MonoStatementAndSrc { statement, src }
}

fun write[W](writer: W, mono: Mono) {
  writer."Types:\n"
  | TODO: add keys and value iters to stdlib
  for entry in mono.type_defs do writer." - {entry.key}\n"

  writer."Globals:\n"
  for entry in mono.globals do
    writer." - {entry.key}: {entry.value.return_type}\n"

  writer."Funs:\n"
  for entry in mono.funs do {
    writer.write(entry.key, entry.value)
    writer.write(newline)
  }
}
fun write[W](writer: W, name: Str, fun_: MonoFun) {
  writer."{name}\n"
  switch fun_.kind
  case body(body) {
    for zip in body.slots.iter().enumerate() do {
      var index = zip.index
      var slot = zip.item
      if index > 0 then writer.write(newline)
      writer."  _{index}: {slot.type} = "
      switch slot.initial_value
      case uninitialized writer."uninitialized"
      case arg(i) writer."arg_{i}"
      case int(int) writer.write(int)
      case float(float) writer.write(float)
      case str(str) writer."\"{str}\""
    }
    for statement in body.statements do
      writer."\n  {"{statement.statement}".pad_right(40)} {statement.src}"
  }
  case asm_(code) writer.write(code)
}
fun write[W](writer: W, statement: MonoStatement) {
  switch statement
  case nop writer."nop"
  case label(label) writer."{label}:"
  case assign(assign) writer."{assign.to} = {assign.value}"
  case set_enum(set) writer."{set.to} = {set.variant}({set.payload})"
  case call(call)
    writer."{call.to} = {call.fun_} called with ({comma_separated(call.args)})"
  case try_start(catch) writer."try started, catch {catch}"
  case try_end writer."try ended"
  case jump(jump) writer."jump to {jump.target}"
  case jump_if_variant(jump)
    writer."if {jump.condition} is {jump.variant}, jump to {jump.target}"
  case get_enum_value(get) writer."{get.to} = get {get.variant} of {get.of}"
  case return_(returned) writer."return {returned}"
  case ref(expr) writer."{expr.to} = {expr.of}.&"
}
fun write[W](writer: W, label: MonoLabel) { writer.".l_{label.id}" }
fun write[W](writer: W, slot: MonoSlotRef) { writer."_{slot.index}" }
fun write[W](writer: W, expr: MonoExpr) {
  switch expr.kind
  case global(name) writer."global_{name}"
  case slot(slot) writer.write(slot)
  case member(member) writer."{member.of.*}.{member.name}"
  case nothing writer."_nothing"
  case never writer."_never"
}

| Helper for building a MonoFunBody.
struct MonoBodyBuilder {
  slots: Vec[MonoSlot],
  statements: Vec[MonoStatementAndSrc],
  context: &Context,
  ast: Ast,
  mono: &Mono,
}

fun finish(body: MonoBodyBuilder): MonoFunBody {
  MonoFunBody { slots = body.slots, statements = body.statements }
}

fun add_slot(
  body: &MonoBodyBuilder, type: Type, initial_value: MonoSlotValue
): MonoExpr {
  var ref = MonoSlotRef { index = body.slots.len }
  body.slots.&.push(MonoSlot { type, initial_value })
  MonoExpr { kind = MonoExprKind.slot(ref), type }
}
fun uninitialized(body: &MonoBodyBuilder, type: Type): MonoExpr {
  body.add_slot(type, MonoSlotValue.uninitialized)
}
fun arg(body: &MonoBodyBuilder, type: Type, index: Int): MonoExpr {
  body.add_slot(type, MonoSlotValue.arg(index))
}
fun int(body: &MonoBodyBuilder, value: Int): MonoExpr {
  body.add_slot(type("Int"), MonoSlotValue.int(value))
}
fun float(body: &MonoBodyBuilder, value: Float): MonoExpr {
  body.add_slot(type("Float"), MonoSlotValue.float(value))
}
fun str(body: &MonoBodyBuilder, value: Str): MonoExpr {
  body.add_slot(type("Str"), MonoSlotValue.str(value))
}
fun untyped_slot(body: &MonoBodyBuilder): MonoSlotRef {
  var ref = MonoSlotRef { index = body.slots.len }
  body.slots.&.push(MonoSlot {
    type = type("<placeholder>"),
    initial_value = MonoSlotValue.uninitialized,
  })
  ref
}
fun typed(body: &MonoBodyBuilder, untyped: MonoSlotRef, type: Type): MonoExpr {
  | TODO: assert that the type is not set yet or that it matches
  body.slots.get_ref(untyped.index).type = type
  MonoExpr { kind = MonoExprKind.slot(untyped), type }
}

fun add(body: &MonoBodyBuilder, statement: MonoStatementAndSrc) {
  body.statements.&.push(statement)
}
fun nop(body: &MonoBodyBuilder, src: Src) { body.add(MonoStatement.nop @ src) }
fun label(body: &MonoBodyBuilder, id: Int, src: Src) {
  body.add(MonoStatement.label(MonoLabel { id }) @ src)
}
fun assign(body: &MonoBodyBuilder, to: MonoExpr, value: MonoExpr, src: Src) {
  body.add(MonoStatement.assign(MonoAssign { to, value }) @ src)
}
fun set_enum(
  body: &MonoBodyBuilder, to: MonoExpr, variant: Str, payload: MonoExpr,
  src: Src
) {
  body.add(MonoStatement.set_enum(MonoSetEnum { to, variant, payload }) @ src)
}
fun call(
  body: &MonoBodyBuilder, to: MonoExpr, fun_: Str, args: Vec[MonoExpr], src: Src
) {
  body.add(MonoStatement.call(MonoCall { to, fun_, args }) @ src)
}
fun try_start(body: &MonoBodyBuilder, catch: MonoLabel, src: Src) {
  body.add(MonoStatement.try_start(catch) @ src)
}
fun try_end(body: &MonoBodyBuilder, src: Src) {
  body.add(MonoStatement.try_end @ src)
}
fun jump(body: &MonoBodyBuilder, target: Int, src: Src) {
  body.add(MonoStatement.jump(MonoJump {
    target = MonoLabel { id = target }
  }) @ src)
}
fun jump_if_variant(
  body: &MonoBodyBuilder, condition: MonoExpr, variant: Str, target: Int,
  src: Src
) {
  body.add(MonoStatement.jump_if_variant(MonoJumpIfVariant {
    condition, variant, target = MonoLabel { id = target }
  }) @ src)
}
fun get_enum_value(
  body: &MonoBodyBuilder, to: MonoExpr, of: MonoExpr, variant: Str, src: Src
) {
  body.add(MonoStatement.get_enum_value(MonoGetEnumValue {
    to, of, variant
  }) @ src)
}
fun return_(body: &MonoBodyBuilder, value: MonoExpr, src: Src) {
  body.add(MonoStatement.return_(value) @ src)
}
fun ref(body: &MonoBodyBuilder, to: MonoExpr, of: MonoExpr, src: Src) {
  body.add(MonoStatement.ref(MonoRef { to, of }) @ src)
}

fun jump_placeholder(body: &MonoBodyBuilder, src: Src): MonoPlaceholder {
  var index = body.statements.len
  body.jump(0, src)
  MonoPlaceholder { index }
}
fun jump_if_variant_placeholder(
  body: &MonoBodyBuilder, condition: MonoExpr, variant: Str, src: Src
): MonoPlaceholder {
  var index = body.statements.len
  body.jump_if_variant(condition, variant, 0, src)
  MonoPlaceholder { index }
}
struct MonoPlaceholder { index: Int }
fun update_target(
  body: &MonoBodyBuilder, placeholder: MonoPlaceholder, target: Int
) {
  var statement = body.statements.get_ref(placeholder.index).statement.&
  switch statement.*
    case jump statement.* = MonoStatement.jump(MonoJump {
      target = MonoLabel { id = target }
    })
    case jump_if_variant(jump)
      statement.* = MonoStatement.jump_if_variant(MonoJumpIfVariant {
        condition = jump.condition, variant = jump.variant,
        target = MonoLabel { id = target }
      })
    default unreachable()
}

var nothing_expr =
  MonoExpr { kind = MonoExprKind.nothing, type = type("Nothing") }
var never_expr =
  MonoExpr { kind = MonoExprKind.never, type = type("Never") }

fun member(of: MonoExpr, name: Str, type: Type): MonoExpr {
  MonoExpr {
    kind = MonoExprKind.member(MonoMember { of = of.put_on_heap(), name }),
    type,
  }
}
fun member(of: MonoExpr, field: MonoStructField): MonoExpr {
  of.member(field.name, field.type)
}

| Monomorphization  
| A rough sketch on how this compiler stage works: The Ast functions are
| compiled into monomorphized functions, starting from the main function. The
| Mono contains all monoed functions and types, corresponding to code and type
| definitions that actually need to be generated later on.
|
| Generic functions can be compiled multiple times with multiple type arguments.
| For example, take this code:
|
| struct Foo[T] { inner: T }
| fun wrap_in_foo[T](val: T) { Foo { inner = val } }
| fun main(): Byte {
|   var foo = wrap_in_foo(wrap_in_foo(2.lower_byte()))
|   0.lower_byte()
| }
|
| The following types and functions are monomorphized:
|
| - main[]()
|   - wrap_in_foo[Byte]()
|     - Foo[Byte]
|   - wrap_in_foo[Foo[Byte]]()
|     - Foo[Foo[Byte]]
|
| TODO: move this down to the compile fun
| Recursive functions  
| We want to allow recursive functions without the compiler itself getting
| into an infinitely recursing state. That's why even before a function is
| compiled, a mock-version of it is added to the function map. When this
| function is encountered recursively, only its signature is needed to figure
| out how to use it.

fun compile_entry_point(
  ast: Ast, fun_: LookupFunSolution
): Result[Mono, Error] {
  print_status("Monoing")

  var context = context()
  var mono = Mono {
    type_defs = map[Type, MonoTypeDef](),
    layouts = map[Type, MemLayout](),
    globals = map[Str, MonoFun](),
    globals_init_order = vec[Str](),
    funs = map[Str, MonoFun](),
    entry_point = "<placeholder>",
  }

  type("Never").compile(ast, mono.&)?
  type("Nothing").compile(ast, mono.&)?

  var signature = fun_.compile(context.&, ast, mono.&)
    or(error) return error[Mono, Error](make_error(
      error.src, error.title, error.description, context.signatures))
  mono.entry_point = signature

  ok[Mono, Error](mono)
}
fun compile_main(ast: Ast): Result[Mono, Error] {
  var src = src("_entry_point", 0..0)
  var main = ast.lookup_fun("main" @ src, none[Vec[Type]](), vec[Type]())
    or return error[Mono, Error](make_error(
      src, "There is no main().", "Your project must have a main() function.",
      vec[Str]()
    ))
  var mono = ast.compile_entry_point(main)?
  var return_type = mono.funs.get(mono.entry_point).return_type
  if not(return_type.is_never()) then
    return error[Mono, Error](make_error(
      src, "main() returns {return_type}.",
      "The main() function should return Never. You can call exit(0) if you 
      'want the program to stop.",
      vec[Str]()
    ))
  ok[Mono, Error](mono)
}
fun compile_fuzzer_main(ast: Ast, input: Type): Result[Mono, Error] {
  var src = src("_entry_point", 0..0)
  var fuzzer_main = ast.lookup_fun(
    "fuzzer_main" @ src, some(vec(input)), vec[Type]()
  ) or(error) return error[Mono, Error](make_error(
    src, "There is no fuzzer_main().",
    "Your project must have a fuzzer_main() function.",
    vec[Str]()
  ))
  var mono = ast.compile_entry_point(fuzzer_main).unwrap_or_report_and_exit()
  var return_type = mono.funs.get(mono.entry_point).return_type
  if not(return_type.is_never()) then
    return error[Mono, Error](make_error(
      src, "fuzzer_main() returns {return_type}.",
      "The fuzzer_main() function should return Never, but it returns 
        '{return_type}."
    ))
  ok[Mono, Error](mono)
}

| Monomorphizes a type, outputting all the required type defs into the Mono. For
| example, monomorphizing Map[T, Bool] with {T: Int} results in Map[Int, Bool]
| and also creates all the required defs (Map[Int, Bool], MapBucket[Int, Bool],
| Slice[MapBucket[Int, Bool]], etc.)
| Also saves the corresponding layout in the Mono.
fun compile(type: Type, ast: Ast, mono: &Mono): Result[Type, Error] {
  type.compile(map[Str, Type](), ast, mono)
}
fun compile(
  type: Type, type_env: Map[Str, Type], ast: Ast, mono: &Mono
): Result[Type, Error] {
  var mono_type = type.mono_type_def(type_env, ast, mono)?
  if mono_type.is_complete() then
    mono_type.mem_layout(mono.layouts.&, mono.type_defs).ignore()
  ok[Type, Error](mono_type)
}
fun mono_type_def(
  type: Type, type_env: Map[Str, Type], ast: Ast, mono: &Mono,
): Result[Type, Error] {
  | TODO: Make sure generic types don't have parameters.
  var type = type_env.get_maybe(type.name) or {
    var args = vec[Type]()
    for arg in type.args do args.&.push(arg.mono_type_def(type_env, ast, mono)?)
    Type { name = type.name, args }
  }

  if type.is_incomplete() then return ok[Type, Error](type)

  if mono.type_defs.contains(type) then return ok[Type, Error](type)

  | Types are allowed to contain themselves. For example, you can do this:
  |
  | struct Tree { children: Vec[Tree] }
  |
  | In order to not run into infinite recursion, we insert a placeholder type
  | into the type defs map, then lower the type, and then replace that
  | placeholder with the actual type def. In the example above:
  |
  | 1. Lower Tree
  |    1. Insert a placeholder for Tree in the type defs
  |    2. Lower Vec[Tree]
  |       1. Insert a placeholder for Vec[Tree] in the type defs
  |       2. Lower Slice[Tree]
  |          ...
  |          (this will not lower Tree again because it's already in the defs)
  |       3. Lower Int
  |       4. Put Vec[Tree]: struct { data: Slice[Tree], cap: Int } in the type
  |          defs, replacing the placeholder.
  |    3. Put Tree: struct { children: Vec[Tree] } in the type defs
  mono.type_defs.&.put(type,
    MonoTypeDef.opaque_(MonoOpaqueType { size = 0, alignment = 0 }))

  switch ast.lookup_type(type.name)?
  case opaque_(opaque_) {
    mono.type_defs.&.put(type, MonoTypeDef.opaque_(
      MonoOpaqueType { size = opaque_.size, alignment = opaque_.alignment }
    ))
  }
  case struct_(struct_) {
    var inner_type_env = map[Str, Type]()
    type.args.len == struct_.type_args.len or
      return error[Type, Error](make_error(
        src("todo", 0..0),
        "You tried to use a {type}, but {struct_.name} takes 
          '{struct_.type_args.len} type arguments."
      ))
    for zip in zip(struct_.type_args.iter(), type.args.iter()) do
      inner_type_env.&.put(zip.a.str, zip.b)

    var fields = vec[MonoStructField]()
    for field in struct_.fields do
      fields.&.push(MonoStructField {
        name = field.name.str,
        type = field.type.mono_type_def(inner_type_env, ast, mono)?,
      })

    mono.type_defs.&.put(type, MonoTypeDef.struct_(MonoStruct { fields }))
  }
  case enum_(enum_) {
    var inner_type_env = map[Str, Type]()
    type.args.len == enum_.type_args.len or
      return error[Type, Error](make_error(
        src("todo", 0..0),
        "You tried to use a {type}, but {enum_.name} takes {enum_.type_args.len} 
          'type arguments."
      ))
    for i in 0..type.args.len do
      inner_type_env.&.put(enum_.type_args.get(i).str, type.args.get(i))

    var variants = vec[MonoEnumVariant]()
    for variant in enum_.variants do
      variants.&.push(MonoEnumVariant {
        name = variant.name.str,
        type = variant.type.mono_type_def(inner_type_env, ast, mono)?,
      })

    mono.type_defs.&.put(type, MonoTypeDef.enum_(MonoEnum { variants }))
  }

  ok[Type, Error](type)
}

| You can use _ to infer parts of the type, for example like Maybe[_].
fun is_complete(type: Type): Bool {
  if type.name == "_" then return false
  for arg in type.args do arg.is_complete() or return false
  true
}
fun is_incomplete(type: Type): Bool { not(type.is_complete()) }

| Monoes a global variable (well, it can't have type arguments, so compiling
| would be the more appropriate term), outputting all the required type defs,
| other global variables, and functions into the Mono.
fun compile(
  global: AstVar, context: &Context, ast: Ast, mono: &Mono,
): Result[Nothing, Error] {
  if mono.globals.contains(global.name.str) then return ok[Nothing, Error]({})

  context.push("var {global.name}")

  var compile_fun = CompileFun {
    context, ast, mono, type_env = map[Str, Type](),
    return_type = type_sink(),
    body = MonoBodyBuilder {
      slots = vec[MonoSlot](), statements = vec[MonoStatementAndSrc](),
      context, ast, mono
    },
    next_label = 0, vars = vars[MonoExpr](),
    break_scopes = stack[BreakScope](),
    continue_scopes = stack[ContinueScope](),
  }

  var value = global.value.compile(compile_fun.&)?
  compile_fun.body.&.return_(value, global.name.src)
  if compile_fun.return_type.&.add(value.type) is error(error) then
    return error[Nothing, Error](make_error(
      global.name.src, "Type mismatch.", error))

  mono.globals.&.put(global.name.str, MonoFun {
    name = global.name,
    type_args = vec[Type](),
    arg_types = vec[Type](),
    return_type = compile_fun.return_type.finish(),
    kind = MonoFunKind.body(compile_fun.body.finish()),
  })
  mono.globals_init_order.&.push(global.name.str)

  context.&.pop()
  ok[Nothing, Error]({})
}

| Looks up a matching fun, compiles it and returns a call statement.
fun call_matching_fun(
  body: &MonoBodyBuilder,
  target: MonoExpr,
  name: AstStr, type_args: Maybe[Vec[Type]], args: Vec[MonoExpr], src: Src
): Result[Nothing, Error] {
  var arg_types = vec[Type]()
  for arg in args do arg_types.&.push(arg.type)
  var fun_ = body.ast
    .lookup_fun(name, type_args, arg_types)?
    .compile(body.context, body.ast, body.mono)?
  ok[Nothing, Error](body.call(target, fun_, args, src))
}
fun call_matching_fun(
  body: &MonoBodyBuilder, target: MonoExpr, name: AstStr, args: Vec[MonoExpr],
  src: Src
): Result[Nothing, Error] {
  body.call_matching_fun(target, name, none[Vec[Type]](), args, src)
}

| Monos a function with a type env, outputting it into the Mono. Returns the
| function signature. For example, monomorphizing foo[T](a: T) with {T: Int}
| results in the function signature foo(Int) and creates all required types and
| functions on the Mono.
fun compile(
  lookup_solution: LookupFunSolution,
  context: &Context, ast: Ast, mono: &Mono,
): Result[Str, Error] {
  lookup_solution.fun_.compile(lookup_solution.type_env, context, ast, mono)
}
fun compile(
  fun_: AstFun, type_env: Map[Str, Type],
  context: &Context, ast: Ast, mono: &Mono,
): Result[Str, Error] {
  var type_args = vec[Type]()
  for arg in fun_.type_args do
    type_args.&.push(type(arg.str).compile(type_env, ast, mono)?)

  var arg_types = vec[Type]()
  for arg in fun_.args do
    arg_types.&.push(arg.type.compile(type_env, ast, mono)?)

  var signature = signature(fun_.name.str, some(type_args), arg_types).format()
  if mono.funs.contains(signature) then return ok[Str, Error](signature)
  context.&.push(signature)

  var return_type = fun_.returns.compile(type_env, ast, mono)?

  | TODO: explain
  mono.funs.&.put(signature, MonoFun {
    name = fun_.name, type_args, arg_types, return_type,
    kind = MonoFunKind.asm_(vec[AstInstr]()),
  })

  var kind =
    switch fun_.kind
    case builtin(builtin) MonoFunKind.body(compile_builtin_fun(
      fun_.name.str, type_args, arg_types, builtin.dots.src, context, ast, mono
    )?)
    case asm_(code) MonoFunKind.asm_(code)
    case body(body) {
      var compile_fun = CompileFun {
        context, ast, mono, type_env,
        return_type = type_sink(return_type),
        body = MonoBodyBuilder {
          slots = vec[MonoSlot](), statements = vec[MonoStatementAndSrc](),
          context, ast, mono
        },
        next_label = 0, vars = vars[MonoExpr](),
        break_scopes = stack[BreakScope](),
        continue_scopes = stack[ContinueScope](),
      }
      for i in 0..fun_.args.len do
        compile_fun.vars.&.define(
          fun_.args.get(i).name.str,
          compile_fun.body.&.arg(arg_types.get(i), i)
        )
      var body_result = body.compile(compile_fun.&)?
      compile_fun.body.&.return_(body_result, fun_.name.src)
      | For builtin functions and asm functions, we trust the fully specified
      | return type. For Martinaise functions, we take the inferred return type.
      if compile_fun.return_type.&.add(body_result.type) is error(error) then
        return error[Str, Error](make_error(
          fun_.name.src,
          "The last expression of the function body doesn't match the return 
            'type.",
          error,
        ))
      return_type = compile_fun.return_type.finish()

      MonoFunKind.body(compile_fun.body.finish())
    }

  mono.funs.&.put(signature, MonoFun {
    name = fun_.name, type_args, arg_types, return_type, kind
  })
  context.pop()

  ok[Str, Error](signature)
}

struct CompileFun {
  context: &Context,
  ast: Ast,
  mono: &Mono,
  type_env: Map[Str, Type],
  return_type: TypeSink,
  body: MonoBodyBuilder,
  next_label: Int,
  vars: Vars[MonoExpr],
  | When lowering loops, breaks and continues don't know where to jump yet.
  | Instead, they fill these structures with jump addresses that need to be
  | adjusted later.
  break_scopes: Stack[BreakScope],
  continue_scopes: Stack[ContinueScope],
}
struct BreakScope {
  result: MonoSlotRef, type: Maybe[Type], breaks: Vec[MonoPlaceholder]
}
struct ContinueScope { continues: Vec[MonoPlaceholder] }

fun next_label_id(self: &CompileFun): Int {
  var id = self.next_label
  self.next_label = self.next_label + 1
  id
}

| Most expressions are compiled in a separate variable scope. For example, this
| shouldn't work:
|
| foo(var a = 3, a)
|
| Only the body expression compiles child expressions in a common scope:
|
| {
|   var a = a
|   var b = a  | works
| }
fun compile(expr: AstExpr, self: &CompileFun): Result[MonoExpr, Error] {
  var scope = self.vars.snapshot()
  var mono = expr.compile_in_current_scope(self)
  self.vars.&.restore(scope)
  mono
}
fun compile(body: Vec[AstExpr], self: &CompileFun): Result[MonoExpr, Error] {
  var scope = self.vars.snapshot()
  var last = none[MonoExpr]()
  for expr in body do last = some(expr.compile_in_current_scope(self)?)
  self.vars.&.restore(scope)
  ok[MonoExpr, Error](last or nothing_expr)
}
fun compile_in_current_scope(
  expr: AstExpr, self: &CompileFun,
): Result[MonoExpr, Error] {
  var context = self.context
  var ast = self.ast
  var mono = self.mono
  var body = self.body.&

  ok[MonoExpr, Error](
    switch expr
    case int(int) {
      type("Int").compile(ast, mono)?
      body.int(int)
    }
    case float(float) {
      type("Float").compile(ast, mono)?
      body.float(float)
    }
    case str(str) {
      type("Str").compile(ast, mono)?
      body.str(str)
    }
    case name(name) {
      switch self.vars.lookup(name.str)
      case some(expr) {
        body.nop(name.src)
        expr
      }
      case none {
        switch ast.lookup_global(name.str)
        case some(global) {
          global.compile(context, ast, mono)?
          var type = mono.globals.get(name.str).return_type
          MonoExpr { kind = MonoExprKind.global(name.str), type }
        }
        | TODO: print which variables are in scope
        case none return error[MonoExpr, Error](make_error(
          name.src, "\"{name}\" is not in scope."))
      }
    }
    case call(call) {
      var callee = none[MonoExpr]()
      var name =
        switch call.callee.*
        case name(name) name  | foo(a, b)
        case member(member) { | a.foo(b)
          callee = some(member.of.compile(self)?)
          member.name
        }
        default return error[MonoExpr, Error](make_error(
          call.opening_parenthesis.src, "This expression can't be called."))
      var type_args =
        switch call.type_args
        case none none[Vec[Type]]()
        case some(type_args) {
          var mono_type_args = vec[Type]()
          for arg in type_args do
            mono_type_args.&.push(arg.compile(self.type_env, ast, mono)?)
          some(mono_type_args)
        }
      var mono_args = vec[MonoExpr]()
      for arg in call.args do mono_args.&.push(arg.compile(self)?)

      | Martinaise supports auto-dereferencing: If you call value.foo() on a value
      | of type &T, we first look for functions matching foo(&T). If none match, we
      | try dereferencing the value and look for functions matching foo(T). If we
      | find one, your code acts as if it was value.*.foo().
      var first_error = none[Error]()
      var fun_and_args = loop {
        var args = vec[MonoExpr]()
        var arg_types = vec[Type]()
        if callee is some(c) then {
          args.&.push(c)
          arg_types.&.push(c.type)
        }
        for arg in mono_args do {
          args.&.push(arg)
          arg_types.&.push(arg.type)
        }

        var solution = ast.lookup_fun(name, type_args, arg_types) or(error) {
          if first_error is none then first_error = some(error)
          if callee is some(c) then if c.type.name == "&" then {
            | Dereference the callee
            callee = some(c.member("*", c.type.args.get(0)))
            continue
          }
          return error[MonoExpr, Error](first_error.unwrap())
        }
        var fun_ = solution.compile(context, ast, mono)?
        break(tuple(fun_, args))
      }
      var fun_ = fun_and_args.a
      var args = fun_and_args.b

      var result = self.body.&.uninitialized(mono.funs.get(fun_).return_type)
      body.call(result, fun_, args, name.src)
      result
    }
    case try_scope(try_) {
      var src = try_.keyword.src

      var catch_label = self.next_label_id()
      body.try_start(MonoLabel { id = catch_label }, src)
      var result = try_.body.compile(self)?
      body.try_end(src)

      var after_scope = self.next_label_id()
      var wrapped_result = self.body.&.uninitialized(
        type("Result", vec(result.type, type("Nothing"))).compile(ast, mono)?)
      body.set_enum(wrapped_result, "ok", result, src)
      body.jump(after_scope, src)
      body.label(catch_label, src)
      body.set_enum(wrapped_result, "error", nothing_expr, src)
      body.label(after_scope, src)
      wrapped_result
    }
    case make_struct(make_struct) {
      var struct_ = ast.lookup_type(make_struct.type.name)?.struct_
        or return error[MonoExpr, Error](make_error(
          make_struct.type_src, "{make_struct.type.name} is not a struct type."
        ))
      var fields = map[Str, MonoExpr]() {
        for field in make_struct.fields do
          fields.&.put(field.name.str, field.value.compile(self)?)
      }
      for field in struct_.fields do
        if not(fields.contains(field.name.str))
        then return error[MonoExpr, Error](make_error(
          make_struct.type_src,
          "The \"{field.name}\" field is missing.",
          "You need to initialize it with a {field.type}."
        ))

      var solver = create_type_solver(struct_.type_args)
      | TODO: Foo[] { ... } should not be treated like Foo { ... }
      if make_struct.type.args.is_not_empty() then {
        make_struct.type.args.len == struct_.type_args.len
          or return error[MonoExpr, Error](make_error(
            make_struct.type_src,
            "You provided the wrong number of type arguments.",
            "A {struct_.name} needs {make_struct.type.args.len} type arguments, 
              'you provided {struct_.type_args.len}."
          ))
        for i in 0..struct_.type_args.len do
          solver.&.unify(
            type(struct_.type_args.get(i).str),
            make_struct.type.args.get(i).compile(self.type_env, ast, mono)?,
          ).unwrap() or panic("unifying type args always works")
      }
      for field in fields do {
        var name = field.key
        var value = field.value
        var type_in_struct = none[Type]()
        for f in struct_.fields do
          if f.name.str == name then type_in_struct = some(f.type)

        var type_in_struct = type_in_struct
          or return error[MonoExpr, Error](make_error(
            make_struct.type_src,
            "Tried to initialize field {name}, but {struct_.name} doesn't have 
              'that."
          ))
        var works = solver.&.unify(type_in_struct, value.type)
          or(message) return error[MonoExpr, Error](make_error(
            make_struct.type_src, message))
        if not(works) then return error[MonoExpr, Error](make_error(
          make_struct.type_src,
          "Tried to assign {value.type} to field \"{name}\" of type 
            '{type_in_struct}."
        ))
      }
      var type_env = solver.finish()
        or(error) return error[MonoExpr, Error](
          make_error(make_struct.type_src, error))

      var unspecialized_type = make_struct.type
      if make_struct.type.args.is_empty() & struct_.type_args.is_not_empty()
      then for arg in struct_.type_args do
        unspecialized_type.args.&
          .push(type(arg.str).compile(type_env, ast, mono)?)
      var type = unspecialized_type.compile(self.type_env, ast, mono)?

      var slot = self.body.&.uninitialized(type)
      for field in fields do
        body.assign(slot.member(field.key, field.value.type), field.value,
          make_struct.type_src)
      slot
    }
    case make_enum(make_enum) {
      var enum_ = ast.lookup_type(make_enum.type.name)?.enum_
        or return error[MonoExpr, Error](make_error(
          make_enum.variant.src, "{make_enum.type.name} is not an enum type."))
      var arg = make_enum.arg.compile(self)?
      var variant_type = {
        var type = none[Type]()
        for variant in enum_.variants do
          if variant.name.str == make_enum.variant.str then
            type = some(variant.type)
        type or return error[MonoExpr, Error](make_error(
          make_enum.variant.src,
          "Unknown variant {make_enum.type.name}.{make_enum.variant}."
        ))
      }

      var solver = create_type_solver(enum_.type_args)
      | TODO: Maybe[].some(3) should not be treated like Maybe.some(3)
      if make_enum.type.args.is_not_empty() then {
        if make_enum.type.args.len != enum_.type_args.len then
          return error[MonoExpr, Error](make_error(
            make_enum.variant.src,
            "Tried to create enum {enum_.name} with {make_enum.type.args.len} 
              'type arguments, but it needs {enum_.type_args.len}."
          ))
        for i in 0..enum_.type_args.len do
          switch solver.&.unify(
            type(enum_.type_args.get(i).str),
            make_enum.type.args.get(i).compile(self.type_env, ast, mono)?
          )
          case error(message) return error[MonoExpr, Error](make_error(
            make_enum.variant.src, message))
          case ok(works) assert(works, "unifying type args always works")
      }
      switch solver.&.unify(variant_type, arg.type)
        case error(message) return error[MonoExpr, Error](make_error(
          make_enum.variant.src, message))
        case ok(works) works or return error[MonoExpr, Error](make_error(
          make_enum.variant.src,
          "Tried to create {make_enum.type.name}.{make_enum.variant} with 
            '{arg.type}, but it needs a {variant_type}."
        ))
      var type_env = solver.finish()
        or(error) return error[MonoExpr, Error](
          make_error(make_enum.variant.src, error))

      var unspecialized_type = make_enum.type
      if make_enum.type.args.is_empty() & enum_.type_args.is_not_empty() then
        for a in enum_.type_args do
          unspecialized_type.args.&
            .push(type(a.str).compile(type_env, ast, mono)?)
      var type = unspecialized_type.compile(self.type_env, ast, mono)?

      var slot = body.uninitialized(type)
      body.set_enum(slot, make_enum.variant.str, arg, make_enum.variant.src)
      slot
    }
    case member(member) {
      var of = member.of.compile(self)?
      | expr.& references the of
      if member.name.str == "&" then {
        var ref_type = type("&", vec(of.type))
          .compile(self.type_env, ast, mono)?
        var slot = self.body.&.uninitialized(ref_type)
        self.body.&.ref(slot, of, member.name.src)
        return ok[MonoExpr, Error](slot)
      }
      | When accessing a member on a reference, we automatically dereference the
      | receiver as often as necessary. For example, you can access point.x if
      | point is a &&&Point.
      loop
        if {of.type.name == "&"} & {member.name.str != "*"}
        then of = of.member("*", of.type.args.get(0))
        else break
      switch mono.type_defs.get(of.type)
      case struct_(struct_) {
        var field = {
          var the_field = none[MonoStructField]()
          for field in struct_.fields do
            if field.name == member.name.str then the_field = some(field)
          the_field or return error[MonoExpr, Error](make_error(
            member.name.src, "{member.name} is not a field on {of.type}.",
            {
              var out = string_builder().&
              out."It only contains these fields:"
              for field in struct_.fields do out."\n - {field.name}"
              out.to_str()
            }
          ))
        }
        of.member(field)
      }
      case enum_(enum_) {
        var variant = {
          var the_variant = none[MonoEnumVariant]()
          for variant in enum_.variants do
            if variant.name == member.name.str then the_variant = some(variant)
          the_variant or return error[MonoExpr, Error](make_error(
            member.name.src, "This is not a variant of {of.type}.",
            {
              var out = string_builder().&
              out."It only has these variant:"
              for variant in enum_.variants do out."\n - {variant.name}"
              out.to_str()
            }
          ))
        }
        var src = member.name.src
        var payload = body.uninitialized(variant.type)
        var maybe = body.uninitialized(type("Maybe", vec(variant.type)))
        var matches_label = self.next_label_id()
        var matches_not_label = self.next_label_id()
        var after_label = self.next_label_id()
        body.jump_if_variant(of, variant.name, matches_label, src)
        body.jump(matches_not_label, src)
        body.label(matches_label, src)
        body.get_enum_value(payload, of, variant.name, src)
        body.set_enum(maybe, "some", payload, src)
        body.jump(after_label, src)
        body.label(matches_not_label, src)
        body.set_enum(maybe, "none", nothing_expr, src)
        body.label(after_label, src)
        maybe
      }
      case opaque_ return error[MonoExpr, Error](make_error(
        member.name.src, "Invalid member access.",
        "{of.type} is an opaque type."
      ))
    }
    case var_(var_) {
      var value = var_.value.compile(self)?
      var slot = body.uninitialized(value.type)
      body.assign(slot, value, var_.name.src)
      self.vars.&.define(var_.name.str, slot)
      nothing_expr
    }
    case assign(assign) {
      var to = assign.to.compile(self)?
      var value = assign.value.compile(self)?
      value.type == to.type or return error[MonoExpr, Error](make_error(
        assign.equal_sign.src,
        "Invalid assign",
        "The variable needs a {to.type}, the value is a {value.type}."
      ))
      body.assign(to, value, assign.equal_sign.src)
      nothing_expr
    }
    | Switch  
    | Switches are lowered to a jump table. Here's an example of a switch and
    | how it will be compiled:
    |
    | switch value
    | case foo foo
    | case bar(bar) bar
    | default baz
    |
    | _0: Result <- the result slot
    | _1: Bar <- slot for bar binding
    | ...
    | jump_if_variant value foo label_0 ──┐
    | jump_if_variant value bar label_1 ──┼─┐
    | jump label_2  ──────────────────────┼─┼─┐
    | label_0: <──────────────────────────┘ │ │
    | _0 = foo                              │ │
    | jump label_3 ─────────────────>┐      │ │
    | label_1: <─────────────────────┼──────┘ │
    | _1 = get_enum_value value bar  │        │
    | _0 = bar                       │        │
    | jump label_3 ─────────────────>┤        │
    | label_2: <─────────────────────┼────────┘
    | _0 = baz                       │
    | jump label_3 ─────────────────>┤
    | label_3: <─────────────────────┘
    | ...
    case switch_(switch_) {
      var result = body.untyped_slot()
      var type = none[Type]() | TODO: use type sink

      var value = switch_.value.compile(self)?
      var enum_ = mono.type_defs.get(value.type).enum_
        or return error[MonoExpr, Error](make_error(
          switch_.keyword.src,
          "{value.type} is not an enum.",
          "You can only switch on enums."
        ))

      | Ensure all cases refer to enum variants and all variants are handled
      | exactly once.
      var handled = set[Str]()
      for case_ in switch_.cases do {
        if handled.contains(case_.variant.str) then
          return error[MonoExpr, Error](make_error(
            case_.variant.src,
            "You handle the \"{case_.variant}\" variant multiple times."
          ))
        | TODO: when supporting continue with label, use that
        var handled_this_case = false
        for variant in enum_.variants do
          if variant.name == case_.variant.str then {
            handled.&.put(case_.variant.str)
            handled_this_case = true
          }
        if handled_this_case then continue
        return error[MonoExpr, Error](make_error(
          case_.variant.src, "This is not a variant.",
          {
            var out = string_builder().&
            out."{value.type} only has these variants:"
            for variant in enum_.variants do out."\n - {variant.name}"
            out.to_str()
          }
        ))
      }
      if switch_.default_ is none then
        for variant in enum_.variants do
          if not(handled.contains(variant.name)) then
            return error[MonoExpr, Error](make_error(
              switch_.keyword.src,
              "You don't handle {value.type}.{variant.name}."
            ))

      var jump_table_jumps = map[Str, MonoPlaceholder]()
      for case_ in switch_.cases do
        jump_table_jumps.&.put(
          case_.variant.str,
          body.jump_if_variant_placeholder(
            value, case_.variant.str, case_.variant.src))
      var default_jump =
        switch switch_.default_
        case some(default_) some(body.jump_placeholder(default_.keyword.src))
        case none none[MonoPlaceholder]()
      | Contains indices of statements which will be replaced with unconditional
      | jumps to after the switch.
      var after_switch_jumps = vec[MonoPlaceholder]()

      | Case bodies
      for case_ in switch_.cases do {
        var src = case_.variant.src
        var label = self.next_label_id()
        body.label(label, src)
        body.update_target(jump_table_jumps.get(case_.variant.str), label)
        var variant_type = {
          var variant_type = none[Type]()
          for variant in enum_.variants do
            if variant.name == case_.variant.str then
              variant_type = some(variant.type)
          variant_type.unwrap("expected variant type")
        }
        var unpacked = body.uninitialized(variant_type)
        body.get_enum_value(unpacked, value, case_.variant.str, src)
        var scope = self.vars.snapshot()
        if case_.binding is some(binding) then
          self.vars.&.define(binding.str, unpacked)
        var case_expr = case_.body.compile(self)?
        self.vars.&.restore(scope)

        if not(case_expr.type.is_never()) then {
          switch type
          case none type = some(case_expr.type)
          case some(expected) {
            case_expr.type == expected or return error[MonoExpr, Error](make_error(
              case_.variant.src,
              "This case evaluates to a {case_expr.type}, but previous cases to 
                '{expected}."
            ))
            {}
          }
          body.assign(body.typed(result, case_expr.type), case_expr, src)
        }
        after_switch_jumps.&.push(body.jump_placeholder(src))
      }

      | Default case
      if switch_.default_ is some(default_) then {
        var src = default_.keyword.src
        var label = self.next_label_id()
        body.label(label, src)
        body.update_target(default_jump.unwrap("no default jump"), label)
        var default_result = default_.body.compile(self)?
        if not(default_result.type.is_never()) then {
          type = some(default_result.type)
          body.assign(
            body.typed(result, default_result.type), default_result, src)
        }
        after_switch_jumps.&.push(body.jump_placeholder(src))
      }

      var after_switch = self.next_label_id()
      body.label(after_switch, switch_.keyword.src)
      for jump in after_switch_jumps do body.update_target(jump, after_switch)

      body.typed(result, type or type("Never"))
    }
    | Loop  
    | Loops are lowered to two labels – one before and one after the loop.
    | Breaks, continues, and the loop itself each compile to a single jump to
    | one of those labels. Here's an example of a loop and how it will be
    | compiled:
    |
    | loop {
    |   ...
    |   continue
    |   ...
    |   break(5)
    | }
    |
    | _0: Result <- the result slot
    | ...
    | label_0: <────────┐
    | ...               │
    | jump label_0 ────>┤
    | ...               │
    | jump label_1 ──┐  │
    | ...            │  │
    | jump label_0 ──┼─>┘
    | label_1: <─────┘
    | ...
    case loop_(loop_) {
      var src = loop_.keyword.src
      var result = body.untyped_slot()
      self.break_scopes.&.push(BreakScope {
        result,
        type = none[Type](), | TODO: use type sink
        breaks = vec[MonoPlaceholder](),
      })
      | TODO: save the loop start instead
      self.continue_scopes.&.push(ContinueScope {
        continues = vec[MonoPlaceholder]()
      })

      var loop_start = self.next_label_id()
      body.label(loop_start, src)
      loop_.body.compile(self)?
      body.jump(loop_start, src)

      var after_loop = self.next_label_id()
      body.label(after_loop, src)
      var break_scope    = self.break_scopes.&.pop()
      var continue_scope = self.continue_scopes.&.pop()
      for break_ in break_scope.breaks do body.update_target(break_, after_loop)
      for continue_ in continue_scope.continues do
        self.body.&.update_target(continue_, loop_start)
      body.typed(result, break_scope.type or type("Never"))
    }
    case break_(break_) {
      if self.break_scopes.is_empty() then
        return error[MonoExpr, Error](make_error(
          break_.keyword.src, "This break is outside a loop.",
          "Breaks can only be inside loops."
        ))
      var scope = self.break_scopes.top_ref()

      var src = break_.keyword.src
      var value = break_.value.compile(self)?

      if scope.type is some(expected) then
        value.type == expected or return error[MonoExpr, Error](make_error(
          break_.keyword.src,
          "Inconsistent break values.",
          "  previous break > {expected}\n
          '      this break > {value.type}"
        ))
      scope.type = some(value.type)
      | TODO: This is not correct. The type of the slot is only updated after
      | the loop body is fully lowered. The created slot expr still has the
      | wrong type.
      body.assign(body.typed(scope.result, value.type), value, src)

      scope.breaks.&.push(body.jump_placeholder(src))
      never_expr
    }
    case continue_(continue_) {
      if self.continue_scopes.is_empty() then
        return error[MonoExpr, Error](make_error(
          continue_.keyword.src, "This continue is outside of a loop."))
      var scope = self.continue_scopes.top_ref()
      scope.continues.&.push(body.jump_placeholder(continue_.keyword.src))
      never_expr
    }
    case return_(return_) {
      var value = return_.value.compile(self)?
      if self.return_type.&.add(value.type) is error(error) then
        return error[MonoExpr, Error](make_error(
          return_.keyword.src, "Inconsistent return types.", error))
      body.return_(value, return_.keyword.src)
      never_expr
    }
    case try(try_) {
      var src = try_.question_mark.src
      var value = try_.value.compile(self)?
      value.type.name == "Result" or return error[MonoExpr, Error](make_error(
        try_.question_mark.src,
        "The ? operator can only be used on Results.",
        "The value on the left has the type {value.type}."
      ))
      var return_type = self.return_type.finish()
      return_type.name == "Result" or return error[MonoExpr, Error](make_error(
        try_.question_mark.src,
        "? is not allowed in this function.",
        "The try operator ? can only be used in functions that return Result. 
          'This function returns a {return_type}."
      ))
      value.type.args.get(1) == return_type.args.get(1)
        or return error[MonoExpr, Error](make_error(
          try_.question_mark.src,
          "? has the wrong type.",
          "You used ? on a Result where the error type doesn't match the error 
            'type of the function.\n
            '  type of ? value: Result[..., {value.type.args.get(1)}]\n
            ' type of function: Result[..., {return_type.args.get(1)}]"
        ))

      var ok_type = value.type.args.get(0)
      var error_type = value.type.args.get(1)

      var jump_if_ok = body.jump_if_variant_placeholder(value, "ok", src)
      var error_payload = body.uninitialized(error_type)
      var error_to_return = body.uninitialized(return_type)
      body.get_enum_value(error_payload, value, "error", src)
      body.set_enum(error_to_return, "error", error_payload, src)
      body.return_(error_to_return, src)

      var after_error_handling = self.next_label_id()
      body.label(after_error_handling, src)
      body.update_target(jump_if_ok, after_error_handling)

      var ok_payload = body.uninitialized(ok_type)
      body.get_enum_value(ok_payload, value, "ok", src)
      ok_payload
    }
    case block(block) block.compile(self)?
  )
}

| Memory Layout  
| Finding efficient memory layouts for types is a bit tricky.

struct MemLayout { type: Type, size: Int, alignment: Int, kind: MemLayoutKind }
enum MemLayoutKind {
  opaque_, struct_: Vec[MemLayoutStructPart], enum_: Vec[MemLayoutVariant]
}
enum MemLayoutStructPart { padding: Int, field: MemLayoutField }
struct MemLayoutField { name: Str, layout: MemLayout }
struct MemLayoutVariant { name: Str, layout: MemLayout }

fun mem_layout(
  type: Type, layouts: &Map[Type, MemLayout], type_defs: Map[Type, MonoTypeDef]
): MemLayout {
  layouts.get_maybe(type) or {
    var layout = type.calculate_mem_layout(layouts, type_defs)
    layouts.put(type, layout)
    layout
  }
}
fun calculate_mem_layout(
  type: Type, layouts: &Map[Type, MemLayout], type_defs: Map[Type, MonoTypeDef]
): MemLayout {
  if type.name == "&" then return MemLayout {
    type, size = 8, alignment = 8, kind = MemLayoutKind.opaque_
  }
  calculate_mem_layout(type, type_defs.get(type), layouts, type_defs)
}
| We sometimes want to mem-layout anonymous structs, for example when arranging
| the arguments of a function. Those anonymous types don't have corresponding
| entries in the type-defs map, so this function directly accepts a type def
| directly.
fun calculate_mem_layout(
  type: Type, def: MonoTypeDef,
  layouts: &Map[Type, MemLayout], type_defs: Map[Type, MonoTypeDef]
): MemLayout {
  switch def
  case opaque_(info) {
    if info.alignment == 0 then
      panic("mem layouting unfinished (placeholder) type: {type}")
    MemLayout {
      type,
      size = info.size,
      alignment = info.alignment,
      kind = MemLayoutKind.opaque_,
    }
  }
  case struct_(struct_) {
    | First, layout all the fields and determine this struct's alignment.
    var fields = vec[MemLayoutField]()
    var alignment = 1
    for field in struct_.fields do {
      var layout = field.type.mem_layout(layouts, type_defs)
      alignment = max(alignment, layout.alignment)
      fields.&.push(MemLayoutField { name = field.name, layout })
    }

    | Fields with a size that is a multiple of the alignment can all be put to
    | the beginning.
    var fields_sized_multiple_of_alignment = vec[MemLayoutField]()
    var remaining_fields = vec[MemLayoutField]()
    for field in fields do
      if field.layout.size % alignment == 0
      then fields_sized_multiple_of_alignment.&.push(field)
      else remaining_fields.&.push(field)

    | For all remaining fields, try all permutations to find the one with the
    | smallest overall size.
    var smallest_permutation = uninitialized_slice[Int](remaining_fields.len)
    var smallest_size_of_remaining = 999999999 | TODO
    for permutation in permutations(remaining_fields.len).enumerate() do {
      | Only try the first 1000 permutations.
      if permutation.index >= 1000 then break
      var permutation = permutation.item
      var size = 0
      for field in permutation do {
        var field = remaining_fields.get(field)
        | TODO: use round_up_to_multiple of
        size = size
          + size.needed_for_multiple_of(field.layout.alignment) | padding
          + field.layout.size | the field itself
      }
      if size < smallest_size_of_remaining then {
        smallest_size_of_remaining = size
        permutation.copy_to(smallest_permutation)
      }
    }

    | Build the actual layout.
    var parts = vec[MemLayoutStructPart]()
    var size = 0
    for field in fields_sized_multiple_of_alignment do {
      parts.&.push(MemLayoutStructPart.field(field))
      size = size + field.layout.size
    }
    for index in smallest_permutation do {
      var field = remaining_fields.get(index)
      var padding = size.needed_for_multiple_of(field.layout.alignment)
      if padding > 0 then {
        parts.&.push(MemLayoutStructPart.padding(padding))
        size = size + padding
      }
      parts.&.push(MemLayoutStructPart.field(field))
      size = size + field.layout.size
    }
    MemLayout { type, size, alignment, kind = MemLayoutKind.struct_(parts) }
  }
  case enum_(enum_) {
    var variants = vec[MemLayoutVariant]()
    var alignment = 1
    var size = 0
    for variant in enum_.variants do {
      var layout = variant.type.mem_layout(layouts, type_defs)
      alignment = max(alignment, layout.alignment)
      size = max(size, layout.size)
      variants.&.push(MemLayoutVariant { name = variant.name, layout })
    }
    var size = size + 1 | one byte for the tag
    MemLayout { type, size, alignment, kind = MemLayoutKind.enum_(variants) }
  }
}

fun needed_for_multiple_of(number: Int, factor: Int): Int {
  number.round_up_to_multiple_of(factor) - number
}

| TODO: move to stdlib?
fun permutations(size: Int): Iter[Slice[Int], Permutations] {
  var numbers = vec[Int]()
  for i in 0..size do numbers.&.push(i)
  Iter[Slice[Int], Permutations] {
    state = Permutations { is_first = true, last = numbers.to_slice() }
  }
}
struct Permutations { is_first: Bool, last: Slice[Int] }
fun next(self: &Iter[Slice[Int], Permutations]): Maybe[Slice[Int]] {
  var self = self.state.&
  if self.is_first then { self.is_first = false return some(self.last) }
  if self.last.is_empty() then return none[Slice[Int]]()
  var index = self.last.len - 1
  loop {
    if index == 0 then { return none[Slice[Int]]() }
    index = index - 1
    if self.last.get(index) < self.last.get(index + 1) then {
      | Find the smallest element after the index that is greater than
      | list[index].
      var smallest_index = index + 1
      var smallest = self.last.get(index + 1)
      for j in {index + 2}..self.last.len do
        if {self.last.get(j) > self.last.get(index)}
          & {self.last.get(j) < smallest}
        then smallest_index = j
      swap(self.last.get_ref(index), self.last.get_ref(smallest_index))
      self.last.without_first(index + 1).&.sort()
      return some(self.last)
    }
  }
}

| Printing a memory layout is actually more complicated than calculating it. But
| it was quite fun to write.

enum MemShade { a, b, padding }
fun write[W](writer: W, shade: MemShade) {
  writer.write(switch shade case a "▓" case b "░" case padding ".")
  | writer.write(switch shade case a "▓" case b "▒" case padding "░")
}
| Adjacent fields should have different shades, inner fields want to start with
| the same shading as the parent.
fun choose_shade(previous: MemShade, preffered: MemShade) {
  switch preffered
  case padding unreachable()
  case a if previous is a then MemShade.b else MemShade.a
  case b if previous is b then MemShade.a else MemShade.b
}

| When walking the memory layout, we basically need to write multiple lines
| simultaneously. So, that's what we do.
struct MemWriter {
  lines: Vec[StringBuilder],
  last_shades: Vec[MemShade],
}
fun mem_writer(lines: Int): MemWriter {
  var lines_vec = vec[StringBuilder]()
  var last_shades = vec[MemShade]()
  for i in 0..lines do {
    lines_vec.&.push(string_builder())
    last_shades.&.push(MemShade.padding)
  }
  MemWriter { lines = lines_vec, last_shades }
}
fun line(writer: &MemWriter, index: Int): &StringBuilder {
  writer.lines.get_ref(index)
}
fun shade(writer: &MemWriter, index: Int): &MemShade {
  writer.last_shades.get_ref(index)
}
fun write[W](writer: W, layout: MemLayout) {
  var mem_writer = mem_writer(layout.num_lines_when_printing())
  mem_writer.&.write(layout, 0, MemShade.a)

  var byte = 0
  loop {
    if byte > layout.size then break
    writer."▏{"{byte}".fit_to_size(7)}"
    byte = byte + 8
  }
  writer."\n"

  for line in mem_writer.lines.iter().enumerate() do {
    writer.write(line.item.to_str())
    if line.index == 0 then writer." {layout.size}"
    if line.index < {mem_writer.lines.len - 1} then writer.writeln()
  }
}
fun num_lines_when_printing(layout: MemLayout): Int {
  if layout.size == 0 then return 0
  switch layout.kind
  case opaque_ 2
  case struct_(parts) {
    var max = 0
    for part in parts do
      max = max(max,
        switch part
        case padding 1
        case field(field) field.layout.num_lines_when_printing()
      )
    max + 3
  }
  case enum_(variants) {
    var sum = 0
    for variant in variants do
      sum = sum + max(1, variant.layout.num_lines_when_printing()) + 1
    sum + 2
  }
}
fun write(
  writer: &MemWriter, layout: MemLayout, line: Int, preffered_shade: MemShade
) {
  if layout.size == 0 then return {}

  var shade =
    switch preffered_shade
    case padding unreachable()
    case a if writer.last_shades.get(line) is a then MemShade.b else MemShade.a
    case b if writer.last_shades.get(line) is b then MemShade.a else MemShade.b
  for i in 0..layout.size do writer.line(line)."{shade}"
  writer.last_shades.get_ref(line).* = shade

  switch layout.kind
  case opaque_
    writer.line(line + 1)."{format(layout.type).fit_to_size(layout.size)}"
  case struct_(parts) {
    writer.line(line + 1)."{format(layout.type).fit_to_size(layout.size)}"
    var last_line = line + layout.num_lines_when_printing()
    for part in parts do
      switch part
      case padding(padding) {
        writer.line(line + 2).write_n(padding, " ")
        writer.line(line + 3).write_n(padding, "{MemShade.padding}")
        writer.shade(line + 3).* = MemShade.padding
        for line in {line + 4}..last_line do {
          writer.line(line).write_n(padding, " ")
          writer.shade(line).* = MemShade.padding
        }
      }
      case field(field) {
        writer.line(line + 2)
          .write(field.name.fit_to_size(field.layout.size))
        writer.write(field.layout, line + 3, shade)
        for line
        in {line + 3 + field.layout.num_lines_when_printing()}..last_line
        do {
          writer.line(line).write_n(field.layout.size, " ")
          writer.shade(line).* = MemShade.padding
        }
      }
  }
  case enum_(variants) {
    writer.line(line + 1)
      ."{format(layout.type).fit_to_size(layout.size - 1)}│"
    var start_line = line
    var line = line + 2
    for variant in variants.iter().enumerate() do {
      var is_last = variant.index == variants.len - 1
      var variant = variant.item
      var padding = layout.size - variant.layout.size - 1
      writer.line(line)
        ."{variant.name.fit_to_size(layout.size - 1, "─")}
         '{if is_last then "┘" else "┤"}"
      writer.write(variant.layout, line + 1, shade)
      writer.line(line + 1).write_n(padding, "{MemShade.padding}")
      writer.line(line + 1)."{if is_last then " " else "│"}"
      var lines = variant.layout.num_lines_when_printing()
      for line in {line + 2}..{line + 1 + lines} do {
        writer.line(line).write_n(padding, " ")
        writer.line(line)."{if is_last then " " else "│"}"
      }
      line = line + 1 + variant.layout.num_lines_when_printing()
    }
    for line in start_line..line do writer.shade(line).* = MemShade.padding
  }
}
fun fit_to_size(str: Str, size: Int): Str { str.fit_to_size(size, " ") }
fun fit_to_size(str: Str, size: Int, padding: Str): Str {
  if size == 0 then return ""
  if size == 1 then return "…"
  if str.len >= size then str = "{str.first(size - 1)}…"

  var string = string_builder().&
  string.write(str)
  for i in str.len..size do string.write(padding)
  string.to_str()
}
fun write_n[W](writer: W, n: Int, str: Str) {
  for i in 0..n do writer.write(str)
}

| Builtin Functions  

fun compile_builtin_fun(
  name: Str, type_args: Vec[Type], arg_types: Vec[Type], src: Src,
  context: &Context, ast: Ast, mono: &Mono
): Result[MonoFunBody, Error] {
  var body = MonoBodyBuilder {
    slots = vec[MonoSlot](), statements = vec[MonoStatementAndSrc](),
    context, ast, mono
  }.&
  
  if name == "size_of" then
    return compile_size_of_fun(type_args, arg_types, body, src)

  if name == "alignment_of" then
    return compile_alignment_of_fun(type_args, arg_types, body, src)

  if name == "stride_size_of" then
    return compile_stride_size_of_fun(type_args, arg_types, body, src)

  if name == "type" then
    return compile_type_fun(type_args, arg_types, body, src)

  if name == "write_debug" then
    return compile_write_debug_fun(type_args, arg_types, body, src)

  if name == "generate" then
    return compile_generate_fun(type_args, arg_types, body, src)

  if name == "fuzzing_complexity" then
    return compile_fuzzing_complexity_fun(type_args, arg_types, body, src)

  if name == "mutate" then
    return compile_mutate_fun(type_args, arg_types, body, src)

  error[MonoFunBody, Error](make_error(src, "Unknown builtin {name}"))
}

fun compile_size_of_fun(
  type_args: Vec[Type], arg_types: Vec[Type], body: &MonoBodyBuilder, src: Src
): Result[MonoFunBody, Error] {
  type_args.len == 1 or return error[MonoFunBody, Error](make_error(
    src, "size_of should take exactly one type argument."))
  type("Int").compile(body.ast, body.mono)?

  var size = body.int(body.mono.layouts.get(type_args.get(0)).size)
  body.return_(size, src)
  ok[MonoFunBody, Error](body.finish())
}

fun compile_alignment_of_fun(
  type_args: Vec[Type], arg_types: Vec[Type], body: &MonoBodyBuilder, src: Src
): Result[MonoFunBody, Error] {
  type_args.len == 1 or return error[MonoFunBody, Error](make_error(
    src, "alignment_of should take exactly one type argument."))
  type("Int").compile(body.ast, body.mono)?

  var alignment = body.int(body.mono.layouts.get(type_args.get(0)).alignment)
  body.return_(alignment, src)
  ok[MonoFunBody, Error](body.finish())
}

fun compile_stride_size_of_fun(
  type_args: Vec[Type], arg_types: Vec[Type], body: &MonoBodyBuilder, src: Src
): Result[MonoFunBody, Error] {
  type_args.len == 1 or return error[MonoFunBody, Error](make_error(
    src, "stride_size_of should take exactly one type argument."))
  type("Int").compile(body.ast, body.mono)?

  var layout = body.mono.layouts.get(type_args.get(0))
  var stride_size = layout.size.round_up_to_multiple_of(layout.alignment)
  body.return_(body.int(stride_size), src)
  ok[MonoFunBody, Error](body.finish())
}

fun compile_type_fun(
  type_args: Vec[Type], arg_types: Vec[Type], body: &MonoBodyBuilder, src: Src
): Result[MonoFunBody, Error] {
  type_args.len == 1 or return error[MonoFunBody, Error](make_error(
    src, "type should take exactly one type argument."))
  type("Type").compile(body.ast, body.mono)?
  type("Vec", vec(type("Type"))).compile(body.ast, body.mono)?

  var reflected = compile_type_fun_rec(type_args.get(0), body, src)?
  body.return_(reflected, src)
  ok[MonoFunBody, Error](body.finish())
}
fun compile_type_fun_rec(
  type: Type, body: &MonoBodyBuilder, src: Src
): Result[MonoExpr, Error] {
  var name = body.str(type.name)

  var vec = body.uninitialized(type("Vec", vec(type("Type"))))
  body.call_matching_fun(
    vec, "vec" @ src, some(vec(type("Type"))), vec[MonoExpr](), src)?

  var ref_vec = body.uninitialized(type("&", vec(type("Vec", vec(type("Type"))))))
  body.ref(ref_vec, vec, src)

  for arg in type.args do {
    var nothing = body.uninitialized(type("Nothing"))
    var arg = compile_type_fun_rec(arg, body, src)?
    body.call_matching_fun(nothing, "push" @ src, vec(ref_vec, arg), src)?
  }

  var type = body.uninitialized(type("Type"))
  body.assign(type.member("name", type("Str")), name, src)
  body.assign(type.member("args", type("Vec", vec(type("Type")))), vec, src)

  ok[MonoExpr, Error](type)
}

fun compile_write_debug_fun(
  type_args: Vec[Type], arg_types: Vec[Type], body: &MonoBodyBuilder, src: Src
): Result[MonoFunBody, Error] {
  arg_types.len == 2 or return error[MonoFunBody, Error](make_error(
    src, "write_debug should take exactly two arguments."))
  type("Str").compile(body.ast, body.mono)?

  var writer = body.arg(arg_types.get(0), 0)
  var value = body.arg(arg_types.get(1), 1)
  var nothing = body.uninitialized(type("Nothing"))

  switch body.mono.type_defs.get(value.type)
  case opaque_ {
    var dots = body.str("...")
    body.call_matching_fun(nothing, "write" @ src, vec(writer, dots), src)?
  }
  case struct_(struct_) {
    body.call_matching_fun(nothing, "write" @ src,
      vec(writer, body.str("{value.type} \{")), src)?
    for it in struct_.fields.iter().enumerate() do {
      var field = it.item
      var str =
        if it.index == 0
        then " {field.name} = "
        else ", {field.name} = "
      var str = body.str(str)
      body.call_matching_fun(nothing, "write" @ src, vec(writer, str), src)?
      body.call_matching_fun(
        nothing, "write_debug" @ src, vec(writer, value.member(field)), src)?
    }
    var str = body.str(" }")
    body.call_matching_fun(nothing, "write" @ src, vec(writer, str), src)?
  }
  case enum_(enum_) {
    var payloads = vec[MonoExpr]()
    var variant_strs = vec[MonoExpr]()
    for variant in enum_.variants do {
      payloads.&.push(body.uninitialized(variant.type))
      variant_strs.&.push(body.str(variant.name))
    }
    var opening_str = body.str("(")
    var closing_str = body.str(")")

    for it in enum_.variants.iter().enumerate() do
      body.jump_if_variant(value, it.item.name, it.index, src)

    for it in enum_.variants.iter().enumerate() do {
      var variant = it.item
      var payload = payloads.get(it.index)

      body.label(it.index, src)
      body.call_matching_fun(nothing, "write" @ src,
        vec(writer, variant_strs.get(it.index)), src)?
      if variant.type != type("Nothing") then {
        body.get_enum_value(payload, value, variant.name, src)
        body.call_matching_fun(nothing, "write" @ src,
          vec(writer, opening_str), src)?
        body.call_matching_fun(
          nothing, "write_debug" @ src, vec(writer, payload), src)?
        body.call_matching_fun(nothing, "write" @ src,
          vec(writer, closing_str), src)?
      }
      body.jump(enum_.variants.len, src)
    }

    var label = body.label(enum_.variants.len, src)
    | TODO: update jumps
  }
  body.return_(nothing, src)
  ok[MonoFunBody, Error](body.finish())
}

fun compile_generate_fun(
  type_args: Vec[Type], arg_types: Vec[Type], body: &MonoBodyBuilder, src: Src,
): Result[MonoFunBody, Error] {
  arg_types.len == 3 or return error[MonoFunBody, Error](make_error(
    src, "generate should take exactly three arguments."))
  var static_ty = arg_types.get(0)
  static_ty.name == "Static" or return error[MonoFunBody, Error](make_error(
    src, "generate should take a Static."))
  static_ty.args.len == 1 or return error[MonoFunBody, Error](make_error(
    src, "Static should have one type argument."))
  var value_ty = static_ty.args.get(0)
  arg_types.get(1) == type("&", vec(type("Random")))
    or return error[MonoFunBody, Error](make_error(
      src, "generate should take a &Random as the second argument."))
  arg_types.get(2) == type("Int")
    or return error[MonoFunBody, Error](make_error(
      src, "generate should take an complexity Int as the third argument."))

  var static = body.arg(static_ty, 0)
  var random = body.arg(type("&", vec(type("Random"))), 1)
  var complexity = body.arg(type("Int"), 2)
  var nothing = body.uninitialized(type("Nothing"))
  var value = body.uninitialized(value_ty)

  switch body.mono.type_defs.get(value_ty)
  case opaque_ return error[MonoFunBody, Error](make_error(src,
    "For opaque types, you need to implement a generate function yourself."))
  case struct_(struct_) {
    | var complexities = random.split(complexity, 2)
    | SomeStruct {
    |   foo = Static[Foo]{}.generate(random, complexities.get(0)),
    |   bar = Static[Bar]{}.generate(random, complexities.get(1)),
    | }
    var num_fields = body.int(struct_.fields.len)
    var complexities = body.uninitialized(type("Slice", vec(type("Int"))))
    body.call_matching_fun(
      complexities, "split" @ src, vec(random, complexity, num_fields), src)?

    for it in struct_.fields.iter().enumerate() do {
      var field = it.item

      | doesn't have to be initialized (size 0)
      var static_field = body.uninitialized(
        type("Static", vec(field.type)).compile(body.ast, body.mono)?)

      var field_complexity = body.uninitialized(type("Int"))
      var index = body.int(it.index)
      body.call_matching_fun(field_complexity, "get" @ src,
        vec(complexities, index), src)?

      var new_field_value = body.uninitialized(field.type)
      body.call_matching_fun(new_field_value, "generate" @ src,
        vec(static_field, random, field_complexity), src)?
      body.assign(value.member(field), new_field_value, src)
    }
  }
  case enum_(enum_) {
    | var variant = random.next_int(0..2)
    | if variant == 0 then return SomeEnum.foo
    | if variant == 1 then
    |   return SomeEnum.bar(Static[Int]{}.generate(random, complexity))
    | unreachable()
    if enum_.variants.len == 0 then return error[MonoFunBody, Error](make_error(
      src, "Can't generate instances of {value_ty}."))

    type("Bool").compile(body.ast, body.mono)?
    type("Range", vec(type("Int"))).compile(body.ast, body.mono)?

    var lower = body.int(0)
    var upper = body.int(enum_.variants.len)
    var range = body.uninitialized(type("Range", vec(type("Int"))))
    body.call_matching_fun(range, ".." @ src, vec(lower, upper), src)?

    var variant = body.uninitialized(type("Int"))
    body.call_matching_fun(variant, "next_int" @ src, vec(random, range), src)?

    var check = body.uninitialized(type("Bool"))
    for index in 0..enum_.variants.len do {
      var constant = body.int(index)
      body.call_matching_fun(check, "==" @ src, vec(variant, constant), src)?
      body.jump_if_variant(check, "true", index, src)
    }

    for it in enum_.variants.iter().enumerate() do {
      var variant = it.item
      body.label(it.index, src)

      | doesn't need to be initialized (size 0)
      var static_payload = body.uninitialized(
        type("Static", vec(variant.type)).compile(body.ast, body.mono)?)

      var payload = body.uninitialized(variant.type)
      body.call_matching_fun(payload, "generate" @ src,
        vec(static_payload, random, complexity), src)?
      body.set_enum(value, variant.name, payload, src)
      body.jump(enum_.variants.len, src)
    }

    body.label(enum_.variants.len, src)
  }

  body.return_(value, src)
  ok[MonoFunBody, Error](body.finish())
}

fun compile_fuzzing_complexity_fun(
  type_args: Vec[Type], arg_types: Vec[Type], body: &MonoBodyBuilder, src: Src
): Result[MonoFunBody, Error] {
  arg_types.len == 1 or return error[MonoFunBody, Error](make_error(
    src, "fuzzing_complexity should only take one argument."))
  var value_ty = arg_types.get(0)

  var value = body.arg(value_ty, 0)
  var complexity = body.float(0.to_float())

  switch body.mono.type_defs.get(value_ty)
  case opaque_ {
    var one = body.float(1.to_float())
    body.assign(complexity, one, src)
  }
  case struct_(struct_) {
    | complexity = complexity + value.foo.fuzzing_complexity()
    | complexity = complexity + value.bar.fuzzing_complexity()

    var field_complexity = body.uninitialized(type("Float"))
    for field in struct_.fields.iter() do {
      body.call_matching_fun(field_complexity, "fuzzing_complexity" @ src,
        vec(value.member(field)), src)?
      body.call_matching_fun(complexity, "+" @ src,
        vec(complexity, field_complexity), src)?
    }
  }
  case enum_(enum_) {
    | switch enum
    | case foo(payload) complexity = payload.fuzzing_complexity()
    | case bar(payload) complexity = payload.fuzzing_complexity()

    for it in enum_.variants.iter().enumerate() do
      body.jump_if_variant(value, it.item.name, it.index, src)
    for it in enum_.variants.iter().enumerate() do {
      body.label(it.index, src)
      var variant = it.item
      var payload = body.uninitialized(variant.type)
      body.get_enum_value(payload, value, variant.name, src)
      body.call_matching_fun(
        complexity, "fuzzing_complexity" @ src, vec(payload), src)?
      body.jump(enum_.variants.len, src)
    }

    body.label(enum_.variants.len, src)
  }

  body.return_(complexity, src)

  ok[MonoFunBody, Error](body.finish())
}

fun compile_mutate_fun(
  type_args: Vec[Type], arg_types: Vec[Type], body: &MonoBodyBuilder, src: Src
): Result[MonoFunBody, Error] {
  arg_types.len == 3 or return error[MonoFunBody, Error](make_error(
    src, "mutate should take exactly three arguments."))
  var value_ty = arg_types.get(0)
  arg_types.get(1) == type("&", vec(type("Random")))
    or return error[MonoFunBody, Error](make_error(
      src, "mutate should take a &Random as the second argument."))
  arg_types.get(2) == type("Int")
    or return error[MonoFunBody, Error](make_error(
      src, "mutate should take a temperature Int as the third argument."))

  var value = body.arg(value_ty, 0)
  var random = body.arg(type("&", vec(type("Random"))), 1)
  var temperature = body.arg(type("Int"), 2)
  var nothing = body.uninitialized(type("Nothing"))
  var result = body.uninitialized(value_ty)

  switch body.mono.type_defs.get(value_ty)
  case opaque_ return error[MonoFunBody, Error](make_error(src,
    "For opaque types, you need to implement a mutate function yourself."))
  case struct_(struct_) {
    | var field_to_change = random.next_int(0..2)
    | SomeStruct {
    |   foo = if field_to_change == 0 then value.foo.mutate(random, temperature) else value.foo,
    |   bar = if field_to_change == 1 then value.bar.mutate(random, temperature) else value.bar,
    | }
    if struct_.fields.len > 0 then {
      var range = body.uninitialized(type("Range", vec(type("Int"))))
      body.call_matching_fun(range, ".." @ src,
        vec(body.int(0), body.int(struct_.fields.len)), src)?
      var field_to_change = body.uninitialized(type("Int"))
      body.call_matching_fun(field_to_change, "next_int" @ src,
        vec(random, range), src)?

      var check = body.uninitialized(type("Bool"))
      for it in struct_.fields.iter().enumerate() do {
        var field = it.item

        body.label(it.index, src)
        body.call_matching_fun(check, "==" @ src,
          vec(field_to_change, body.int(it.index)), src)?
        body.assign(result.member(field), value.member(field), src)
        body.jump_if_variant(check, "false", it.index + 1, src)

        var new_field_value = body.uninitialized(field.type)
        body.call_matching_fun(new_field_value, "mutate" @ src,
          vec(value.member(field), random, temperature), src)?
        body.assign(value.member(field), new_field_value, src)
      }

      body.label(struct_.fields.len, src)
    }
  }
  case enum_(enum_) {
    | if random.next_in(0..=temperature) > 50 then
    |   return Static[SomeEnum]{}.generate(random, 100)
    | switch enum
    | case foo(payload) SomeEnum.foo(payload.mutate(random, temperature))
    | case bar(payload) SomeEnum.bar(payload.mutate(random, temperature))
    if enum_.variants.len == 0 then return error[MonoFunBody, Error](make_error(
      src, "Can't mutate instances of {value_ty}."))

    type("Bool").compile(body.ast, body.mono)?
    type("Range", vec(type("Int"))).compile(body.ast, body.mono)?

    var lower = body.int(0)
    var upper = body.int(enum_.variants.len)
    var range = body.uninitialized(type("Range", vec(type("Int"))))
    body.call_matching_fun(range, ".." @ src, vec(lower, upper), src)?

    var choice = body.uninitialized(type("Int"))
    body.call_matching_fun(choice, "next_int" @ src, vec(random, range), src)?

    var is_greater = body.uninitialized(type("Bool"))
    body.call_matching_fun(
      is_greater, ">" @ src, vec(choice, body.int(50)), src)?
    body.jump_if_variant(is_greater, "true", enum_.variants.len, src)

    for it in enum_.variants.iter().enumerate() do
      body.jump_if_variant(value, it.item.name, it.index, src)
    for it in enum_.variants.iter().enumerate() do {
      body.label(it.index, src)
      var variant = it.item
      var payload = body.uninitialized(variant.type)
      body.get_enum_value(payload, value, variant.name, src)

      var new_payload = body.uninitialized(variant.type)
      body.call_matching_fun(
        new_payload, "mutate" @ src, vec(payload, random, temperature), src)?
      body.set_enum(value, variant.name, new_payload, src)
      body.jump(enum_.variants.len + 1, src)
    }

    body.label(enum_.variants.len, src)

    | doesn't need to be initialized (size 0)
    var static_payload = body.uninitialized(
      type("Static", vec(value_ty)).compile(body.ast, body.mono)?)

    body.call_matching_fun(value, "mutate" @ src,
      vec(static_payload, random, temperature), src)?
    body.jump(enum_.variants.len + 1, src)
    body.label(enum_.variants.len + 1, src)
  }

  body.return_(value, src)

  ok[MonoFunBody, Error](body.finish())
}

| Soil Binary  
| Martinaise compiles to Soil binaries. Soil is a virtual machine spec that is
| also designed by me. It is on a similar abstraction level as assembly, but
| simpler and platform-agnostic. To understand the following section, I suggest
| reading up on it in more detail: https://github.com/MarcelGarus/soil

struct Soil {
  initial_mem: Map[Str, Slice[Byte]], | map from mem label to bytes
  instructions: Vec[Instr],
  srcs: Vec[Src],
  | TODO: OrderedMap in stdlib
  labels_to_index: Map[Str, Int], | maps label to the instruction index
  labels: Vec[Str], | only so that labels can be printed in order
}
enum Instr {
  nop,
  panic,
  trystart: Int, | instruction index
  tryend,
  move: RegAndReg,
  movei: RegAndInt,
  moveib: RegAndByte,
  moveimem: RegAndStr, | compiles to a movei with the memory address
  load: RegAndReg,
  loadb: RegAndReg,
  store: RegAndReg,
  storeb: RegAndReg,
  push: Reg,
  pop: Reg,
  jump: Int,  | instruction index
  cjump: Int, | instruction index
  call: Int,  | instruction index
  ret,
  syscall: Byte,
  cmp: RegAndReg,
  isequal,
  isless,
  isgreater,
  islessequal,
  isgreaterequal,
  isnotequal,
  fcmp: RegAndReg,
  fisequal,
  fisless,
  fisgreater,
  fislessequal,
  fisgreaterequal,
  fisnotequal,
  inttofloat: Reg,
  floattoint: Reg,
  add: RegAndReg,
  sub: RegAndReg,
  mul: RegAndReg,
  div: RegAndReg,
  rem: RegAndReg,
  fadd: RegAndReg,
  fsub: RegAndReg,
  fmul: RegAndReg,
  fdiv: RegAndReg,
  and: RegAndReg,
  or: RegAndReg,
  xor: RegAndReg,
  negate: Reg,
}
struct RegAndStr { reg: Reg, str: Str }
struct RegAndInt { reg: Reg, int: Int }

fun &(reg: Reg, str: Str): RegAndStr { RegAndStr { reg, str } }
fun &(reg: Reg, int: Int): RegAndInt { RegAndInt { reg, int } }

fun write[W](writer: W, soil: Soil) {
  var index_to_label = map[Int, Str]()
  for it in soil.labels_to_index do index_to_label.&.put(it.value, it.key)
  for it in soil.instructions.iter().zip(soil.srcs.iter()).enumerate() do {
    var index = it.index
    var instruction = it.item.a
    var src = it.item.b

    writer."{"{index}".pad_left(6)} | {"{instruction}".pad_right(20)} | {
        switch src.to_code_range()
        case some(range) "{src.file} {range.start}"
        case none src.file
      }{
        switch read_cached_code(src.file)
        case some(code) " {code.substr(src.span)}"
        case none ""
      }{
        if index_to_label.get_maybe(index) is some(label)
        then " {label}"
        else ""
      }\n"
  }
  writer."\nInitial memory:\n"
  for entry in soil.initial_mem do {
    writer."{entry.key}:"
    for byte in entry.value do writer." {byte}"
    writer."\n"
  }
}
fun write[W](writer: W, instruction: Instr) {
  switch instruction
  case nop             { writer."nop" }
  case panic           { writer."panic" }
  case trystart(arg)   { writer."trystart {arg}" }
  case tryend          { writer."tryend" }
  case move(args)      { writer."move {args.first} {args.second}" }
  case movei(args)     { writer."movei {args.reg} {args.int}" }
  case moveib(args)    { writer."moveib {args.reg} {args.byte}" }
  case moveimem(args)  { writer."movei {args.reg} {args.str}" }
  case load(args)      { writer."load {args.first} {args.second}" }
  case loadb(args)     { writer."loadb {args.first} {args.second}" }
  case store(args)     { writer."store {args.first} {args.second}" }
  case storeb(args)    { writer."storeb {args.first} {args.second}" }
  case push(arg)       { writer."push {arg}" }
  case pop(arg)        { writer."pop {arg}" }
  case jump(arg)       { writer."jump {arg}" }
  case cjump(arg)      { writer."cjump {arg}" }
  case call(arg)       { writer."call {arg}" }
  case ret             { writer."ret" }
  case syscall(arg)    { writer."syscall {arg}" }
  case cmp(args)       { writer."cmp {args.first} {args.second}" }
  case isequal         { writer."isequal" }
  case isless          { writer."isless" }
  case isgreater       { writer."isgreater" }
  case islessequal     { writer."islessequal" }
  case isgreaterequal  { writer."isgreaterequal" }
  case isnotequal      { writer."isnotequal" }
  case fcmp(args)      { writer."fcmp {args.first} {args.second}" }
  case fisequal        { writer."fisequal" }
  case fisless         { writer."fisless" }
  case fisgreater      { writer."fisgreater" }
  case fislessequal    { writer."fislessequal" }
  case fisgreaterequal { writer."fisgreaterequal" }
  case fisnotequal     { writer."fisnotequal" }
  case inttofloat(arg) { writer."inttofloat {arg}" }
  case floattoint(arg) { writer."floattoint {arg}" }
  case add(args)       { writer."add {args.first} {args.second}" }
  case sub(args)       { writer."sub {args.first} {args.second}" }
  case mul(args)       { writer."mul {args.first} {args.second}" }
  case div(args)       { writer."div {args.first} {args.second}" }
  case rem(args)       { writer."rem {args.first} {args.second}" }
  case fadd(args)      { writer."fadd {args.first} {args.second}" }
  case fsub(args)      { writer."fsub {args.first} {args.second}" }
  case fmul(args)      { writer."fmul {args.first} {args.second}" }
  case fdiv(args)      { writer."fdiv {args.first} {args.second}" }
  case and(args)       { writer."and {args.first} {args.second}" }
  case or(args)        { writer."or {args.first} {args.second}" }
  case xor(args)       { writer."xor {args.first} {args.second}" }
  case negate(arg)     { writer."negate {arg}" }
}

| Assembling  
| The process of converting the Mono to Soil assembly is called "assembling".
| The assembler has a function for every assembly instruction, for example:
|
| - ret()
| - add(Reg, Reg)
| - movei(Reg, Int)
| - ...
|
| This way, the assembly instructions are type checked in Martinaise (for
| example, you can't add an Int to a Reg).
|
| The compiler can also call set_src() to change which src emitted
| instructions are attributed to.

struct Asm {
  current_src: Src,
  last_label: Str,
  patches: Vec[Patch],
  soil: Soil,
}
struct Patch { where: Int, label: Str} | where is the instruction index

fun set_src(asm: &Asm, src: Src) { asm.current_src = src }

| If the last label was foo.bar, and you define a new label ..baz:, then this
| gets globalized to foo.bar.baz. In general, for each leading dot, a component
| from the current label gets used.
fun globalize(asm: Asm, label: Str): Result[Str, Str] {
  var num_dots = 0
  loop
    if label.chars().get_maybe(num_dots) == some(#.)
    then num_dots = num_dots + 1
    else break
  if num_dots == 0 then return ok[Str, Str](label)
  label = label.substr(num_dots..label.len)
  var shared_prefix = 0
  loop {
    if shared_prefix >= asm.last_label.len then {
      if num_dots == 1 then break
      return error[Str, Str]("Label has too many dots at the beginning.")
    }
    if asm.last_label.chars().get(shared_prefix) == #. then {
      num_dots = num_dots - 1
      if num_dots == 0 then break
    }
    shared_prefix = shared_prefix + 1
  }
  var global = vec[Char]()
  global.&.push_all(asm.last_label.substr(0..shared_prefix).chars())
  global.&.push(#.)
  for i in 0..label.len do global.&.push(label.chars().get(i))
  ok[Str, Str](global.to_str())
}

fun define_label(asm: &Asm, label: Str) {
  label = asm.globalize(label).unwrap()
  asm.soil.labels.&.push(label)
  asm.soil.labels_to_index.&.put(label, asm.soil.instructions.len)
  asm.last_label = label
}
fun define_disambiguated_label(asm: &Asm, prefix: Str): Str {
  var label = "{prefix}.{asm.bytes.len()}"
  asm.label(label)
  label
}
fun label(asm: &Asm, label: Str): Int {
  label = asm.globalize(label).unwrap()
  asm.patches.&.push(Patch { where = asm.soil.instructions.len, label })
  0
}

| Instructions
fun emit(asm: &Asm, instruction: Instr) {
  asm.soil.instructions.&.push(instruction)
  asm.soil.srcs.&.push(asm.current_src)
}
fun nop(asm: &Asm)                      { asm.emit(Instr.nop) }
fun panic(asm: &Asm)                    { asm.emit(Instr.panic) }
fun trystart(asm: &Asm, catch: Int)     { asm.emit(Instr.trystart(catch)) }
fun tryend(asm: &Asm)                   { asm.emit(Instr.tryend) }
fun move(asm: &Asm, a: Reg, b: Reg)     { asm.emit(Instr.move(a & b)) }
fun movei(asm: &Asm, a: Reg, b: Int)    { asm.emit(Instr.movei(a & b)) }
fun moveib(asm: &Asm, a: Reg, b: Byte)  { asm.emit(Instr.moveib(a & b)) }
fun moveimem(asm: &Asm, a: Reg, b: Str) { asm.emit(Instr.moveimem(a & b)) }
fun load(asm: &Asm, a: Reg, b: Reg)     { asm.emit(Instr.load(a & b)) }
fun loadb(asm: &Asm, a: Reg, b: Reg)    { asm.emit(Instr.loadb(a & b)) }
fun store(asm: &Asm, a: Reg, b: Reg)    { asm.emit(Instr.store(a & b)) }
fun storeb(asm: &Asm, a: Reg, b: Reg)   { asm.emit(Instr.storeb(a & b)) }
fun push(asm: &Asm, a: Reg)             { asm.emit(Instr.push(a)) }
fun pop(asm: &Asm, a: Reg)              { asm.emit(Instr.pop(a)) }
fun jump(asm: &Asm, a: Int)             { asm.emit(Instr.jump(a)) }
fun cjump(asm: &Asm, a: Int)            { asm.emit(Instr.cjump(a)) }
fun call(asm: &Asm, a: Int)             { asm.emit(Instr.call(a)) }
fun ret(asm: &Asm)                      { asm.emit(Instr.ret) }
fun syscall(asm: &Asm, a: Byte)         { asm.emit(Instr.syscall(a)) }
fun cmp(asm: &Asm, a: Reg, b: Reg)      { asm.emit(Instr.cmp(a & b)) }
fun isequal(asm: &Asm)                  { asm.emit(Instr.isequal) }
fun isless(asm: &Asm)                   { asm.emit(Instr.isless) }
fun isgreater(asm: &Asm)                { asm.emit(Instr.isgreater) }
fun islessequal(asm: &Asm)              { asm.emit(Instr.islessequal) }
fun isgreaterequal(asm: &Asm)           { asm.emit(Instr.isgreaterequal) }
fun isnotequal(asm: &Asm)               { asm.emit(Instr.isnotequal) }
fun fcmp(asm: &Asm, a: Reg, b: Reg)     { asm.emit(Instr.fcmp(a & b)) }
fun fisequal(asm: &Asm)                 { asm.emit(Instr.fisequal) }
fun fisless(asm: &Asm)                  { asm.emit(Instr.fisless) }
fun fisgreater(asm: &Asm)               { asm.emit(Instr.fisgreater) }
fun fislessequal(asm: &Asm)             { asm.emit(Instr.fislessequal) }
fun fisgreaterequal(asm: &Asm)          { asm.emit(Instr.fisgreaterequal) }
fun fisnotequal(asm: &Asm)              { asm.emit(Instr.fisnotequal) }
fun inttofloat(asm: &Asm, a: Reg)       { asm.emit(Instr.inttofloat(a)) }
fun floattoint(asm: &Asm, a: Reg)       { asm.emit(Instr.floattoint(a)) }
fun add(asm: &Asm, a: Reg, b: Reg)      { asm.emit(Instr.add(a & b)) }
fun sub(asm: &Asm, a: Reg, b: Reg)      { asm.emit(Instr.sub(a & b)) }
fun mul(asm: &Asm, a: Reg, b: Reg)      { asm.emit(Instr.mul(a & b)) }
fun div(asm: &Asm, a: Reg, b: Reg)      { asm.emit(Instr.div(a & b)) }
fun rem(asm: &Asm, a: Reg, b: Reg)      { asm.emit(Instr.rem(a & b)) }
fun fadd(asm: &Asm, a: Reg, b: Reg)     { asm.emit(Instr.fadd(a & b)) }
fun fsub(asm: &Asm, a: Reg, b: Reg)     { asm.emit(Instr.fsub(a & b)) }
fun fmul(asm: &Asm, a: Reg, b: Reg)     { asm.emit(Instr.fmul(a & b)) }
fun fdiv(asm: &Asm, a: Reg, b: Reg)     { asm.emit(Instr.fdiv(a & b)) }
fun and(asm: &Asm, a: Reg, b: Reg)      { asm.emit(Instr.and(a & b)) }
fun or(asm: &Asm, a: Reg, b: Reg)       { asm.emit(Instr.or(a & b)) }
fun xor(asm: &Asm, a: Reg, b: Reg)      { asm.emit(Instr.xor(a & b)) }
fun negate(asm: &Asm, a: Reg)           { asm.emit(Instr.negate(a)) }

fun mangle(name: Str): Str {
  var contains_dot = false
  for char in name do if char == #. then contains_dot = true
  if contains_dot then {
    var str = string_builder()
    for char in name do if char == #. then str.&."[dot]" else str.&."{char}"
    str.to_str()
  } else name
}

fun name_to_offset_map(parts: Vec[MemLayoutStructPart]): Map[Str, Int] {
  var offsets = map[Str, Int]()
  var offset = 0
  for part in parts do
    offset = offset +
      switch part
      case padding(padding) padding
      case field(field) {
        offsets.&.put(field.name, offset)
        field.layout.size
      }
  offsets
}

fun assemble(mono: Mono, entry_point: Str, asm: &Asm): Result[Nothing, Error] {
  for global in mono.globals do
    asm.soil.initial_mem.&.put(global.key,
      filled_slice(mono.layouts.get(global.value.return_type).size,
        0.lower_byte()))
  asm.soil.initial_mem.&.put("_coverage_bitset", empty_slice[Byte]())
  asm.soil.initial_mem.&.put("_coverage_len", filled_slice(8, 0.lower_byte()))

  asm.set_src(src("_setup", 0..0))
  asm.define_label("_start")
  asm.push(Reg.a)
  for global in mono.globals_init_order do {
    asm.moveimem(Reg.a, global)
    asm.store(Reg.sp, Reg.a)
    asm.call(asm.label("{global}.init"))
  }
  asm.define_label("_entry_point")
  asm.moveib(Reg.a, 0.lower_byte())
  asm.store(Reg.sp, Reg.a)
  asm.call(asm.label(entry_point))

  var arg_layouts = map[Str, MemLayout]() | fun signature to arg layouts
  for fun_ in mono.funs do {
    var name = fun_.key
    var arg_struct = MonoStruct { fields = vec[MonoStructField]() }
    for arg in fun_.value.arg_types.iter().enumerate() do
      arg_struct.fields.&.push(MonoStructField {
        name = "arg_{arg.index}", type = arg.item,
      })
    arg_layouts.&.put(name, calculate_mem_layout(
      type("arguments of {name}"), MonoTypeDef.struct_(arg_struct),
      mono.layouts.&, mono.type_defs,
    ))
  }

  for global in mono.globals do {
    arg_layouts.&.put(global.key, MemLayout {
      type = type("Nothing"),
      size = 0,
      alignment = 1,
      kind = MemLayoutKind.struct_(vec[MemLayoutStructPart]()),
    })
    asm.define_label("{global.key}.init")
    global.value.assemble_body(global.key, mono, arg_layouts, asm)?
  }

  for fun_ in mono.funs do {
    var signature = fun_.key
    var fun_ = fun_.value
    asm.define_label(signature.mangle())
    fun_.assemble_body(signature, mono, arg_layouts, asm)?
  }

  asm.ret()

  for it in asm.soil.instructions.iter().enumerate() do
    if it.item is moveimem(reg_and_label) then {
      var label = reg_and_label.str
      if not(asm.soil.initial_mem.contains(label)) and
        label != "_end_of_initial_memory"
      then return error[Nothing, Error](make_error(
        asm.soil.srcs.get(it.index), "Label {label} doesn't exist.",
        "Note that movei only accepts labels of globals that your program 
          'references in Martinaise code somewhere else.",
        vec[Str](),
      ))
    }

  ok[Nothing, Error]({})
}

fun smart_movei(asm: &Asm, reg: Reg, immediate: Int) {
  if {0..256}.contains(immediate)
  then asm.moveib(reg, immediate.lower_byte())
  else asm.movei(reg, immediate)
}
fun smart_move_and_add_offset(asm: &Asm, to: Reg, from: Reg, offset: Int) {
  if offset == 0 then asm.move(to, from) else {
    asm.smart_movei(to, offset)
    asm.add(to, from)
  }
}
fun smart_addi(asm: &Asm, to: Reg, value: Int, scratch: Reg) {
  if value != 0 then {
    asm.smart_movei(scratch, value)
    asm.add(to, scratch)
  }
}

fun assemble_body(
  fun_: MonoFun, signature: Str,
  mono: Mono, arg_layouts: Map[Str, MemLayout], asm: &Asm,
): Result[Nothing, Error] {
  var layouts = mono.layouts
  asm.set_src(fun_.name.src)

  switch fun_.kind
  case body(body) {
    var arg_offsets =
      arg_layouts.get(signature).kind.struct_.unwrap().name_to_offset_map()

    | Layout locals
    var locals_struct = MonoStruct { fields = vec[MonoStructField]() }
    for slot in body.slots.iter().enumerate() do {
      if slot.item.initial_value is arg then continue | already on the stack
      locals_struct.fields.&.push(MonoStructField {
        name = "local_{slot.index}", type = slot.item.type,
      })
    }
    var locals_layout = calculate_mem_layout(
      type("locals of {signature}"), MonoTypeDef.struct_(locals_struct),
      layouts.&, mono.type_defs,
    )
    var locals_offsets =
      locals_layout.kind.struct_.unwrap().name_to_offset_map()
    var locals_size = locals_layout.size.round_up_to_multiple_of(8)

    | Combine all slots – args and locals
    var slot_offsets = map[MonoSlotRef, Int]() | relative to sp
    for slot in body.slots.iter().enumerate() do {
      var offset =
        if slot.item.initial_value is arg
        then locals_size
          + 8 | return value
          + arg_offsets.get("arg_{slot.index}")
        else locals_offsets.get("local_{slot.index}")
      slot_offsets.&.put(MonoSlotRef { index = slot.index }, offset)
    }

    asm.smart_movei(Reg.a, locals_size)
    asm.sub(Reg.sp, Reg.a)

    for slot in slot_offsets do {
      var offset = slot.value
      var slot = slot.key
      switch body.slots.get(slot.index).initial_value
      case uninitialized {}
      case arg {}
      case int(int) {
        asm.smart_move_and_add_offset(Reg.a, Reg.sp, offset)
        asm.smart_movei(Reg.b, int)
        asm.store(Reg.a, Reg.b)
      }
      case float(float) {
        asm.smart_move_and_add_offset(Reg.a, Reg.sp, offset)
        asm.smart_movei(Reg.b, float.cast[Float, Int]())
        asm.store(Reg.a, Reg.b)
      }
      case str(str) {
        var str_label = "$str_{asm.soil.initial_mem.size}"
        asm.soil.initial_mem.&.put(str_label, str.bytes())
        asm.smart_move_and_add_offset(Reg.a, Reg.sp, offset)
        asm.moveimem(Reg.b, str_label)
        asm.store(Reg.a, Reg.b)
        asm.smart_addi(Reg.a, 8, Reg.b)
        asm.smart_movei(Reg.b, str.bytes().len)
        asm.store(Reg.a, Reg.b)
      }
    }

    for statement in body.statements do {
      var src = statement.src
      var statement = statement.statement

      asm.set_src(src)

      switch statement
      case nop asm.nop()
      case label(label) asm.define_label("{label}")
      case assign(assign) {
        var size = layouts.get(assign.value.type).size
        asm.save_address(Reg.a, assign.value, 0, slot_offsets, layouts, Reg.c)
        asm.save_address(Reg.b, assign.to, 0, slot_offsets, layouts, Reg.c)
        asm.copy_memory(Reg.a, Reg.b, size, Reg.c)
      }
      case set_enum(set) {
        var type = set.to.type
        var variant = 0
        var enum_ = mono.type_defs.get(type).enum_.unwrap()
        for v in enum_.variants.iter().enumerate() do
          if v.item.name == set.variant then variant = v.index

        | Save the target into a.
        asm.save_address(Reg.a, set.to, 0, slot_offsets, layouts, Reg.c)

        | Store the variant tag.
        var tag_offset = layouts.get(type).size - 1
        asm.smart_move_and_add_offset(Reg.b, Reg.a, tag_offset)
        asm.moveib(Reg.c, variant.lower_byte())
        asm.storeb(Reg.b, Reg.c)

        | Store the payload.
        var payload_size = layouts.get(set.payload.type).size
        asm.save_address(Reg.b, set.payload, 0, slot_offsets, layouts, Reg.c)
        asm.copy_memory(Reg.b, Reg.a, payload_size, Reg.c)
      }
      case call(call) {
        var args_layout = arg_layouts.get_maybe(call.fun_)
          or panic("no arg layout for {call.fun_} available")
        var arg_offsets = args_layout.kind.struct_.unwrap().name_to_offset_map()
        var args_size = args_layout.size.round_up_to_multiple_of(8)

        | Prepare args
        asm.smart_movei(Reg.a, args_size)
        asm.sub(Reg.sp, Reg.a)
        for arg in call.args.iter().enumerate() do {
          var size = layouts.get(arg.item.type).size
          var offset_in_args = arg_offsets.get("arg_{arg.index}")
          asm.save_address(
            Reg.a, arg.item, args_size, slot_offsets, layouts, Reg.c
          )
          asm.smart_move_and_add_offset(Reg.b, Reg.sp, offset_in_args)
          asm.copy_memory(Reg.a, Reg.b, size, Reg.c)
        }

        | Prepare return address
        asm.save_address(Reg.a, call.to, args_size, slot_offsets, layouts, Reg.b)
        asm.moveib(Reg.b, 8.lower_byte())
        asm.sub(Reg.sp, Reg.b)
        asm.store(Reg.sp, Reg.a)

        | Make the call
        asm.call(asm.label(call.fun_.mangle()))

        | Restore stack
        asm.smart_addi(Reg.sp, args_size + 8, Reg.a)
      }
      case try_start(catch) asm.trystart(asm.label("{catch}"))
      case try_end asm.tryend()
      case jump(jump) asm.jump(asm.label("{jump.target}"))
      case jump_if_variant(jump) {
        var type = jump.condition.type
        var variant_tag_offset = layouts.get(type).size - 1
        var checked_tag = 0.lower_byte()
        var enum_ = mono.type_defs.get(type).enum_
          or panic("jump_if_variant of a non-enum")
        for v in enum_.variants.iter().enumerate() do
          if v.item.name == jump.variant then checked_tag = v.index.lower_byte()

        asm.save_address(Reg.a, jump.condition, 0, slot_offsets, layouts, Reg.b)
        asm.smart_addi(Reg.a, variant_tag_offset, Reg.b)
        asm.loadb(Reg.a, Reg.a)
        asm.moveib(Reg.b, checked_tag)
        asm.cmp(Reg.a, Reg.b)
        asm.isequal()
        asm.cjump(asm.label("{jump.target}"))
      }
      case get_enum_value(get) {
        var variant_type = get.to.type
        var size = layouts.get(variant_type).size

        asm.save_address(Reg.a, get.of, 0, slot_offsets, layouts, Reg.b)
        asm.save_address(Reg.b, get.to, 0, slot_offsets, layouts, Reg.c)
        asm.copy_memory(Reg.a, Reg.b, size, Reg.c)
      }
      case return_(expr) {
        var size = layouts.get(expr.type).size
        if size > 0 then {
          asm.save_address(Reg.a, expr, 0, slot_offsets, layouts, Reg.b)
          asm.smart_move_and_add_offset(Reg.b, Reg.sp, locals_size)
          asm.load(Reg.b, Reg.b)
          asm.copy_memory(Reg.a, Reg.b, size, Reg.c)
        }
        asm.jump(asm.label(".end"))
      }
      case ref(ref) {
        asm.save_address(Reg.a, ref.of, 0, slot_offsets, layouts, Reg.b)
        asm.save_address(Reg.b, ref.to, 0, slot_offsets, layouts, Reg.c)
        asm.store(Reg.b, Reg.a)
      }
    }
    asm.define_label(".end")
    asm.smart_addi(Reg.sp, locals_size, Reg.a)
    asm.ret()
  }
  case asm_(instructions) for instruction in instructions do {
    asm.set_src(instruction.mnemonic.src)
    switch instruction.kind
    | TODO: Ensure that the label is a local label
    case label(label)     asm.define_label(label.str)
    case nop              asm.nop()
    case panic            asm.panic()
    case move(regs)       asm.move(regs.first, regs.second)
    case movei(args) {
      switch args.word
      case label(label)   asm.moveimem(args.reg, label.str)
      case literal(word)  asm.movei(args.reg, word)
      case str(str) {
                          var str_label = "str_{asm.soil.initial_mem.size}"
                          asm.soil.initial_mem.&.put(str_label, str.bytes())
                          asm.moveimem(args.reg, str_label)
      }
    }
    case moveib(args)     asm.moveib(args.reg, args.byte)
    case load(regs)       asm.load(regs.first, regs.second)
    case loadb(regs)      asm.loadb(regs.first, regs.second)
    case store(regs)      asm.store(regs.first, regs.second)
    case storeb(regs)     asm.storeb(regs.first, regs.second)
    case push(reg)        asm.push(reg)
    case pop(reg)         asm.pop(reg)
    case jump(word)       asm.jump(asm.label(word.str))
    case cjump(word)      asm.cjump(asm.label(word.str))
    case call(word)       asm.call(asm.label(word.str))
    case ret              asm.ret()
    case syscall(byte)    asm.syscall(byte)
    case cmp(regs)        asm.cmp(regs.first, regs.second)
    case isequal          asm.isequal()
    case isless           asm.isless()
    case isgreater        asm.isgreater()
    case islessequal      asm.islessequal()
    case isgreaterequal   asm.isgreaterequal()
    case isnotequal       asm.isnotequal()
    case fcmp(regs)       asm.fcmp(regs.first, regs.second)
    case fisequal         asm.fisequal()
    case fisless          asm.fisless()
    case fisgreater       asm.fisgreater()
    case fislessequal     asm.fislessequal()
    case fisgreaterequal  asm.fisgreaterequal()
    case fisnotequal      asm.fisnotequal()
    case inttofloat(reg)  asm.inttofloat(reg)
    case floattoint(reg)  asm.floattoint(reg)
    case add(regs)        asm.add(regs.first, regs.second)
    case sub(regs)        asm.sub(regs.first, regs.second)
    case mul(regs)        asm.mul(regs.first, regs.second)
    case div(regs)        asm.div(regs.first, regs.second)
    case rem(regs)        asm.rem(regs.first, regs.second)
    case fadd(regs)       asm.fadd(regs.first, regs.second)
    case fsub(regs)       asm.fsub(regs.first, regs.second)
    case fmul(regs)       asm.fmul(regs.first, regs.second)
    case fdiv(regs)       asm.fdiv(regs.first, regs.second)
    case and(regs)        asm.and(regs.first, regs.second)
    case or(regs)         asm.or(regs.first, regs.second)
    case xor(regs)        asm.xor(regs.first, regs.second)
    case negate(reg)      asm.negate(reg)
  }

  ok[Nothing, Error]({})
}

| Saves the address of the expr in the register.
fun save_address(
  asm: &Asm, register: Reg, expr: MonoExpr, locals_offset: Int,
  slot_offsets: Map[MonoSlotRef, Int], layouts: Map[Type, MemLayout],
  scratch: Reg,
) {
  switch expr.kind
  case nothing {} | you can read zero bytes from anywhere
  case never {}   | you can read zero bytes from anywhere
  case global(name) asm.moveimem(register, name)
  case slot(slot) {
    asm.smart_move_and_add_offset(register, Reg.sp,
      locals_offset + slot_offsets.get(slot))
  }
  case member(member) {
    asm.save_address(
      register, member.of.*, locals_offset, slot_offsets, layouts, scratch)
    if member.name == "*"
    then asm.load(register, register)
    else {
      var offset_in_struct =
        switch layouts.get(member.of.type).kind
        case struct_(s) s.name_to_offset_map().get(member.name)
        case enum_(e) panic("member receiver is an enum")
        case opaque_ panic("can't access member {member.of.type}.{member.name} 
          'because {member.of.type} is opaque")
      asm.smart_addi(register, offset_in_struct, scratch)
    }
  }
}

fun copy_memory(asm: &Asm, from: Reg, to: Reg, amount: Int, scratch: Reg) {
  if amount == 0 then return {}
  loop {
    if amount >= 8 then {
      asm.load(scratch, from)
      asm.store(to, scratch)
      amount = amount - 8
      if amount == 0 then break else {
        asm.moveib(scratch, 8.lower_byte())
        asm.add(from, scratch)
        asm.add(to, scratch)
      }
    } else {
      asm.loadb(scratch, from)
      asm.storeb(to, scratch)
      amount = amount - 1
      if amount == 0 then break else {
        asm.moveib(scratch, 1.lower_byte())
        asm.add(from, scratch)
        asm.add(to, scratch)
      }
    }
  }
}

fun fix_patches(asm: &Asm): Result[Nothing, Error] {
  for patch in asm.patches do {
    var target = asm.soil.labels_to_index.get_maybe(patch.label)
      or return error[Nothing, Error](make_error(
        asm.soil.srcs.get(patch.where),
        "Label {patch.label} doesn't exist",
        {
          | TODO: reformat
          var builder = string_builder().&
          builder."Note that only functions and constants referenced by 
            'Martinaise code are compiled."
          | for label in asm.soil.labels_to_index do builder."\n- {label.key}"
          builder.to_str()
        },
        vec[Str]()
      ))
    switch asm.soil.instructions.get(patch.where)
    case jump asm.soil.instructions.get_ref(patch.where).* = Instr.jump(target)
    case cjump asm.soil.instructions.get_ref(patch.where).* = Instr.cjump(target)
    case call asm.soil.instructions.get_ref(patch.where).* = Instr.call(target)
    case trystart
      asm.soil.instructions.get_ref(patch.where).* = Instr.trystart(target)
    default unreachable()
  }
  asm.patches.len = 0
  ok[Nothing, Error]({})
}

fun soil(mono: Mono): Result[Soil, Error] {
  print_status("Assembling")

  var asm = Asm {
    current_src = src("_nowhere", 0..0),
    last_label = "",
    patches = vec[Patch](),
    soil = Soil {
      initial_mem = map[Str, Slice[Byte]](),
      instructions = vec[Instr](),
      srcs = vec[Src](),
      labels_to_index = map[Str, Int](),
      labels = vec[Str](),
    },
  }
  mono.assemble(mono.entry_point, asm.&)?
  asm.&.fix_patches()?

  ok[Soil, Error](asm.soil)
}

| Binary-fication  
| The Soil VM can only run Soil binaries, which contain instructions and byte
| code in a compact form. Here is the functionality for serializing a Soil into
| that.

fun to_binary(soil: Soil): Slice[Byte] {
  print_status("Assembling binary")

  var bin = SoilBinary { bytes = vec[Byte]() }.&

  | magic bytes
  bin.emit("soil".bytes())

  | initial memory section
  bin.emit_byte(1)
  bin.emit(0) | len, will be overwritten
  var mem_start = bin.bytes.len
  var mem_label_to_offset = map[Str, Int]() | mem label to offset
  for entry in soil.initial_mem do {
    mem_label_to_offset.&.put(entry.key, bin.bytes.len - mem_start)
    for byte in entry.value do bin.bytes.&.push(byte)
  }
  mem_label_to_offset.&.put("_end_of_initial_memory", bin.bytes.len - mem_start)
  var mem_end = bin.bytes.len
  bin.overwrite(mem_start - 8, mem_end - mem_start)

  | byte code section
  bin.emit_byte(0)
  bin.emit(0) | len, will be overwritten
  var byte_code_start = bin.bytes.len
  var instruction_index_to_byte_code_offset =
    uninitialized_slice[Int](soil.instructions.len)
  var patches = map[Int, Int]() | offset in binary to instruction index
  for it in soil.instructions.iter().enumerate() do {
    instruction_index_to_byte_code_offset.get_ref(it.index).* =
      bin.bytes.len - byte_code_start
    switch it.item
    case nop                  { bin.emit_byte(16#00) }
    case panic                { bin.emit_byte(16#e0) }
    case trystart(word)       { bin.emit_byte(16#e1)
                                patches.&.put(bin.bytes.len, word)
                                bin.emit(0) }
    case tryend               { bin.emit_byte(16#e2) }
    case move(regs)           { bin.emit_byte(16#d0) bin.emit(regs) }
    case movei(reg_and_word)  { bin.emit_byte(16#d1) bin.emit(reg_and_word) }
    case moveib(reg_and_byte) { bin.emit_byte(16#d2) bin.emit(reg_and_byte) }
    case moveimem(reg_and_str) { bin.emit_byte(16#d1)
                                bin.emit(reg_and_str.reg &
                                  mem_label_to_offset.get(reg_and_str.str)) }
    case load(regs)           { bin.emit_byte(16#d3) bin.emit(regs) }
    case loadb(regs)          { bin.emit_byte(16#d4) bin.emit(regs) }
    case store(regs)          { bin.emit_byte(16#d5) bin.emit(regs) }
    case storeb(regs)         { bin.emit_byte(16#d6) bin.emit(regs) }
    case push(reg)            { bin.emit_byte(16#d7) bin.emit(reg) }
    case pop(reg)             { bin.emit_byte(16#d8) bin.emit(reg) }
    case jump(word)           { bin.emit_byte(16#f0)
                                patches.&.put(bin.bytes.len, word)
                                bin.emit(0) }
    case cjump(word)          { bin.emit_byte(16#f1)
                                patches.&.put(bin.bytes.len, word)
                                bin.emit(0) }
    case call(word)           { bin.emit_byte(16#f2)
                                patches.&.put(bin.bytes.len, word)
                                bin.emit(0) }
    case ret                  { bin.emit_byte(16#f3) }
    case syscall(byte)        { bin.emit_byte(16#f4) bin.emit(byte) }
    case cmp(regs)            { bin.emit_byte(16#c0) bin.emit(regs) }
    case isequal              { bin.emit_byte(16#c1) }
    case isless               { bin.emit_byte(16#c2) }
    case isgreater            { bin.emit_byte(16#c3) }
    case islessequal          { bin.emit_byte(16#c4) }
    case isgreaterequal       { bin.emit_byte(16#c5) }
    case isnotequal           { bin.emit_byte(16#c6) }
    case fcmp(regs)           { bin.emit_byte(16#c7) bin.emit(regs) }
    case fisequal             { bin.emit_byte(16#c8) }
    case fisless              { bin.emit_byte(16#c9) }
    case fisgreater           { bin.emit_byte(16#ca) }
    case fislessequal         { bin.emit_byte(16#cb) }
    case fisgreaterequal      { bin.emit_byte(16#cc) }
    case fisnotequal          { bin.emit_byte(16#cd) }
    case inttofloat(reg)      { bin.emit_byte(16#ce) bin.emit(reg) }
    case floattoint(reg)      { bin.emit_byte(16#cf) bin.emit(reg) }
    case add(regs)            { bin.emit_byte(16#a0) bin.emit(regs) }
    case sub(regs)            { bin.emit_byte(16#a1) bin.emit(regs) }
    case mul(regs)            { bin.emit_byte(16#a2) bin.emit(regs) }
    case div(regs)            { bin.emit_byte(16#a3) bin.emit(regs) }
    case rem(regs)            { bin.emit_byte(16#a4) bin.emit(regs) }
    case fadd(regs)           { bin.emit_byte(16#a5) bin.emit(regs) }
    case fsub(regs)           { bin.emit_byte(16#a6) bin.emit(regs) }
    case fmul(regs)           { bin.emit_byte(16#a7) bin.emit(regs) }
    case fdiv(regs)           { bin.emit_byte(16#a8) bin.emit(regs) }
    case and(regs)            { bin.emit_byte(16#b0) bin.emit(regs) }
    case or(regs)             { bin.emit_byte(16#b1) bin.emit(regs) }
    case xor(regs)            { bin.emit_byte(16#b2) bin.emit(regs) }
    case negate(reg)          { bin.emit_byte(16#b3) bin.emit(reg) }
  }
  for patch in patches do {
    var real_target = instruction_index_to_byte_code_offset.get(patch.value)
    bin.overwrite(patch.key, real_target)
  }
  var byte_code_end = bin.bytes.len
  bin.overwrite(byte_code_start - 8, byte_code_end - byte_code_start)

  | labels section
  bin.emit_byte(3)
  bin.emit(0)
  var labels_start = bin.bytes.len
  bin.emit(soil.labels.len)
  for label in soil.labels do {
    var index = soil.labels_to_index.get(label)
    var offset = instruction_index_to_byte_code_offset.get(index)
    bin.emit(offset)
    bin.emit(label.len)
    for char in label do bin.emit(char.byte)
  }
  var labels_end = bin.bytes.len
  bin.overwrite(labels_start - 8, labels_end - labels_start)

  bin.bytes.to_slice()
}
struct SoilBinary { bytes: Vec[Byte] }
fun emit(bin: &SoilBinary, byte: Byte) { bin.bytes.&.push(byte) }
fun emit_byte(bin: &SoilBinary, byte: Int) {
  bin.bytes.&.push(byte.lower_byte())
}
fun emit(bin: &SoilBinary, bytes: Slice[Byte]) { bin.bytes.&.push_all(bytes) }
fun emit(bin: &SoilBinary, word: Int) {
  bin.emit_byte(word & 16#ff)
  bin.emit_byte(word / 16#100 & 16#ff)
  bin.emit_byte(word / 16#10000 & 16#ff)
  bin.emit_byte(word / 16#1000000 & 16#ff)
  bin.emit_byte(word / 16#100000000 & 16#ff)
  bin.emit_byte(word / 16#10000000000 & 16#ff)
  bin.emit_byte(word / 16#1000000000000 & 16#ff)
  bin.emit_byte(word / 16#100000000000000 & 16#ff)
}
fun overwrite(bin: &SoilBinary, pos: Int, n: Int) {
  bin.bytes.&.get_ref(pos + 0).* = {n & 16#ff}.lower_byte()
  bin.bytes.&.get_ref(pos + 1).* = {n / 16#100 & 16#ff}.lower_byte()
  bin.bytes.&.get_ref(pos + 2).* = {n / 16#10000 & 16#ff}.lower_byte()
  bin.bytes.&.get_ref(pos + 3).* = {n / 16#1000000 & 16#ff}.lower_byte()
  bin.bytes.&.get_ref(pos + 4).* = {n / 16#100000000 & 16#ff}.lower_byte()
  bin.bytes.&.get_ref(pos + 5).* = {n / 16#10000000000 & 16#ff}.lower_byte()
  bin.bytes.&.get_ref(pos + 6).* = {n / 16#1000000000000 & 16#ff}.lower_byte()
  bin.bytes.&.get_ref(pos + 7).* = {n / 16#100000000000000 & 16#ff}.lower_byte()
}
fun emit(bin: &SoilBinary, reg: Reg) { bin.emit(reg.to_bits()) }
fun emit(bin: &SoilBinary, regs: RegAndReg) {
  bin.emit(regs.second.to_bits() * 16#10.lower_byte() + regs.first.to_bits())
}
fun emit(bin: &SoilBinary, reg_and_byte: RegAndByte) {
  bin.emit(reg_and_byte.reg)
  bin.emit(reg_and_byte.byte)
}
fun emit(bin: &SoilBinary, reg_and_int: RegAndInt) {
  bin.emit(reg_and_int.reg)
  bin.emit(reg_and_int.int)
}
fun to_bits(reg: Reg): Byte {
  switch reg
  case sp 2#0000.lower_byte()
  case st 2#0001.lower_byte()
  case a  2#0010.lower_byte()
  case b  2#0011.lower_byte()
  case c  2#0100.lower_byte()
  case d  2#0101.lower_byte()
  case e  2#0110.lower_byte()
  case f  2#0111.lower_byte()
}

| Fuzzing Stuff  
| Martinaise supports exploring code by finding sensible inputs for functions
| through fuzzing.

struct Signature { name: AstStr, args: Vec[Type] }

fun parse_position(parser: &Parser): Maybe[CodePosition] {
  var line = parser.parse_digits(10).unwrap() or return none[CodePosition]()
  parser.consume_prefix(":")
  var column = parser.parse_digits(10).unwrap() or return none[CodePosition]()
  some(CodePosition { line, column })
}

fun parse_signature(parser: &Parser): Result[Signature, Str] {
  var name = parser.parse_lower_name()
    or return error[Signature, Str]("Expected a function name.")
  parser.consume_prefix("(")
    or return error[Signature, Str]("Expected an opening parenthesis.")
  var args = vec[Type]()
  loop {
    args.&.push(parser.parse_type()? or break)
    parser.consume_prefix(",") or break
  }
  parser.consume_prefix(")")
    or return error[Signature, Str]("Expected a closing parenthesis.")
  ok[Signature, Str](Signature { name, args })
}

fun find_fun(ast: Ast, file: Str, pos: CodePosition): Maybe[AstFun] {
  | TODO: make sure position is actually inside fun (save closing brace AstStr)
  var offset = pos.to_offset(file) or return none[AstFun]()
  var best = none[AstFun]()
  for funs in ast.funs do for fun_ in funs.value do {
    if fun_.name.src.file != file then continue
    var fun_offset = fun_.name.src.span.start
    if fun_offset < offset then {
      var is_new_best =
        switch best
        case none true
        case some(f) fun_offset > f.name.src.span.start
      if is_new_best then best = some(fun_)
    }
  }
  best
}

fun generate_fuzzing_hooks(
  ast: &Ast, fun_: AstFun, type_env: Map[Str, Type],
  has_fuzzing_target_position: Bool
) {
  print_status("Generating fuzzing hooks")

  var arg_types = vec[Type]()
  for arg in fun_.args do
    arg_types.&.push(arg.type.specialize(type_env).unwrap())

  var src = src("fuzzing", 0..0)
  var opening_paren = "(" @ src

  { | struct $Input { arg_0: TypeOfArg0, arg_1: TypeOfArg1, ... }
    var fields = vec[AstStructField]()
    for it in arg_types.iter().enumerate() do
      fields.&.push(AstStructField {
        name = "arg_{it.index}" @ src, type = it.item
      })
    ast.types.&.put("$Input", AstType.struct_(AstStruct {
      name = "$Input" @ src, type_args = vec[AstStr](), fields
    }))
  }

  { | fun run(input: $Input): _ { <fun to fuzz>(input.arg_0, input.arg_1, ...) }
    var args = vec[AstExpr]()
    for index in 0..arg_types.len do
      args.&.push(AstExpr.name("input" @ src).member("arg_{index}" @ src))
    ast.funs.&.get_ref_or_put_default("run", vec[AstFun]()).push(AstFun {
      name = "run" @ src,
      is_fallback = false,
      type_args = vec[AstStr](),
      args = vec[AstFunArg](AstFunArg {
        name = "input" @ src, type = type("$Input")
      }),
      returns = type("_"),
      kind = AstFunKind.body(vec(
        AstExpr.name(fun_.name).call(args, opening_paren)
      )),
    })
  }

  | fun arg_strs(input: $Input): Slice[Str] {
  |   var v = vec[Str]()
  |   {
  |     var sb = string_builder()
  |     sb.&.write_debug(input.arg_0)
  |     v.&.push(sb.to_str())
  |   }
  |   ...
  |   v
  | }
  {
    var body = vec[AstExpr]()
    body.&.push(var_("v" @ src,
      AstExpr.name("vec" @ src).call(
        some(vec(type("Str"))), vec[AstExpr](), opening_paren
      )))
    for index in 0..arg_types.len do {
      body.&.push(AstExpr.block(vec(
        var_("sb" @ src,
          AstExpr.name("string_builder" @ src).call(opening_paren)),
        AstExpr.name("sb" @ src).member("&" @ src)
          .member("write_debug" @ src).call(vec(
            AstExpr.name("input" @ src).member("arg_{index}" @ src)
          ), opening_paren),
        AstExpr.name("v" @ src).member("&" @ src)
          .member("push" @ src).call(vec(
            AstExpr.name("sb" @ src).member("to_str" @ src).call(opening_paren)
          ), opening_paren),
      )))
    }
    body.&.push(AstExpr.name("v" @ src)
      .member("to_slice" @ src).call(opening_paren))
    ast.funs.&.get_ref_or_put_default("arg_strs", vec[AstFun]())
      .push(AstFun {
        name = "arg_strs" @ src,
        is_fallback = true,
        type_args = vec[AstStr](),
        args = vec[AstFunArg](AstFunArg {
          name = "input" @ src, type = type("$Input")
        }),
        returns = type("Slice", vec(type("Str"))),
        kind = AstFunKind.body(body),
      })
  }

  | fun fuzzing_info(static: Static[$Input]): FuzzingInfo {
  |   FuzzingInfo {
  |     has_target_position = ...,
  |     fun_line = ...,
  |     fun_name = ...,
  |   }
  | }
  {
    var args = vec(AstExpr.name("static" @ src))
    for index in 0..arg_types.len do
      args.&.push(AstExpr.name("input" @ src).member("arg_{index}" @ src))
    ast.funs.&.get_ref_or_put_default("fuzzing_info", vec[AstFun]())
      .push(AstFun {
        name = "fuzzing_info" @ src,
        is_fallback = false,
        type_args = vec[AstStr](),
        args = vec[AstFunArg](AstFunArg {
          name = "static" @ src, type = type("Static", vec(type("$Input")))
        }),
        returns = type("FuzzingInfo"),
        kind = AstFunKind.body(vec(
          AstExpr.make_struct(AstMakeStruct {
            type = type("FuzzingInfo"),
            type_src = src,
            fields = vec(
              AstMakeStructField {
                name = "has_target_position" @ src,
                value = AstExpr.name({
                  if has_fuzzing_target_position then "true" else "false"
                } @ src)
              },
              AstMakeStructField {
                name = "fun_line" @ src,
                value = AstExpr.int(
                  fun_.name.src.to_code_range().unwrap().start.line)
              },
              AstMakeStructField {
                name = "fun_name" @ src,
                value = AstExpr.str(fun_.name.str)
              },

            )
          }),
        )),
      })
  }
}

| For fuzzing, we want to exercise many different code paths. If we find an
| input that runs a new path, we want to focus on that input and mutate it to
| find similar ones.
| To do that, the compiler needs to track the coverage. I chose to track the
| branch coverage, aka which cjumps were taken. To make tracking efficient, the
| compiler inserts some instructions before every cjump instruction, updating a
| global bitset of which cjumps were taken.
| Adds a coverage initialization preamble and instruments cjumps in the given
| function by adding code that updates the coverage.
fun instrument(
  soil: Soil, function: Str, position: Maybe[Tuple2[Str, CodePosition]]
): Soil {
  var new = Asm {
    current_src = src("_not_used", 0..0),
    last_label = "",
    patches = vec[Patch](),
    soil = Soil {
      initial_mem = soil.initial_mem, | TODO: make a copy; this is mutated
      instructions = vec[Instr](),
      srcs = vec[Src](),
      labels_to_index = map[Str, Int](),
      labels = soil.labels,
    }
  }
  var mapping = map[Int, Int]()

  var target_instr = none[Int]()
  if position is some(it) then {
    var file = it.a
    if it.b.to_offset(file) is some(offset) then {
      for it in soil.srcs.iter().enumerate() do {
        var src = it.item
        if src.file != file then continue
        var instr_offset = src.span.start
        if instr_offset > offset then continue
        var is_new_target =
          switch target_instr
          case none true
          case some(index) soil.srcs.get(index).span.start < instr_offset
        if is_new_target then target_instr = some(it.index)
      }
    }
  }

  var index_to_label = map[Int, Str]()
  for entry in soil.labels_to_index do
    index_to_label.&.put(entry.value, entry.key)

  var label = ""
  var num_cjumps = 0
  for it in soil.instructions.iter().enumerate() do {
    if index_to_label.get_maybe(it.index) is some(l) then label = l
    if it.item is cjump then
      if label.starts_with(function) then num_cjumps = num_cjumps + 1
  }

  | Defines _coverage_bitset and _coverage_len data labels.
  new.soil.initial_mem.&.put("_coverage_bitset",
    filled_slice(2 * num_cjumps + 1, 0.lower_byte()))
  new.soil.initial_mem.&.put("_coverage_len", Slice[Byte] {
    len = 8, data = {2 * num_cjumps + 1}.put_on_heap().to_address()
  })

  var label = ""
  var cjump_index = 0
  var to_patch = vec[Int]()
  for it in soil.instructions.iter().enumerate() do {
    var instruction = it.item
    mapping.&.put(it.index, new.soil.instructions.len)

    if index_to_label.get_maybe(it.index) is some(l) then label = l
    new.&.set_src(soil.srcs.get(it.index))

    if target_instr is some(target_instr) then
      if it.index == target_instr then {
        | Prefix with this:
        | push a push b
        | movei a _coverage_bitset movei b <coverage bitset len> add a b
        | moveib b 1
        | storeb a b   | store a 1 at (_coverage_bitset + <len>)
        | pop b pop a
        new.&.push(Reg.a)
        new.&.push(Reg.b)
        new.&.moveimem(Reg.a, "_coverage_bitset")
        new.&.movei(Reg.b, 2 * num_cjumps)
        new.&.add(Reg.a, Reg.b)
        new.&.moveib(Reg.b, 1.lower_byte())
        new.&.storeb(Reg.a, Reg.b)
        new.&.pop(Reg.b)
        new.&.pop(Reg.a)
      }

    switch instruction
    case jump(target) {
      to_patch.&.push(new.soil.instructions.len)
      new.&.emit(instruction)
    }
    case cjump(target) {
      if label.starts_with(function) then {
        | Replace with this:
        | push a push b
        | movei a _coverage_bitset
        | movei b <index> add a b   | _coverage_bitset + index
        | moveib b 1
        | cjump .jump_taken
        | .jump_not_taken: add a b  | _coverage_bitset + index + 1
        | .jump_taken: storeb a b   | store a 1 there
        | .end: pop b pop a
        | cjump <target>            | <-- the original cjump

        new.&.push(Reg.a)
        new.&.push(Reg.b)
        new.&.moveimem(Reg.a, "_coverage_bitset")
        new.&.movei(Reg.b, cjump_index) | TODO: not times 2?
        new.&.add(Reg.a, Reg.b)
        new.&.moveib(Reg.b, 1.lower_byte())
        new.&.cjump(new.soil.instructions.len + 2) |-------+
        new.&.add(Reg.a, Reg.b)                            |
        new.&.storeb(Reg.a, Reg.b) | <---------------------+
        new.&.pop(Reg.b)
        new.&.pop(Reg.a)
        to_patch.&.push(new.soil.instructions.len) new.&.cjump(target)

        cjump_index = cjump_index + 1
      } else {
        to_patch.&.push(new.soil.instructions.len) new.&.emit(instruction)
      }
    }
    case call(target) {
      to_patch.&.push(new.soil.instructions.len) new.&.emit(instruction)
    }
    case trystart(catch) {
      to_patch.&.push(new.soil.instructions.len) new.&.emit(instruction)
    }
    default new.&.emit(instruction)
  }

  for patch in to_patch do {
    var instr = new.soil.instructions.&.get_ref(patch)
    switch instr.*
    case jump(target)  instr.* = Instr.jump(mapping.get(target))
    case cjump(target) instr.* = Instr.cjump(mapping.get(target))
    case call(target)  instr.* = Instr.call(mapping.get(target))
    case trystart(catch)  instr.* = Instr.trystart(mapping.get(catch))
    default unreachable()
  }
  for entry in soil.labels_to_index do
    new.soil.labels_to_index.&.put(entry.key, mapping.get(entry.value))

  | println("New Soil:\n{"{new.soil}".substr(0..700000)}\n...")
  | println("Fuzzed function is at {soil.labels_to_index.get(function)}")
  | if target_instr is some(index) then {
  |   var pos = position.unwrap()
  |   println("Target instruction is at {soil.srcs.get(index).span.start} (actual target was {pos.b.to_offset(pos.a).unwrap()}). 
  |     'Human-readable: {soil.srcs.get(index).to_code_range().unwrap().start} and {pos.b}")
  | }
  | println()

  new.soil
}

| Command Line Interface  
| The command line interface which you use to interact with the Martinaise
| compiler.

var help_for_martinaise = "
  'Usage: martinaise <command>\n
  'Commands:\n
  '  help [<command>]      prints help for a command\n
  '  ast <file>            prints the abstract syntax tree\n
  '  mono <file>           prints the monomorphized code\n
  '  soil <file>           prints the Soil instructions\n
  '  compile <file>        compiles the file to a Soil binary\n
  '  run <file>            compiles and runs the file\n
  '  funs <file>           prints all functions\n
  '  fuzz <file> <target>  fuzzes the given target\n
  '  tooling <...>         interaction with tooling"
var help_for_help = "
  'Usage: martinaise help [<command>]\n
  'If a command is provided, prints command-specific help."
var help_for_ast = "
  'Usage: martinaise ast <file>\n
  'Prints a humand-readable form of the abstract syntax tree.\n
  'Useful for debugging the language itself."
var help_for_mono = "
  'Usage: martinaise mono <file>\n
  'Prints a humand-readable form of the monomorphized code.\n
  'Only contains functions reachable from main.\n
  'Useful for debugging the language itself."
var help_for_soil = "
  'Usage: martinaise soil <file>\n
  'Prints the Soil instructions and initial memory.\n
  'Useful for debugging the language itself."
var help_for_compile = "
  'Usage: martinaise compile <file>\n
  'Compiles the given .mar file into a .soil file that runs the main function."
var help_for_run = "
  'Usage: martinaise run <file>\n
  'Runs the main function."
var help_for_funs = "
  'Usage: martinaise funs <file>\n
  'Prints all functions that are defined in the file or in imported files."
var help_for_fuzz = "
  'Usage: martinaise fuzz <file> <target>\n
  'Fuzzes a piece of code.\n
  'Targets:\n
  '<signature>      Fuzzes the function matching the signature.\n
  '<line>:<column>  Tries to find inputs that reach the given position.\n\n
  'Examples:\n
  'martinaise fuzz test.mar \"push(&Vec[Int], Int)\"\n
  'martinaise fuzz test.mar 2:3"
var help_for_tooling = "
  'Usage: martinaise tooling <command>\n
  'Commands:\n
  'analyze <file>        Analyzes the given file, outputting errors as JSON.\n
  'fuzz <line>:<column>  Tries to find inputs that reach the given position."

enum Command {
  help: Maybe[HelpTarget],
  ast: Str,
  mono: Str,
  soil: Str,
  compile: Str,
  run: Str,
  funs: Str,
  fuzz: FuzzCommand,
  tooling: ToolingCommand,
}

enum HelpTarget { help, ast, mono, soil, compile, run, funs, fuzz, tooling }

struct FuzzCommand { path: Str, what: FuzzWhat }
enum FuzzWhat { position: CodePosition, fun_: Signature }

enum ToolingCommand { analyze: Str, fuzz: ToolingFuzzCommand }
struct ToolingFuzzCommand { path: Str, target: CodePosition }

fun wrong_usage(message: Str): Never { stderr."{message}\n" exit(1) }
fun ensure_mar_extension(path: Str): Str {
  if not(path.ends_with(".mar")) then
    wrong_usage("Expected a .mar file, got: {path}")
  path
}

| Parses the command line arguments. If they are ill-formed, prints a message
| describing the proper usage and exits.
fun parse_args(): Command {
  var args = get_process_args()

  | Note the program name itself is also an additional argument at the front.
  if args.len < 2 then wrong_usage(help_for_martinaise)

  var command = args.get(1)
  if command == "help" then Command.help({
    if args.len == 2 then none[HelpTarget]()
    else if args.len == 3 then some({
      var command = args.get(2)
      if command == "help" then HelpTarget.help
      else if command == "ast" then HelpTarget.ast
      else if command == "mono" then HelpTarget.mono
      else if command == "soil" then HelpTarget.soil
      else if command == "compile" then HelpTarget.compile
      else if command == "run" then HelpTarget.run
      else if command == "funs" then HelpTarget.funs
      else if command == "fuzz" then HelpTarget.fuzz
      else if command == "tooling" then HelpTarget.tooling
      else wrong_usage(help_for_help)
    })
    else wrong_usage(help_for_help)
  })
  else if command == "ast" then Command.ast({
    args.len == 3 or wrong_usage(help_for_ast)
    args.get(2).ensure_mar_extension()
  })
  else if command == "mono" then Command.mono({
    args.len == 3 or wrong_usage(help_for_mono)
    args.get(2).ensure_mar_extension()
  })
  else if command == "soil" then Command.soil({
    args.len == 3 or wrong_usage(help_for_soil)
    args.get(2).ensure_mar_extension()
  })
  else if command == "compile" then Command.compile({
    | TODO: support specifying output file
    args.len == 3 or wrong_usage(help_for_compile)
    args.get(2).ensure_mar_extension()
  })
  else if command == "run" then Command.run({
    | TODO: support passing args
    args.len == 3 or wrong_usage(help_for_run)
    args.get(2).ensure_mar_extension()
  })
  else if command == "funs" then Command.funs({
    args.len == 3 or wrong_usage(help_for_funs)
    args.get(2).ensure_mar_extension()
  })
  else if command == "fuzz" then Command.fuzz({
    args.len == 4 or wrong_usage(help_for_fuzz)
    var path = args.get(2).ensure_mar_extension()
    var parser = parser("_cli", args.get(3))
    var what =
      switch parser.&.parse_position()
      case some(pos) FuzzWhat.position(pos)
      case none FuzzWhat.fun_(
        parser.&.parse_signature() or(error) wrong_usage({
          var sb = string_builder().&
          sb."{args.get(3)}\n"
          for i in 0..parser.cursor do sb." "
          sb."^\n{error}"
          sb.to_str()
        })
      )
    FuzzCommand { path, what }
  })
  else if command == "tooling" then Command.tooling({
    if args.len < 3 then wrong_usage(help_for_tooling)
    var command = args.get(2)
    if command == "analyze" then {
      args.len == 4 or wrong_usage(help_for_tooling)
      ToolingCommand.analyze(args.get(3).ensure_mar_extension())
    }
    else if command == "fuzz" then {
      args.len == 5 or wrong_usage(help_for_tooling)
      var path = args.get(3).ensure_mar_extension()
      var parser = parser("_cli", args.get(4))
      var target = parser.&.parse_position()
        or wrong_usage(help_for_tooling)
      ToolingCommand.fuzz(ToolingFuzzCommand { path, target })
    }
    else wrong_usage(help_for_tooling)
  })
  else wrong_usage(help_for_martinaise)
}

fun unwrap_or_report_and_exit[T](result: Result[T, Error]): T {
  result or(error) {
    if tooling_mode
    then println(error.to_json())
    else { eprintln() stderr.write(error) eprintln() }
    exit(1)
  }
}

fun main(): Never {
  var command = parse_args()

  if command is tooling then {} else eprintln("Welcome to Martinaise 8.")

  switch command
  case help(command) {
    var help = if command is some(command) then {
      switch command
      case help help_for_help
      case ast help_for_ast
      case mono help_for_mono
      case soil help_for_soil
      case compile help_for_compile
      case run help_for_run
      case funs help_for_funs
      case fuzz help_for_fuzz
      case tooling help_for_tooling
    } else help_for_martinaise
    print(help)
  }
  case ast(path) {
    var ast = parse_project(path).unwrap_or_report_and_exit()
    print_status("{ast}")
  }
  case mono(path) {
    var ast = parse_project(path).unwrap_or_report_and_exit()
    var mono = ast.compile_main().unwrap_or_report_and_exit()
    print_status("{mono}")
  }
  case soil(path) {
    var ast = parse_project(path).unwrap_or_report_and_exit()
    var mono = ast.compile_main().unwrap_or_report_and_exit()
    var soil = mono.soil().unwrap_or_report_and_exit()
    print_status("{soil}")
  }
  case compile(path) {
    var start = now_instant()
    var ast = parse_project(path).unwrap_or_report_and_exit()
    var ast_done = now_instant()
    print_status("Parsed        – {ast_done.nanos_since(start) / 1000000} ms\n")
    var mono = ast.compile_main().unwrap_or_report_and_exit()
    var mono_done = now_instant()
    print_status("Monomorphized – {mono_done.nanos_since(ast_done) / 1000000} ms\n")
    var soil = mono.soil().unwrap_or_report_and_exit()
    var soil_done = now_instant()
    print_status("Assembled     – {soil_done.nanos_since(mono_done) / 1000000} ms\n")
    var binary = soil.to_binary()
    var binary_done = now_instant()
    print_status("Binaryfied    – {binary_done.nanos_since(soil_done) / 1000000} ms\n")

    print_status("Writing binary")
    var out_file = path
    out_file.&.trim_suffix(".mar")
    out_file = "{out_file}.soil"
    write_file(out_file, binary)
    var write_done = now_instant()
    print_status("Written       – {write_done.nanos_since(binary_done) / 1000000} ms\n")
    print_status("Compiled to {out_file} ({binary.len} bytes) in {write_done.nanos_since(start) / 1000000} ms. Enjoy!")
  }
  case run(path) {
    var ast = parse_project(path).unwrap_or_report_and_exit()
    var mono = ast.compile_main().unwrap_or_report_and_exit()
    var soil = mono.soil().unwrap_or_report_and_exit()
    var binary = soil.to_binary()

    print_status("Compiled ({binary.len} bytes). Running!")
    exec(binary)
  }
  case funs(path) {
    var ast = parse_project(path).unwrap_or_report_and_exit()

    print_status("Functions:")
    var all_names = vec[Str]()
    for entry in ast.funs do all_names.&.push(entry.key)
    all_names.to_slice().&.sort()
    for name in all_names do for f in ast.funs.get(name) do
      println("{f.stripped_signature()}")
  }
  case fuzz(fuzz) {
    var path = fuzz.path
    var ast = parse_project(path).unwrap_or_report_and_exit()

    var fuzzed_fun =
      switch fuzz.what
      case position(pos) {
        switch ast.find_fun(path, pos)
        case none wrong_usage("There is no function at that position.")
        case some(fun_) {
          if fun_.type_args.is_empty()
          then LookupFunSolution { fun_, type_env = map[Str, Type]() }
          else wrong_usage("Can't fuzz generic function (for now).")
        }
      }
      case fun_(signature)
        ast.lookup_fun(signature.name, none[Vec[Type]](), signature.args)
          .unwrap_or_report_and_exit()

    | Generates an $Input struct for the fuzzed function as well as functions:
    | generate(Generator[$Input]): $Input
    | run($Input): _
    ast.&.generate_fuzzing_hooks(
      fuzzed_fun.fun_, fuzzed_fun.type_env, fuzz.what is position)

    var mono = ast.compile_fuzzer_main(type("$Input"))
      .unwrap_or_report_and_exit()
    var soil = mono.soil().unwrap_or_report_and_exit()

    var fuzzed_fun = fuzzed_fun.compile(context().&, ast, mono.&)
      .unwrap() | The fuzzed fun should already be compiled.
    var pos =
      switch fuzz.what
      case position(pos) some(tuple(path, pos))
      case fun_ none[Tuple2[Str, CodePosition]]()
    soil = soil.instrument(fuzzed_fun, pos)

    var binary = soil.to_binary()

    print_status("Generated fuzzer ({binary.len} bytes). Fuzzing!")
    exec(binary)
  }
  case tooling(command) {
    tooling_mode = true

    switch command
    case analyze(path) {
      var ast = parse_project(path).unwrap_or_report_and_exit()
      var mono = ast.compile_main().unwrap_or_report_and_exit()
      var soil = mono.soil().unwrap_or_report_and_exit()
    }
    case fuzz(fuzz) {
      var path = fuzz.path
      var ast = parse_project(path).unwrap_or_report_and_exit()

      var fuzzed_fun =
        switch ast.find_fun(path, fuzz.target)
        case none wrong_usage("There is no function at that position.")
        case some(fun_) {
          if fun_.type_args.is_empty()
          then LookupFunSolution { fun_, type_env = map[Str, Type]() }
          else wrong_usage("Can't fuzz generic function (for now).")
        }
      ast.&.generate_fuzzing_hooks(fuzzed_fun.fun_, fuzzed_fun.type_env, true)

      var mono = ast.compile_fuzzer_main(type("$Input"))
        .unwrap_or_report_and_exit()
      var soil = mono.soil().unwrap_or_report_and_exit()

      var fuzzed_fun = fuzzed_fun.compile(context().&, ast, mono.&)
        .unwrap("The fuzzed fun should already be compiled.")
      var soil = soil.instrument(fuzzed_fun, some(tuple(path, fuzz.target)))

      var binary = soil.to_binary()
      print_status("Generated fuzzer ({binary.len} bytes). Fuzzing!")
      exec(binary)
    }
  }
  exit(0)
}

fun exec(binary: Slice[Byte]): Never asm {
  moveib a 8  add a sp load a a | binary.data
  moveib b 16 add b sp load b b | binary.len
  syscall 12
}
